\chapter{Conclusion} \label{sec:conclusionChapter}

We conclude this report by highlighting the contributions of this project:
\begin{itemize}
    \item
    Within the scope defined in Section~\ref{sec:scope}, we have explained the data structure presented in \cite{patrascu2014dynamic}, together with helper functions and algorithms. This has been complemented with illustrative examples.
    
    \item
    We have implemented and documented the data structure, making it publicly available for future work.
    
    \item
    We have implemented and included correctness tests in the repository. These attest the correctness of the implementations we present, and that were designed such that they can be used to assess the correctness of further implementations.
    
    \item
    We have listed other data structures that are of interest within the context of the dynamic predecessor problem, pointing to future work in the form of benchmarks.
\end{itemize}

\section{Final Remark}

There is a fine balance between space and time consumption when developing and implementing sub-logarithmic data structures and algorithms. For example, van Emde Boas trees is a very fast data structure, but with a big space consumption drawback. Fusion Trees improve on space consumption, but updates take excessive time. Dynamic Fusion Trees, introduced in this project, seem to find the perfect balance between space and time consumption.

TURN THIS INTO A CONCLUSION
\textbf{Despite their theoretical relevance, when having a data structure and its operations measured against wall clock, one might be surprised with the results.
This is because theoretical bounds have the potential to hide big constants, which are brought to light when wall clock measurements are performed.
Nevertheless, we will enumerate some models of computation, as many of the data structures here presented have their running times described in terms of a given model, and therefore, it is of interest to provide this context.}

\section{Future Work} \label{sec:futureWork}
In this section, we leave some suggestions on how further work on this topic can be conducted. We have split these into three main categories:
\begin{enumerate}
    \item
    Implementation, which covers specific data structures or algorithms.
    
    \item
    Optimization, which entails improving the present code.
    
    \item
    Benchmarking, which points to other data structures that either solve partially or totally the dynamic predecessor 
    
\end{enumerate}

\subsection{Implementation} \label{sec:FutureWorkImplementation}

\paragraph*{Delete methods}
The implementation featured in Section~\ref{sec:InsertDontCares} implements the {\ttfamily delete} method naively, but all the ingredients needed to implement it while adhering to \textit{Inserting a key} section of \cite{patrascu2014dynamic} are already present in the implementation.

\paragraph*{Key compression in constant time}
One of the bottlenecks of implementations from Sections~\ref{sec:rankWithDontCares} and \ref{sec:InsertDontCares} is how the compressed keys with "don't cares" are maintained. Specifically, the next iterative step in the implementation from Section~\ref{sec:InsertDontCares} is to implement functions that compute the compressed keys in $O(1)$ time, as explained in Chapters $[3.2 - 3.3]$ of \cite{patrascu2014dynamic}.

\paragraph*{Dynamic Fusion Tree}
After enabling all the operations at the node level in $O(1)$ time with the previous steps' implementation, all that remains to complete the implementation is to implement a $k$-ary tree using a \textit{Dynamic Fusion Node} as its node. This is covered in Chapter $4$ of \cite{patrascu2014dynamic}.

\paragraph*{Non-recursive implementation}
Chapter 4 of \cite{patrascu2014dynamic} mentions that once the dynamic fusion tree is implemented, the rank operation on a tree is given by a recursive function. Recursion in Java can be slow \cite{shirazi2003java}, and for this reason, a non-recursive alternative is preferred.

\subsection{Benchmarking}

\paragraph*{msb functions}
It would be interesting to see how the different msb functions implemented in this project compare to each other in terms of time.

\paragraph*{Dynamic Predecessor Problem Data Structures}
Once the \textit{Dynamic Fusion Tree} is fully implemented, the next logical step would be to benchmark it with other data structures that solve, either partially or entirely, the dynamic predecessor problem. These would be the data structures mentioned in Section~\ref{sec:IntegerSets}.

\subsection{Optimization}

\paragraph*{Space}
Space consumption can be improved by, for instance, avoiding and combining some of the fields. When $k = 8$, $bKey$ would only use $8$ of the $64$ allocated bits, and $index$ would use $3 \times 8 = 24$ bits. So, in total, $32$ bits for both words. This is an example of how space can be improved.

\paragraph*{Simulate a longer word size}
One of the limitations of the present implementation is that the maximum integer size is 64 bits on a common modern machine. An interesting improvement would be to simulate larger word size $w$, which would increase $k$, allowing to store more keys at the node level. This would have to be carefully studied to keep every operation in $O(1)$ time.


\paragraph*{Lookup {\ttfamily M} constant}
The {\ttfamily Util} class includes a function, {\ttfamily M}, which takes $b$ and $w$ as parameters and returns the word $(0^{b-1}1)^{(w/b)}$. It is a widely used function in this repository, and it has been implemented with a loop. With limited word size, this could easily be implemented as a lookup function, improving the running time up to $O(1)$.

\paragraph*{Profiling}
This technique allows us to see which sections of the code the CPU uses most of the time, indicating possible code bottlenecks. By using it, the implementation can be fine-tuned up to the point where it can be competitive.