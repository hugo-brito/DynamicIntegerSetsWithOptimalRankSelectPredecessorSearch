\part{Implementation}

% \addsec{Unnumbered level}

% \section{First level}
% \subsection{Second level}
% \subsubsection{Third level}
% \paragraph{Forth level}
% \subparagraph{Fifth level}

% \subsection{Dummy subsection}

% This is some text to showcase the features of this thesis template. For example, it is possible to add a side note with\myMarginnote{I am a side note!}.

% In this paragraph, I will add an image as a template:
% \begin{figure}[H]
% \centering
% 	\includegraphics[width=0.9\textwidth]%
% 	{03_GraphicFiles/CowLickingNose.jpg}%
% \caption[A cow]{A cow licking its nose. Usage with permission of the photographer \textsc{Nicole Barth}, taken from \url{www.flickr.com/photos/46311827@N07/14885545396}.}
% \label{fig:CowLickingNose}
% \end{figure}

% In \figurename~\ref{fig:CowLickingNose}\myMarginnote{Reference to a figure} you see a cow that is licking its nose. The picture was taken by Nicole Barth on 11.08.2014 using a Canon EOS 500D. The original file has a resolution of $4247 \times 2831$ pixels.
% Note that the image is also referenced.

\chapter{Background}

In this section, a series of data structures, techniques and other relevant aspects are presented in order to lay the foundation for the implementation that is presented in this report. The following subsections aim at providing some background and to frame the state of the art up to the point where the  \cite{patrascu2014dynamic} paper was presented.

The \cite{patrascu2014dynamic} paper presents a dynamic data structure for storing integers and claims that its running times are optimal. We start by looking at what has been done in that research area.

\section{Basic Concepts}

\subsection{Word}
A word consists of a $w$-bit integer. This means that we are bound to an universe $\mathcal U = \{0, 1, ..., 2^{w}-1\}$.

\subsection{Universe}
The universe of all possible keys, denoted by $\mathcal U$, has size $u = 2^{w}$. 

\subsection{The Predecessor Problem}
Data structures that maintain a set, $S$ of (integer) keys and enable the following operations are said to solve the static predecessor problem \cite{beame1999optimal}:
\begin{itemize}
    \item
    $member(x)$ returns $[x \in S]$.
    \item
    $predecessor(x)$ returns $max\{y\in S\ |\ y < x\}$.
    \item
    $successor(x)$ returns $min\{y\in S\ |\ y \geq x\}$.
\end{itemize}

The predecessor problem can also be dynamic \cite{beame1999optimal} if the said data structure allows:
\begin{itemize}
    \item
    $insert(x)$ sets $S=S \cup \{x\}$.
    \item
    $delete(x)$ sets $S=S \setminus \{x\}$.
\end{itemize}

In this context, the following operations might also be relevant:
\begin{itemize}
    \item
    $rank(x)$ returns $\#\{ y \in S\ |\ y < x\}$.
    \item
    $select(i)$ returns $y \in S$ with $rank(y) = i$, if any.
\end{itemize}

In particular, the data structure presented in \cite{patrascu2014dynamic} not only implements all of the above, and claims that the running times are optimal for all of them are optimal, it also establishes that, by having the operations defined in this manner \cite{patrascu2014dynamic}:
\begin{itemize}
    \item
    $predecessor(x) = select(rank(x - 1))$
    \item
    $successor(x) = select(rank(x))$
\end{itemize}

Given this set of standard operations, this data structure solves the dynamic predecessor problem \cite{beame1999optimal}.

\subsection{Models of Computation}\label{sec:modelsofcomputation}

In order to analyze and describe running times, authors resort to models of computation. Each model states which operations have an associated cost, and which ones do not.
These models provide no unit of cost, and the given operations either have one unit of cost, or none.

Despite their theoretical relevance, when having a data structure and its operations measured against wall clock, one might be surprised with the results.
This is because theoretical bounds have the potential to hide big constants, which are brought to light when wall clock measurements are performed.
Nevertheless, we will enumerate some models of computation, as many of the data structures here presented have their running times described in terms of a given model and therefore it is of interest to provide this context.

The models are presented in descending order from strongest to the least strong. This means that a less restrictive model, such as the cell-probe model is more suited to describe the theoretical \emph{lower} bounds of a data structure than the least stronger ones \cite{erikdemainelec11}.

\subsubsection{The Cell-Probe Model}
In the cell-probe model memory is divided into cells of size $w$, a parameter of the model. Every computation is free.
The only operations that come with an associated cost are reading or writing to memory, which are basically the memory accesses.
Due to its simplicity, as stated in \ref{sec:modelsofcomputation}, it is widely used to prove lower bounds \cite{erikdemainelec11}.

\subsubsection{Trans-dichotomous RAM}
In the trans-dichotomous RAM model, memory consists of an array of size $S$ of $w$-bit words.
Reading or writing to one of the memory cells costs $O(1)$.
Additionally, memory cells can be used as pointers to other cells, e.g. a single $w$-bit word can be used to access another cell.
This implies that, the word length $w$ has to be large enough in order be able to index all to access all cells in the memory.
Let the problem size be $n$:
\begin{equation}\label{eq:problemSize}
    w \ge \log_2(S) \implies w \ge \log_2(n)
\end{equation}
The name is due to expression~\ref{eq:problemSize}, which relates two dichotomies: problem size $n$; and the model of computation with words of size $w$ \cite{erikdemainelec11}. 

\subsubsection{Word RAM}
Similarly to the trans-dichotomous RAM model, the word RAM also operates with fixed size $w$-bit words. Additionally, the following operations have an associated cost \cite{nelsonjelanilec1}:
\begin{itemize}
    \item Integer arithmetic (addition $+$, subtraction $-$, multiplication $\times$, division $\div$ and remainder of division (modulo) $\bmod$);
    \item Bitwise operations (negation $\neg$, and $\wedge$, or $\vee$, exclusive or $\oplus$);
    \item Bitshift operations (right bitshift $\gg$, left bitshift $\ll$).
\end{itemize}

\section{Integer Data Structures}

Table~\ref{tab:dataStructComparison} can be seen as a summary of relevant data structures that, in incremental steps, led to the data structure presented in this project.

\begin{table}[H]
\centering
\input{src/tex/04_Tables/001_DataStructuresComparison.tex}
\caption[Data structure comparison]{Data structures used to solve the predecessor problem and their respective theoretical running times.}
\label{tab:dataStructComparison}
\end{table}

\subsection{Binary Search Tries}

\subsection{Patricia Tries}

\subsection{Fusion Trees}

\section{Summary of techniques used in the present implementation}

\subsection{Most significant set bit}

Learning about the most significant set bit of a word will be an important operation in the implementation. For this reason, we have looked at different ways to achieve this result efficiently. Since it is to be used as a subroutine in certain operations, it has the potential to become a bottleneck if not implemented carefully.

\subsubsection{Naive}

The simplest way to achieve the intended outcome is to loop through the word until the first non-zero bit is found, returning the number of iterations that it took to find that bit.

This approach takes $O(w)$ time.

\subsubsection{Lookup}

In this approach, a lookup table containing the most significant bits answers for all combinations of 8 bits is pre-computed.

When a query comes, it is split in 8-bit parts and the algorithm looks at the first 8 most significant bits. If those bits are not zero, then the most significant bit of the queried word lies in that block. In such case, the answer will be the most significant set bit of that block plus all the bits that were discarded, e.g. the number of bits we had to shift to the right in order to have that 8-bit block in the 8 least significant positions of the word. Since the answer to any combination of of 8 bits is pre-computed, then we know the answer in constant time.

Otherwise, if the first block of 8 bits is 0, the algorithm looks at the second 8-bit block and does the same operation as described in the previous paragraph, subtracting now 8 bits less to the answer.

This approach takes $O(1)$ after the lookup table has been computed but, not only the lookup table takes time to compute, it also uses some space.

\subsubsection{Constant time with parallel comparison}



\chapter{Implementation of theoretically optimal dynamic rank, select, and predecessor data structure}

\subsection{Code base navigation}

\section{Naive implementation}
We start with a naive implementation of name {\ttfamily NaiveDynamicFusionNode}. It holds a {\ttfamily key} array to store the keys, and a counter for the current number of keys in the data structure. The keys can be any 64-bit integer.

The basic idea behind this implementation is to store the keys in {\ttfamily key}, making their respective rank the same as the their index in that array. In other words, {\ttfamily key} is always sorted.

Updates, e.g. insert and delete, take $O(n)$ time. This is because whenever a key is inserted, its rank $i$ is found, and the key at that position as well as all following keys up to $n-1$ are updated. Since any given key index in {\ttfamily key} is its rank, all the keys with rank larger than the new key have to be moved one position to the right in {\ttfamily key} to make room for the new key and keeping rank consistent.

A rank query takes $O(\log_2(n))$ because a binary search is performed on {\ttfamily key}. Select is faster: $O(1)$, because we need only to access and return the key at position {\ttfamily i} in {\ttfamily key} to fulfill the query.

\section{DynamicFusionNode with binary search for Rank}
We take a step forward by improving on the previous idea: this time, two additional words, {\ttfamily index} and {\ttfamily bKey} are kept in the fields. The goal is to use the concepts described in the \textit{Indexing} chapter of \cite{patrascu2014dynamic} to implement this data structure. The running times will be $O(\log_2 n)$ for updating and querying, and this is because the {\ttfamily rank} operation resorts to binary search to produce the result.

We interpret {\ttfamily bKey} as an array where the values first $k$ significant bits correspond to the positions in {\ttfamily key}. Let us assume that the bits in {\ttfamily bKey} are indexed from $0$ to $k-1$: if the $i^{th}$ bit is set to $1$, then position $i$ in {\ttfamily key} is free and can store a key, and vice-versa.

We interpret {\ttfamily index} as an array of $k$ entries, each taking $\lceil \log_2(k) \rceil$ bits. In order to maximize the use of the number of bits in {\ttfamily index}, and knowing that our program is working with 64-bit integers, we solve the following equation:
\begin{equation}
    k \cdot log_2(k) = 64 \iff k = 16
\end{equation}
If $k=16$, then $\lceil \log_2(k) \rceil = 4$. We use each $\lceil \log_2(k) \rceil$-bits in {\ttfamily index} to store the indices of the keys in {\ttfamily key}, ensuring that in {\ttfamily index} the

\chapter{Correctness tests}

\section{{\ttfamily Util} class tests}

\subsection{MSB series tests}

The {\ttfamily Util} class contains many different implementations of the MSB operation. All tests prefixed with {\ttfamily msb} in the {\ttfamily UtilTest} class compare the results of the Java standard library {\ttfamily numberOfLeadingZeros} (either from the {\ttfamily Integer} or {\ttfamily Long} classes, depending of the number of bits per integer) with the implementation from the class.

\subsection{{\ttfamily splitLong} and {\ttfamily mergeInts}}

For a determined range 64-bit keys, it evaluates if the following property holds for the whole range: {\ttfamily key == mergeInts(splitLong(key))}.

\section{Integer Data Structure tests}

\subsection{Test parameters}

Each implementation of {\ttfamily RankSelectPredecessorUpdate} has a corresponding test class, which in turn has {\ttfamily Test} appended to its name. For example, the {\ttfamily BinarySearchTrie} test class is called {\ttfamily BinarySearchTrieTest} and it can be found in the {\ttfamily src/test/java} folder.

Each test class creates an instance of {\ttfamily RankSelectPredecessorUpdateTest} whose methods take a concrete implementation of {\ttfamily RankSelectPredecessorUpdate} to be tested. The constructor takes the following parameters:

\begin{itemize}
    \item {\ttfamily long seed}. This seed is used as parameter for instantiating a pseudo-random generator from the Java standard library --- {\ttfamily java.util.Random}. This instance will be later used to produce data for the test cases, such as seeds for passes (explained below), which in their turn will produce keys to be used in the tests.
    \item {\ttfamily int passes}. Some tests can be executed in more than one pass. A pass in a particular test consists of generating data with its corresponding seed and running the test with that data. When $passes > 1$, then different seeds are generated, which will result in different pseudo-random values and the test is run {\ttfamily passes} number of times.
    \item {\ttfamily int numKeys}. This parameter defines the size of the data set to be generated. It is particular important for testing for instance {\ttfamily DynamicFusionNode}, which size cannot exceed $k$.
\end{itemize}

\subsection{{\ttfamily insertAndMemberSmallTest()}}
The methods tested in this test are {\ttfamily insert} and {\ttfamily member}. A small set of predetermined keys is inserted in the set and then {\ttfamily member} is called on the set with each of those keys. 

\subsection{{\ttfamily smallCorrectnessTest()}}

An instance of a {\ttfamily RankSelectPredecessorUpdate} implementation is instantiated and keys are inserted such that after these insertions $S = \{10, 12, 42, -1337, -42\}$.

It is defined that:
\begin{itemize}
    \item Select queries can range between $0$ and $|S|-1$. Should any query fall outside this range, then {\ttfamily null} is returned, meaning, no result.
    \item $Select(0) = min\{y \in S \}$.
    \item $Select(|S|-1) = max\{y \in S\}$.
    \item Rank queries be any $w$-bit integer, and their possible range of results $\big[ 0, |S| \big]$
    \item Any given predecessor query returns the largest key in the subset of keys that are \textbf{strictly} smaller than the query, otherwise {\ttfamily null}.
    \item Whereas a successor query returns the queried key if present, otherwise the smallest key in the subset of keys that are larger than the query if any (and in such case {\ttfamily null} is returned).
\end{itemize}

With the given set and the above-mentioned rules, a small test is performed. Table~\ref{tab:smallCorrectnessTests} shows the expressions to be evaluated, and all of them must evaluate to {\ttfamily true} for the test to pass.

\begin{table}[H]
\centering
\input{src/tex/04_Tables/002_CorrectnessTestSmall}
\caption[Small correctness tests]{Small correctness tests.}
\label{tab:smallCorrectnessTests}
\end{table}


\subsection{{\ttfamily insertThenMemberTest()}}

The methods tested in this test are {\ttfamily insert} and {\ttfamily member}, and it can be executed in passes. It consists of:
\begin{enumerate}
    \item
    Iterating through all the the pseudo-randomly-generated keys and inserting them all in the instance to be tested.
    \item
    Iterating in random order through all the keys and asserting $key \in S$.
\end{enumerate}

\subsection{{\ttfamily insertThenDeleteRangeOfKeysTest()}}

The methods tested in this test are {\ttfamily insert} and {\ttfamily member}. It consists of iterating the whole range (which goes from $0$ to {\ttfamily numKeys}), where each iteration {\ttfamily i} consists of:
\begin{enumerate}
    \item
    Asserting that the key, {\ttfamily i} is not in the set by calling {\ttfamily member} on the set with the key.
    \item
    Inserting the key {\ttfamily i} in the set.
    \item
    Asserting that the key {\ttfamily i} is in the set.
\end{enumerate}
Should the number of keys exceed 9, then every $1/10$ of {\ttfamily numKeys} the data structures is reset and all keys are removed.

\subsection{{\ttfamily insertThenDeleteRandomKeysTest()}}

The methods tested in this test are {\ttfamily insert} and {\ttfamily delete} and it can be executed in passes. After inserting all the pseudo-randomly-generated keys in the set, the keys are iterated in random order. Each iteration consists of:
\begin{enumerate}
    \item Asserting that $key \in S$.
    \item Removing the key.
    \item Asserting that $key \not\in S$.
\end{enumerate}

\subsection{{\ttfamily deleteTest()}}

This test aims at asserting that only when deleting an existing key the cardinality of the set is altered. It tests the methods {\ttfamily delete} and size, and it can be executed in passes. At each pass:
\begin{enumerate}
    \item
    Pseudo-random keys are generated and delete on the set is called with that key.
    \item
    If the key was in the set, them the size must have decreased, otherwise it must remain the same.
\end{enumerate}

\subsection{{\ttfamily sizeTest()}}

The methods tested in this test are {\ttfamily insert}, {\ttfamily size} and {\ttfamily delete} and it can be executed in passes. Each pass consists of:
\begin{enumerate}
    \item
    Iterating the pseudo-randomly-generated keys in random order. At each iteration the key is inserted and it is asserted that {\ttfamily size} has increased by 1.
    \item
    After all the keys have been inserted, the keys are iterated in random order once more and at each iteration the key is removed and it is asserted that {\ttfamily size} has decreased by 1.
\end{enumerate}

\subsection{{\ttfamily growingRankTest()}}

This test aims ensuring that the following property holds for all the keys in the set: the rank of keys in sorted order is a monotone increasing function. It can be executed in passes and it is works the following way:
\begin{itemize}
    \item
    After inserting all the keys in the set, a copy of those keys is kept on a {\ttfamily TreeSet} (a set that keeps its values in sorted order) such that we can iterate them in their sorted order.
    \item
    A counter {\ttfamily i} is kept and initialized as $0$. It is incremented at each iteration.
    \item
    The test then asserts that the rank of the key is the same as the number of current iteration. Note that we can assume that this condition must hold because the keys are iterated in sorted order. 
\end{itemize}

\subsection{{\ttfamily selectOfRankTest()}}

This test aims ensuring that the following property holds for all the keys in the set: if a key is present in the set, knowing its rank and them querying for select of that must return the key. It can be executed in passes and it is works by iterating through the pseudo-randomly-generated keys and at each iteration it is asserted that {\ttfamily key == select(rank(key))}.

\subsection{{\ttfamily rankOfSelectTest()}}

This test aims ensuring that the following property holds for all the keys in the set: the rank of select a query is the query. It can be executed in passes and it is works by iterating from {\ttfamily 0} to {\ttfamily numKeys}. At each iteration {\ttfamily i}, it is asserted that {\ttfamily i == rank(select(i))}.