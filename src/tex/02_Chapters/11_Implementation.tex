% \part{Implementation}

% \addsec{Unnumbered level}

% \section{First level}
% \subsection{Second level}
% \subsubsection{Third level}
% \paragraph{Forth level}
% \subparagraph{Fifth level}

% \subsection{Dummy subsection}

% This is some text to showcase the features of this thesis template. For example, it is possible to add a side note with\myMarginnote{I am a side note!}.

% In this paragraph, I will add an image as a template:
% \begin{figure}[H]
% \centering
% 	\includegraphics[width=0.9\textwidth]%
% 	{03_GraphicFiles/CowLickingNose.jpg}%
% \caption[A cow]{A cow licking its nose. Usage with permission of the photographer \textsc{Nicole Barth}, taken from \url{www.flickr.com/photos/46311827@N07/14885545396}.}
% \label{fig:CowLickingNose}
% \end{figure}

% In \figurename~\ref{fig:CowLickingNose}\myMarginnote{Reference to a figure} you see a cow that is licking its nose. The picture was taken by Nicole Barth on 11.08.2014 using a Canon EOS 500D. The original file has a resolution of $4247 \times 2831$ pixels.
% Note that the image is also referenced.

\chapter{Background}

The \cite{patrascu2014dynamic} paper presents a dynamic data structure for storing integers and claims that its running times are optimal.
In this chapter, a series of data structures, techniques, and other relevant aspects will be presented, laying the foundation for the implementation of the data structure presented by Pătrașcu and Thorup.

\section{Basic Concepts}

\subsection{Word} \label{sec:word}
A word consists of a $w$-bit integer. This means that we are bound to an universe $\mathcal U = \{0, 1, ..., 2^{w}-1\}$. The bits which a word is comprised of are indexed from the least (left) to the most (right) significant bit, having the least significant bit index $0$, whereas the most significant has index $w-1$.

\subsection{Universe}
The universe of all possible keys, denoted by $\mathcal U$, has size $u = 2^{w}$, e.g., all combinations of $w$-bit words.

\subsection{The Predecessor Problem} \label{sec:predecessorProblem}
Data structures that maintain a set, $S$ of (integer) keys and enable the following operations are said to solve the static predecessor problem \cite{beame1999optimal}:
\begin{itemize}
    \item
    $\text{member}(x)$ returns $[x \in S]$.
    \item
    $\text{predecessor}(x)$ returns $\text{max}\{y\in S\ |\ y < x\}$.
    \item
    $\text{successor}(x)$ returns $\text{min}\{y\in S\ |\ y \geq x\}$.
\end{itemize}

The predecessor problem can also be dynamic \cite{beame1999optimal} if the said data structure also allows:
\begin{itemize}
    \item
    $\text{insert}(x)$ sets $S=S \cup \{x\}$.
    \item
    $\text{delete}(x)$ sets $S=S \setminus \{x\}$.
\end{itemize}

In this context, the following operations might also be relevant:
\begin{itemize}
    \item
    $\text{rank}(x)$ returns $\#\{ y \in S\ |\ y < x\}$.
    \item
    $\text{select}(i)$ returns $y \in S$ with $\text{rank}(y) = i$, if any.
\end{itemize}

In particular, the data structure presented in \cite{patrascu2014dynamic} not only implements all of the above, but it also establishes that by having the operations defined in this manner \cite{patrascu2014dynamic}:
\begin{itemize}
    \item
    $\text{predecessor}(x) = \text{select}(\text{rank}(x - 1))$
    \item
    $\text{successor}(x) = \text{select}(\text{rank}(x))$
\end{itemize}

Given this set of standard operations, this data structure solves the dynamic predecessor problem.

\subsection{Models of Computation}\label{sec:modelsofcomputation}

In order to analyze and describe running times, authors resort to models of computation. Each model states which operations have an associated cost, and which ones do not.
These models provide no unit of cost, and the given operations either have one unit of cost or none.

Despite their theoretical relevance, when having a data structure and its operations measured against wall clock, one might be surprised with the results.
This is because theoretical bounds have the potential to hide big constants, which are brought to light when wall clock measurements are performed.
Nevertheless, we will enumerate some models of computation, as many of the data structures here presented have their running times described in terms of a given model, and therefore, it is of interest to provide this context.

The models are presented in descending order from strongest to the least strong. This means that a less restrictive model, such as the cell-probe model, is more suited to describe the theoretical \emph{lower} bounds of a data structure than the least stronger ones \cite{erikdemainelec11}.

\subsubsection{The Cell-Probe Model}
In the cell-probe model, memory is divided into cells of size $w$, a parameter of the model. Every computation is free.
The only operations that come with an associated cost are reading or writing to memory, which are basically the memory accesses.
Due to its simplicity, as stated in \ref{sec:modelsofcomputation}, it is widely used to prove lower bounds \cite{erikdemainelec11}.

\subsubsection{Trans-dichotomous RAM}
In the trans-dichotomous RAM model, memory consists of an array of size $S$ of $w$-bit words.
Reading or writing to one of the memory cells costs $O(1)$.
Additionally, memory cells can be used as pointers to other cells, e.g., a single $w$-bit word can be used to access another cell.
This implies that the word length $w$ has to be large enough to be able to index all to access all cells in the memory.
Let the problem size be $n$:
\begin{equation}\label{eq:problemSize}
    w \ge \log_2(S) \implies w \ge \log_2(n)
\end{equation}
The name is due to expression~\ref{eq:problemSize}, which relates two dichotomies: problem size $n$; and the model of computation with words of size $w$ \cite{erikdemainelec11}. 

\subsubsection{Word RAM}
Like the trans-dichotomous RAM model, the word RAM also operates with fixed size $w$-bit words. Additionally, the following operations have an associated cost \cite{nelsonjelanilec1}:
\begin{itemize}
    \item Integer arithmetic (addition $+$, subtraction $-$, multiplication $\times$, division $\div$ and remainder of division (modulo) $\bmod$);
    \item Bit-wise operations (negation $\neg$, and $\wedge$, or $\vee$, exclusive or $\oplus$);
    \item Bit-wise shifting operations (right bit-shift $\gg$, left bit-shift $\ll$).
\end{itemize}

\newpage
\section{Integer Sets} \label{sec:IntegerSets}

This section highlights some data structures that maintain integer sets and implement the (dynamic) predecessor problem, e.g., integer sets that have methods that answer the queries mentioned in Section~\ref{sec:predecessorProblem}.
The data structures are somewhat ordered by what they improve on from the previous, or by complexity, because they add a new way of looking at the problem.
We will also analyze, on a high level, their running times and how the queries can be implemented.
Note that we do not need to be concerned about the successor and predecessor queries for most of them, as they can be trivially implemented by using the definitions from Section~\ref{sec:predecessorProblem}.

\subsection{Array}

Perhaps the most naive way to maintain a set of integers is to implement it while having an underlying array. By ensuring that the array is always sorted after updates, we know that select queries are implemented by returning the key at the specified index, while rank queries are implemented by doing a binary search. These queries take $O(1)$ and $O(\log_2 n)$ time, respectively. Updating, e.g., inserting and deleting, would take $O(n)$ time because:
\begin{enumerate}
    \item
    We would first need to find the rank of the key to be inserted (or deleted), $i$.
    
    \item
    And then, all the keys whose rank is larger than $i$ would have to be moved by one position in the array. For insertion, those keys would have to be moved to the right; for deletion, those keys would have to be moved to the left.
\end{enumerate}

\subsection{Red-Black BST}

Using a self-balancing binary search tree to implement the set, such as a red-black tree, could improve the running times quite substantially.
This data structure guarantees $O(\log_2 n)$ for all of the dynamic predecessor problem queries.
When searching, this guarantee is given by the height invariant of the tree, which is always $O(\log_2 n)$ \cite{cormen2009introduction}.
Updates consist of:
\begin{enumerate}
    \item
    Searching, which takes $O(\log_2 n)$ time.
    
    \item
    Once the rightful place of the key in the tree is found, a $O(1)$ number of operations take place in order to maintain the invariant of the tree. 
\end{enumerate}

Another advantage of this data structure is that, since the elements are sorted internally, select and rank queries can be trivially implemented by storing the size of each sub-tree at every node, which is then used to return the result from those queries.

\subsection{Binary Search Tries}

The previous two data structures use comparison-based algorithms to order the keys internally, e.g., searching entails comparing the keys' full length.
Radix algorithms take a different approach by examining portions of the key.
Tries are radix-based data structures where the path from the root to a particular node is the prefix of the keys stored at the sub-tree rooted at that node.
In this context, we will use them to store words (as defined in Section~\ref{sec:word}), but they can be used to store other types of data, for instance, strings, which can be of fixed or variable length.
The chosen radix is related to the data we want to store in the trie: for instance, when storing strings written with the English alphabet, the radix is 26, whereas in our case, base two integers, the radix is 2. Bitwise tries can also denote tries of radix two.

A binary search trie is a trie for storing integer words, where the keys are kept at leaf nodes. We use the bit values of a key to guide us when searching the following way: starting from the most significant bit of the key,
\begin{enumerate}
    \item
    If the bit value is zero, then we take the left child node.
    \item 
    Otherwise, we take the right one.
\end{enumerate}
We then consider the search key's following less significant bit and repeat. A search ends either at a leaf or a null link. A successful search is when the search key and the key at the node were the same. An unsuccessful search is when either we end up on a null link or the search key, and the key at the leaf node are not the same. This last case happens when those keys share a prefix.

We can infer from the search algorithm's description that this data structure uses a considerable amount of space for storing paths consisting of prefixes shared between keys.

Since this tree is ordered and balanced, and even though it will have on average $44\%$ more nodes than keys, searching and inserting take on average $O(\log_2 n)$ time for random and distinct keys, but the length of the keys bounds the worst case running time, $O(w)$ \cite{sedgewick2002algorithms}. Rank and select queries are implemented with a similar approach as in the red-black tree: every node has the number of leaf nodes stored in its fields, which is used for these queries.

\subsection{Patricia Tries}

Patricia tries, which name is acronym for "practical algorithm to retrieve information coded in alphanumeric", also known as compressed binary tries, improve the space complexity of the binary search tries.
They embody different ways to encode the same trie abstraction as binary search tries.
They achieve this by allowing the internal nodes to store keys and by compressing the paths between nodes.
Each node will have an associated index of branching bit stored: this allows us to skip the bits that belong to shared prefixes, fast forwarding to the branching bits.
The result is a trie with exactly as many nodes as there are keys, which also improves the worst running times of updating and query from $O(w)$ to $O(\log_2 n)$.

\subsection{van Emde Boas Tree}

The van Emde Boas tree data structure 

\subsection{Fusion Trees}

The fusion tree data structure is specifically designed to store integers that fit into a single machine word. As a result, on a 32-bit machine, you would use the fusion tree to store integers of up to 32 bits, and on a 64-bit machine, you would use a fusion tree to store integers of up to 64 bits.
A fusion tree is 

\subsection{Summary}

Table~\ref{tab:dataStructComparison} is a summary of relevant data structures that incrementally lead to the data structure presented in this project.

\begin{table}[H]
\centering
\input{04_Tables/001_DataStructuresComparison.tex}
\caption[Data structure comparison]{Data structures used to solve the predecessor problem and their respective theoretical running times.}
\label{tab:dataStructComparison}
\end{table}

\newpage
\section{Summary of techniques used in the present implementation}

All of the algorithms presented in this section have been implemented as static functions in the {\ttfamily Util} class.

\subsection{Bit operations} \label{sec:bit}

Let $A$ be a $w$-bit length word. This section features a set of functions that operate on $A$'s bits. Since these operations only use bit-wise shifting and masking, all the algorithms presented in this section take $O(1)$ time.

\subsubsection{Is the bit set}

This operation aims at extracting the bit at position $d$ in $A$ or, in other words, getting the value of the bit at position $d$. Let us denote such operation by $\text{bit}(d, A)$, then:
\begin{align*}
    \text{bit}(d, A) = (A \gg d) \wedge 1
\end{align*}

Example:
\begin{align*}
    w = 16\\
    d = 8\\
    A = 0101\ 110\underline{1}\ 1100\ 0111_2& \\
    \text{bit}(8,A) = (0101\ 110\underline{1}\ 1100\ 0111_2& \gg 8) \wedge 1 \\
    \cline{1-2}
    \text{bit}(8,A) = 0000\ 0000\ 0101\ 110\underline{1}_2& \\
    \wedge\ 0000\ 0000\ 0000\ 000\underline{1}_2 \\
    \cline{1-2}
    \text{bit}(8,A) = 1 &
\end{align*}

\subsubsection{Set bit}
This operation sets the bit at position $d$ in $A$ to one. Let us denote such operation by $\text{setBit}(d, A)$, then:
\begin{align*}
    \text{setBit}(d, A) = A \vee (1 \ll d)
\end{align*}

Example:
\begin{align*}
    w = 16\\
    d = 4\\
    A = 0101\ 1101\ 110\underline{0}\ 0111_2& \\
    \text{setBit}(4,A) = 0101\ 1101\ 110\underline{0}\ 0111_2& \vee (1 \ll 4) \\
    \cline{1-2}
    \text{setBit}(4,A) = 0101\ 1101\ 110\underline{0}\ 0111_2& \\
    \vee\  0000\ 0000\ 000\underline{1}\ 0000_2& \\
    \cline{1-2}
    \text{setBit}(4,A) = 0101\ 1101\ 110\underline{1}\ 0111_2&
\end{align*}

\subsubsection{Delete bit}
This operation sets the bit at position $d$ in $A$ to zero. Let us denote such operation by $\text{deleteBit}(d, A)$, then:
\begin{align*}
    \text{deleteBit}(d, A) = A \wedge \neg(1 \ll d)
\end{align*}

Example:
\begin{align*}
    w = 16\\
    d = 6\\
    A = 0101\ 1101\ 1\underline{1}00\ 0111_2& \\
    \text{deleteBit}(6,A) = 0101\ 1101\ 1\underline{1}00\ 0111_2& \wedge \neg(1 \ll 6) \\
    \text{deleteBit}(6,A) = 0101\ 1101\ 1\underline{1}00\ 0111_2&\\
    \wedge\ \neg(0000\ 0000\ 0\underline{1}00\ 0000_2&) \\
    \cline{1-2}
    \text{deleteBit}(6,A) = 0101\ 1101\ 1\underline{1}00\ 0111_2& \\
    \wedge\ 1111\ 1111\ 1\underline{0}11\ 1111_2 \\
    \cline{1-2}
    \text{deleteBit}(6,A) = 0101\ 1101\ 1\underline{0}00\ 0111_2&
\end{align*}

\subsection{Masks} \label{sec:masks}

Pătrașcu and Thorup refer constants that we will denote by masks, which are useful for bit-wise operations. In this section, we will see how we can compute them.

\begin{itemize}
    \item
    The mask $0^{w-j} 1^j_2$ consists of a word with $w-j$ significant bits set to zero, and the least $j$ significant bits set to one. It is useful for instance, to mask the first $j$ least significant bits of a word and it is computed with the expression:
    \begin{align*}
        0^{w-j} 1^j_2 = (1 \ll j) - 1
    \end{align*}
    Example:
    \begin{align*}
        w &= 16\\
        j &= 4\\
        \cline{1-2}
        0^{16-4} 1^4_2 &= (1 \ll 4) - 1\\
        &= (0000\ 0000\ 0000\ 0001_2 \ll 4) - 1\\
        &= 0000\ 0000\ 0001\ 0000_2 - 1\\
        &= \underbrace{0000\ 0000\ 0000}_{w-j}\ \underbrace{1111}_{j}{}_2
    \end{align*}
    
    \item
    The mask $1^{w-j} 0^j_2$ consists of a word with $w-j$ significant bits set to one, and the least $j$ significant bits set to zero. For instance, it is useful to mask the first $w - j$ most significant bits of a word. It is easily computed by negating the result from the previous expression:
    \begin{align*}
        1^{w-j} 0^j_2= \neg((1 \ll j) - 1)
    \end{align*}
    Example:
    \begin{align*}
        w &= 16\\
        j &= 4\\
        \cline{1-2}
        1^{16-4} 0^4_2 &= \neg((1 \ll 4) - 1)\\
        &= \neg((0000\ 0000\ 0000\ 0001_2 \ll 4) - 1)\\
        &= \neg(0000\ 0000\ 0001\ 0000_2 - 1)\\
        &= \neg0000\ 0000\ 0000\ 1111_2\\
        &= \underbrace{1111\ 1111\ 1111}_{w-j}\ \underbrace{0000}_{j}{}_2
    \end{align*}
\end{itemize}

\subsection{Fields of words} \label{sec:fieldsOfWords}

We follow the definitions from \cite{patrascu2014dynamic} in regards to viewing words as sets of fields of some length $f \leq w$. Let $A$ be a $w$-bit length word, then if $A$ is comprised of fields, analogously to bit indexing of a word, its least significant field is the rightmost one, denoted $A\langle0\rangle_f$; its most significant field is the leftmost one, denoted $A\langle f-1\rangle_f$, and so on.
Note that the functions presented in this section consist of simple bit-wise shifting and masking with the expressions defined in \ref{sec:masks}. Regarding running times, all these algorithms take $O(1)$ time.

\subsubsection{Field retrieval} \label{sec:fieldRetrieval}

This operation consists of retrieving field $A\langle i\rangle_f$ and it is denoted by $\text{getField}(i, f, A)$. It is defined by:
\begin{align*}
    \text{getField}(i, f, A) = (A \gg (i \times f)) \wedge ((1 \ll f) - 1)
\end{align*}

Example:
\begin{align*}
    i = 1\\
    f = 4\\
    A = 0101\ 1101\ \underline{1100}\ 0111_2& \\
    \text{getField}(1, 4, A) = (0101\ 1101\ \underline{1100}\ 0111_2& \gg (\underbrace{1 \times 4}_{4})) \wedge (\underbrace{(1 \ll 4) - 1}_{1111_2})\\
    \cline{1-2}
    \text{getField}(1, 4, A) = 0000\ 0101\ 1101\ \underline{1100}_2& \\
    \wedge\ 0000\ 0000\ 0000\ 1111_2& \\
    \cline{1-2}
    \text{getField}(1, 4, A) = 0000\ 0000\ 0000\ \underline{1100}_2&
\end{align*}

A range of fields can be retrieved in a single operation. We denote by $\text{getFields}(i, j, f, A)$ the operation consisting of the retrieval of the fields $\{A\langle i\rangle_f,\dots , A\langle j-1\rangle_f\}$, which is defined by:
\begin{align*}
    \text{getFields}(i, j, f, A) = (A \gg (i \times f)) \wedge ((1 \ll ((j - i) \times f)) - 1)
\end{align*}

Example:
\begin{align*}
    i = 1\\
    j = 3\\
    f = 4\\
    A = 0101\ \underline{1101}\ \underline{1100}\ 0111_2& \\
    \text{getFields}(1, 2, 4, A) = (0101\ \underline{1101}\ \underline{1100}\ 0111_2& \gg (\underbrace{1 \times 4}_{4})) \wedge (\underbrace{(1 \ll ((3 - 1) \times 4)) - 1}_{1111\ 1111_2})\\
    \cline{1-2}
    \text{getFields}(1, 2, 4, A) = 0000\ 0101\ \underline{1101}\ \underline{1100}_2&\\
    \wedge\ 0000\ 0000\ 1111\ 1111_2 \\
    \cline{1-2}
    \text{getFields}(1, 2, 4, A) = 0000\ 0000\ \underline{1101}\ \underline{1100}_2&
\end{align*}

We can also specify a lower field and retrieve all the fields from that position up to the end of the word. This is denoted by $\text{getFields}(i, f, A)$ and it is defined by:
\begin{align*}
    \text{getFields}(i, f, A) = A \gg (i \times f)
\end{align*}

Example:
\begin{align*}
    i = 2\\
    f = 4\\
    A = \underline{0101}\ \underline{1101}\ 1100\ 0111_2& \\
    \text{getFields}(2, 4, A) = \underline{0101}\ \underline{1101}\ 1100\ 0111_2& \gg (\underbrace{2 \times 4}_{8})\\
    \cline{1-2}
    \text{getFields}(1, 2, 4, A) = 0000\ 0000\ \underline{0101}\ \underline{1101}_2&
\end{align*}

\subsubsection{Field assignment}

Conversely, it is also possible to assign a value to a particular field. To do so, a mask $m$ is required, and it is computed as a function of $i$ (the position of the field to be set) and $f$ (the length of the fields in $A$). Thus we have:
\begin{align*}
    m = ((1 \ll f) - 1) \ll (i \times f)
\end{align*}
 Setting field $y$ in $A$, denoted by setField$(i, y, f, A)$ is defined by:
\begin{equation*}
    \text{setField}(i, y, f, A) = \underbrace{(A \wedge \neg m)}_{\text{(a) Reset field}} \vee \ \underbrace{(y \ll (i \times f) \wedge m)}_{\text{(b) Set field}}
\end{equation*}
Example:
\begin{align*}
    i = 1\\
    y = 1001_2\\
    f = 4\\
    m = (\underbrace{(1 \ll 4)  - 1} _{1111_2}) \ll (\underbrace{1 \times 4}_{4}) = 0000\ 0000\ 1111\ 0000_2\\
    A = 0101\ 1101\ \underline{1100}\ 0111_2& \\
    \cline{1-2}
    \text{(a)}\quad A \wedge \neg m = 0101\ 1101\ \underline{1100}\ 0111_2 \\
    \wedge\ 1111\ 1111\ 0000\ 1111_2\\
    \text{(a)}\quad = 0101\ 1101\ 0000\ 0111_2\\
    \cline{1-2}
    y \ll (1 \times 4) = 0000\ 0000\ 0000\ \underline{1001}_2& \ll 4\\
    = 0000\ 0000\ \underline{1001}\ 0000_2\\
    \text{(b)}\quad (y \ll 4) \wedge m = 0000\ 0000\ \underline{1001}\ 0000_2\\ 
    \wedge\ 0000\ 0000\ 1111\ 0000_2\\
    \text{(b)}\quad = 0000\ 0000\ \underline{1001}\ 0000_2\\
    \cline{1-2}
    \text{setField}(1, y, 4, A) = \text{(a)} \vee \text{(b)} = 0101\ 1101\ \underline{0000}\ 0111_2\\
    \vee\ 0000\ 0000\ \underline{1001}\ 0000_2 \\
    \cline{1-2}
    \text{setField}(1, y, 4, A) = 0101\ 1101\ \underline{1001}\ 0111_2&
\end{align*}

\subsection{Most significant set bit} \label{sec:msbAlgorithm}

Learning about the most significant set bit of a word will be an important operation in the implementation. For this reason, we will look at different ways to achieve this result. Since it is to be used as a subroutine in certain operations, it has the potential to become a bottleneck if not implemented carefully. We denote the most significant set bit of $x$ by msb$(x)$.

\subsubsection{Naive}

The simplest way to achieve the intended outcome is to loop through the word until the first non-zero bit is found, returning the number of iterations that it took to find that bit.

This approach takes $O(w)$ time.

\subsubsection{Lookup}

In this approach, a lookup table containing the most significant bits answers for all combinations of 8 bits is pre-computed.

When a query comes, it is iterated in fields of 8 bits, starting from the most significant field. If that field is not zero, then the most significant bit of the queried word lies in that block. In such a case, the answer will be the most significant set bit of that field plus all the bits in the non-iterated fields. Since the answer to any combination of 8 bits is pre-computed, we know the answer in constant time.

Otherwise, if the first field zero, the algorithm looks at the second most significant field and does the same operation as described in the previous paragraph.

This approach takes $O(1)$ time after the lookup table has been computed but, not only the lookup table takes time to compute, it also uses some space.

\subsubsection{Constant time with parallel comparison} \label{sec:msbO1}

This operation consists of 4 steps. Let $x$ be the query for the most significant set bit:
\begin{enumerate}
    \item
    We divide $x$ in $\sqrt{w}$ fields of $\sqrt{w}$ bits. The goal is to summarize the fields in $x$ such that if a field is not empty, then its summary is $1$ and $0$ (zero) otherwise.
    \item
    We compress the summary such that it fits in a single $\sqrt{w}$-bits field. The resulting field will have all the leading bits of the summary word consecutive.
    \item
    Then we do parallel comparison of the summary word to find the first non-empty field of $x$ because it will be on that field that the answer will lie.
    \item
    We use the same technique as in the previous bullet point, but now on the first non-empty field of $x$. We end with simple arithmetic to return the most significant set bit. 
\end{enumerate}

We will run a small example where every step will be illustrated. For simplicity, let $w=16$. This implies that we will have $\sqrt{16} = 4$ fields of $4$ bits in size each. Let us also assume that our query $x = 0101\ 0000\ 1000\ 1101_2$.

This approach takes $O(1)$ time and requires a small lookup table of $\sqrt{w}/2$ size, which can easily be explicitly stored together with the algorithm.

\paragraph{Step 1 --- Summarize the query fields} \label{sec:summaryfields}

The goal of this step is to compute a summary word whose leading bit of each of its fields is a summary of each field of the query word $x$. If in a given field $f_i$, the leading bit in the summary word is $1$, then $f_i$ in $x$ was not empty (one or more bits were set), and vice-versa.

\begin{enumerate}
    \item \label{blt:msb1}
    We start by finding $F$. $F$ is a $w$-bit word where the most significant position of every field is set to $1$ and every other position is set to $0$. In this particular example $F = 1000\ 1000\ 1000\ 1000_2$
    
    \item \label{blt:msb2}
    In a local variable $t_1$, we store information about the leading bits of each field of $x$. This is done with $x \wedge F$.
    \begin{align*}
                       x &= \underline{0}101\ \underline{0}000\ \underline{1}000\ \underline{1}101_2 \\
                       F &= 1000\ 1000\ 1000\ 1000_2 \\ \cline{1-2} 
        t_1 = x \wedge F &= \underline{0}000\ \underline{0}000\ \underline{1}000\ \underline{1}000_2
    \end{align*}
    
    \item \label{blt:msb3}
    In another local variable $t_2$, we store $x$ after setting the leading bits of each field to zero. This is done with $x \oplus t_1$.
    \begin{align*}
                         x &= 0\underline{101}\ 0\underline{000}\ 1\underline{000}\ 1\underline{101}_2 \\
                       t_1 &= 0000\ 0000\ 1000\ 1000_2 \\ \cline{1-2}
        t_2 = x \oplus t_1 &= 0\underline{101}\ 0\underline{000}\ 0\underline{000}\ 0\underline{101}_2
    \end{align*}
    
    \item \label{blt:msb4}
    We subtract $t_2$ from $F$ and save it to a local variable $t_3$. Since the leading bit of every field of $F$ is one, after subtracting $t_2$ to $F$, what remains is the information about if that field was empty (all zeros) or not. This information is given by the bit that remains at the most significant position of each resulting field. In other words, if in any given field of the resulting word, the most significant bit is one, then the corresponding field in $x$ was empty; otherwise, it was not empty.
    
    Since we only care about what remains of the most significant position of each field, in the example below, the remaining noise has been replaced with $?$.
    \begin{align*}
                    F &= 1000\ 1000\ 1000\ 1000_2 \\
                  t_2 &= 0\underline{101}\ 0\underline{000}\ 0\underline{000}\ 0\underline{101}_2 \\ \cline{1-2} 
        t_3 = F - t_2 &= \underline{0}???\ \underline{1}000\ \underline{1}000\ \underline{0}???_2
    \end{align*}
    
    \item \label{blt:msb5}
    This step consists of clearing the noise from $t_3$ since we care only about knowing which fields in $x$ were empty or not. To do so, $(\neg t_3) \wedge F$.
    \begin{align*}
                       t_3 &= \underline{0}???\ \underline{1}000\ \underline{1}000\ \underline{0}???_2 \\ \cline{1-2} 
            t_4 = \neg t_3 &= \underline{1}???\ \underline{0}111\ \underline{0}111\ \underline{1}???_2 \\
                         F &= 1000\ 1000\ 1000\ 1000_2 \\ \cline{1-2} 
        t_5 = t_4 \wedge F &= \underline{1}000\ \underline{0}000\ \underline{0}000\ \underline{1}000_2
    \end{align*}
    
    \item \label{blt:msb6}
    The value calculated in \ref{blt:msb2} for $t_1$ holds information about the leading bits of each field, whereas $t_5$ from \ref{blt:msb5} contains the information about the non-leading bits. By merging both words, the resulting word will hold information about the whole word $x$. We achieve this with $t_1 \vee t_5$.
    \begin{align*}
                       t_1 &= \underline{0}000\ \underline{0}000\ \underline{1}000\ \underline{1}000_2 \\
                       t_5 &= \underline{1}000\ \underline{0}000\ \underline{0}000\ \underline{1}000_2 \\ \cline{1-2} 
        t_6 = t_1 \vee t_5 &= \underline{1}000\ \underline{0}000\ \underline{1}000\ \underline{1}000_2
    \end{align*}
\end{enumerate}

In fact, once $F$ is known, steps \ref{blt:msb2} to \ref{blt:msb5} can be computed all at once with the expression:
\begin{equation}
    t_6 = (x \wedge F) \vee ((\neg(F - (x \oplus(x \wedge F)))) \wedge F)
\end{equation}

\paragraph{Step 2 --- Summary compression} \label{sec:summaryCompression}
% minuto 1.12: https://www.youtube.com/watch?v=xSGorVW8j6Q&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&index=12

The goal of this step is to compress the summary word down to a single field.

\begin{enumerate}
    \item \label{blt:summCompression1}
    The first step consists of shifting the leading bits of each field to the least significant position of each field. This is done with $t_6 \gg (\sqrt{w} - 1)$. 
    \begin{align*}
                    t_6 &= \underline{1}000\ \underline{0}000\ \underline{1}000\ \underline{1}000_2 \\ \cline{1-2} 
        t_7 = t_6 \gg 3 &= 000\underline{1}\ 000\underline{0}\ 000\underline{1}\ 000\underline{1}_2
    \end{align*}
    
    \item \label{blt:summCompression2}
    We wish now to copy the least significant bit of each field to a single field, keeping their relative order.
    Similarly to \ref{sec:summaryfields}.\ref{blt:msb1}, we need to find a word $C$, which, when multiplied by $t_6$, will produce the result we are looking for.
    Let $C$ be also partitioned in fields indexed $\{f_0, ..., f_{\sqrt{w} - 1}\}$ where $f_{\sqrt{w} - 1}$ is the most significant field. At every field $f_i$, the only set bit is $b_{\sqrt{w} - 1 - i}$).
    In our example $C = 0001\ 0010\ 0100\ 1000_2$.
    
    \item \label{blt:summCompression3}
    Multiplying $C$ with $t_7$ produces a result $t_8$ with all the important bits in their relative order in the most significant field. There will be some additional noise in the least significant fields, which we can easily clear by $t_8 \gg ((\sqrt{w})\cdot(\sqrt{w} - 1))$.
        \begin{align*}
                         t_7 &= 000\underline{1}\ 000\underline{0}\ 000\underline{1}\ 000\underline{1}_2 \\
                           C &= 0001\ 0010\ 0100\ 1000_2 \\ \cline{1-2} 
          t_8 = t_7 \times C &= \underline{1011}\ ????\ ????\ ????_2\\ \cline{1-2}
        x_s = t_8 \gg (16-4) &= 0000\ 0000\ 0000\ \underline{1011}_2
    \end{align*}
\end{enumerate}

\paragraph{Step 3 --- First non-empty field with parallel comparison} \label{sec:parallel}
At this stage, the goal is to compute the first non-empty field of $x$. To do so, we need to do a parallel comparison between $x_s$ (the summary of $x$'s fields) and all the $\sqrt{w}$ powers of two.

The parallel comparison consists of:
\begin{enumerate}
    \item
    Taking a query $x$ of length $l < w$, making as many copies of it as there are other vectors we wish to compare it with while padding these copies with zero. The resulting vector is stored in a word.
    
    \item
    The vectors we wish to compare $x$ with are stored in word $A$ with each of their leading bits padded with one.
    
    \item
    We take the difference between $A$ and the copies of $x$, checking how many of the padding bits remain one in $A$ after this operation. The result stands for the number of vectors in $A$ that were strictly smaller than $x$.
\end{enumerate}

Since the vector we want to compare $x_s$ with consists of $\sqrt{w}$ powers of two, then we know that we will need $\sqrt{w}\cdot(\sqrt{w} + 1)$ bits to store all such vectors. This extra bit per vector is due to the padding bit mentioned earlier. Since $\sqrt{w}\cdot(\sqrt{w} + 1) > w$, we know also that it might be necessary to do this operation in two iterations. Since a word does not hold enough bits to perform the comparison with a single word, we will split the vectors in two words: one representing the higher $\sqrt{w}/2$ powers of two, and another for the lower ones.

If the power of two vectors are sorted, this parallel comparison will be a monotone function, meaning that once the transition on the leading bit is found, the result is found. This also implies that if the result is found in the higher powers of two, then it is unnecessary to look for it in the lower end.

\begin{enumerate}
    \item \label{blt:parallel1}
    We define two bit vectors, $hi$ and $lo$, with $hi > lo$. These vectors are comprised of the concatenation of the $\sqrt{w}$ powers of two in sorted in descending order and padded with $1$. To each power of two, we have to subtract $1$ for this operation to work, because if we do not and the query is an exact power of two, the corresponding padding $1$ will not be borrowed. In our example:
    \begin{align*}
        hi &= 1\ \underbrace{0111}_{2^3-1=7}\ 1\ \underbrace{0011}_{2^2-1=3}{}_2\\
        lo &= 1\ \underbrace{0001}_{2^1-1=1}\ 1\ \underbrace{0000}_{2^0-1=0}{}_2
    \end{align*}
    
    \item \label{blt:parallel2}
    We define another vector $t_9$ consisting of $\sqrt{w}/2$ concatenated copies of $x_s$ where each of the copies is prefixed by zero. This vector is achieved by multiplying $x_s$ with a word $M$ consisting of $\sqrt{w}/2$ fields of size $\sqrt{w} + 1$ where the least significant bit of each field is set to $1$. Note that, because we have set the size of each field of $M$ to have an additional bit, this corresponds to prefix a zero to each $\sqrt{w}$ field:
    \begin{align*}
        x_s = 0000\ 0000\ 0000\ &\underline{1011}_2\\ 
        M = 0\ 0001\ 0\ &0001_2\\ \cline{1-2}
        t_9 = x_s \times M = 0\ \underline{1011}\ 0\ &\underline{1011}_2
    \end{align*}
    
    \item \label{blt:parallel3}
    To find the first non-empty field of $x$, we take the differences between $t_9$ and $hi$ and $lo$ respectively. The answer will lie one the first field which leading bit resulted in a zero after the operation.
    \begin{align*}
                          hi &= \underline{1}\ \underline{1}000\ \underline{1}\ \underline{01}00_2\\
                          lo &= \underline{1}\ \underline{001}0\ \underline{1}\ \underline{0001}_2 \\
                      t_9 &= 0\ 1011\ 0\ 1011_2\\ \cline{1-2}
        t_{10} = hi - t_9 &= \underline{0}\ ????\ \underline{0}\ ????_2 \\
        t_{11} = lo - t_9 &= \underline{0}\ ????\ \underline{0}\ ????_2
    \end{align*}
    
    \item \label{blt:parallel4}
    Looking at $t_{10}$, we note that the first non-empty field of $x$ is the most significant one because the leading bit of first field resulting from the difference between $hi$ and $t_9$ is now zero. Nevertheless, we will do the same operations on both $t_{10}$ and $t_{11}$ and concatenate the results, so we end up with a single result for the whole query. Note that in the previous step, the actual values within each field besides the leading bit are irrelevant, so we do some masking and shifting, similar to what was done in \ref{sec:summaryfields} and \ref{sec:summaryCompression}.
    \begin{enumerate}
        \item
        The first step is to clear all the irrelevant bits in the fields and turn the leading bits from zero to one. We choose a mask for this specific purpose.
        \begin{align*}
            t_{10} = \underline{0}\ ????\ \underline{0}\ ????_2&\\
            t_{11} = \underline{0}\ ????\ \underline{0}\ ????_2&\\
            Mask_1 = 1\ 0000\ 1\ 0000_2&\\ \cline{1-2}
            t_{12} = (t_{10} \wedge Mask_1) \oplus Mask_1 = \underline{1}\ 0000\ \underline{1}\ 0000_2&\\
            t_{13} = (t_{11} \wedge Mask_1) \oplus Mask_1 = \underline{1}\ 0000\ \underline{1}\ 0000_2&
        \end{align*}
        \item
        Secondly, we wish to summarize the results in a single field. To achieve so, we first multiply the vectors by an integer $V$, which construction follows what we have done for \ref{sec:summaryCompression}.\ref{blt:summCompression2}, and that result will put all the important bits consecutive in the most significant field.
        
        \begin{align*}
            t_{14} = t_{12} \gg \sqrt{w} = 0\ 000\underline{1}\ 0\ 000\underline{1}_2& \\
            t_{15} = t_{13} \gg \sqrt{w} = 0\ 000\underline{1}\ 0\ 000\underline{1}_2& \\
            \cline{1-2}
            V =\ 01000\ 10000_2 & \\
            t_{16} = t_{14} \times V =\ ???????\ \underline{11}00?\ ?????_2& \\
            t_{17} = t_{15} \times V =\ ???????\ \underline{11}00?\ ?????_2& \\
        \end{align*}
        \item
        After the multiplication, we have to remove the noise and move the result to the least significant field. We achieve this by defining another mask for this purpose, followed by the necessary bit shifts. The final step will be to merge the results of the higher and the lower powers of two: $t_{hi} \vee t_{lo}$.
        
        \begin{align*}
            Mask_2 = (1 \ll (\sqrt{w}/2)) - 1 = 11_2&\\
            t_{18} = t_{16} \wedge (Mask_2 \ll 2\cdot \sqrt{w}) =\ \underline{11}\ 0000\ 0000_2& \\
            t_{19} = t_{17} \wedge (Mask_2 \ll 2\cdot \sqrt{w}) =\ \underline{11}\ 0000\ 0000_2& \\
            \cline{1-2}
            t_{hi} = t_{18} \gg (\sqrt{w} + \sqrt{w}/2) = 00\ 0000\ \underline{11}00_2 &\\
            t_{lo} = t_{19} \gg (\sqrt{w} \cdot \sqrt{w} / 2) = 00\ 0000\ 00 \underline{11}_2 &\\
            \cline{1-2}
            t_{q} = t_{hi} \vee t_{lo} = \underline{1111}_2 &\\
        \end{align*}
    \end{enumerate}
    \item
    Note that $t_q$ can only be one of $\sqrt{w}$ possibilities: $0001_2$, $0011_2$, $0111_2$, or $1111_2$. For this reason, we implement a lookup table of size $\sqrt{w}$ for these values, which we return at the end of the method. We can even halve the size of the lookup table by applying the following trick: instead of merging $t_{hi}$ and $t_{lo}$ into a single field, shift $t_{hi}$ all the way to the right. In this scenario, $t_{hi}$ can either be $11_2$, $01_2$ or $0$. The values of the lookup table, in this case, will be only $11_2$ and $01_2$, so if $t_{hi}$ takes one of those values, we return the value in the lookup table plus a constant corresponding to the least significant positions ($\sqrt{w}/2$). Should it be $0$, then we do the lookup for $t_{lo}$ and return the corresponding value in the lookup table.
    
    In our example, since $t_{q} = 1111_2$ the result of this parallel comparison would be $3$ (three), meaning, the method should now look at $x\langle 3\rangle_4$ (the most significant field).
\end{enumerate}

\paragraph{Step 4 --- Final result}
After learning in which field lies the most significant bit, we now run the same method as in \ref{sec:parallel} but now with the actual field.

\begin{enumerate}
    \item
    We start by extracting the field from our query $x$. Let $i$ be the result returned from \ref{sec:parallel}, e.g. the index of the field. We extract $f_i$ by shifting $(\sqrt{w} - 1 - i)$ fields in $x$ to the right and bit-wise $\wedge$ the result with a mask for this purpose.
    \begin{align*}
        x = \underline{0101}\ 0000\ 1000\ 1101_2 &\\
        Mask_3 = (1 \ll \sqrt{w}) - 1 = 0000\ 0000\ 0000\ 1111_2 &\\
        \cline{1-2}
        t_{20} = (x \gg \underbrace{(\sqrt{w} \cdot (\sqrt{w} - 1 - i))}_{4\times(4-1-0)}\ \wedge\ Mask_3 = 0000\ 0000\ 0000\ \underline{0101}_2 &
    \end{align*}
    \item
    We run another parallel comparison with $0101_2$. Let $d$ be the result of computing the parallel comparison of the first non-empty field of $x$, then in our example $d = 2$.
    \item
    We can now compute the overall most significant bit of $x$. The final result is given the expression:
    \begin{equation*}
        \text{msb}(x) = d + i\cdot\sqrt{w}
    \end{equation*}
    In our example, this will evaluate to:
    \begin{equation*}
        \text{msb}(0101\ 0000\ 1000\ 1101_2) = 2 + 3\cdot\sqrt{16} = 2 + 3 \times 4 = 14
    \end{equation*}
\end{enumerate}

\subsection{Least significant set bit} \label{sec:lsbAlgorithm}

Let $\text{lsb}(x)$ denote the least significant set bit of $x$. Citing Pătrașcu and Thorup, after computing the $\text{msb}(x)$ we can in $O(1)$ time compute $\text{lsb}(x)$ with the expression:
\begin{equation*}
    \text{lsb}(x) = \text{msb}((x - 1) \oplus x)
\end{equation*}

Example:
\begin{align*}
    x = 0101\ 1101\ 1100\ 0\underline{1}00_2& \\
    x - 1 = 0101\ 1101\ 1100\ 0\underline{0}11_2& \\
    (x - 1) \oplus x = 0000\ 0000\ 0000\ 0\underline{1}00_2& \\
    \cline{1-2}
    \text{lsb}(x) = \text{msb}((x - 1) \oplus x) = \text{msb}(0000\ 0000\ 0000\ 0\underline{1}00_2&) = 2
\end{align*}

\subsection{Rank Lemma 1} \label{sec:rankLemma1}

Another important operation in the context of the implementation of the data structure presented in \cite{patrascu2014dynamic} is to compute the rank of a word. For this purpose, some subroutines are required, and the algorithm described in this section is one of them. This algorithm consists of the implementation of Lemma~\ref{lemma1} by Fredman and Willard, cited by Pătrașcu and Thorup. It reads:
\begin{lemma} \label{lemma1}
Let $m \cdot b \leq w$. If we are given a b-bit number x and a word A with m b-bit numbers stored in sorted order, that is, $A\langle 0 \rangle_b < A\langle 1 \rangle_b < \dots < A\langle m - 1 \rangle_b$, then in constant time, we can find the rank of x in A, denoted \text{rank}(x,A).
\end{lemma}
An algorithm that implements $\text{rank}(x,A)$ works as the following:
\begin{enumerate}
    \item
    Computing how many fields in $A$ have zero as their leading bit.
    
    \item
    Computing the leading bit of $x$.
    
    \item
    If the leading bit of $x$ is zero, then:
    \begin{enumerate}
        \item
        We bit-shift and mask $A$ as needed, such that the fields whose leading bit is one are no longer present in $A$.
        
        \item
        We compute a word consisting of as many concatenated copies of $x$ as there are fields left in $A$.
        
        \item
        We do parallel comparison\footnote{See Section~\ref{sec:parallel} to learn more about parallel comparison.} between (the shifted/masked) $A$ and (copies of) $x$ by setting the leading bit of each of the remaining fields of $A$ to one and computing the difference between those words.
        
        \item
        The result of rank$(x,A)$ is given by the number of fields whose leading bit is now zero because if the leading bit (that has been set to one in the previous step) is borrowed in the subtraction, then $x$ is larger than the key stored at that field.
    \end{enumerate}
    
    Otherwise, if the leading bit of $x$ is one, then:
    \begin{enumerate}
        \item
        We bit-shift and/or mask $A$ such that the fields whose leading bit is zero are no longer present in $A$, storing the number of fields removed from $A$ on a local variable.
        
        \item
		We set the leading bit of $x$ to zero and compute a word consisting of as many concatenated copies of $x$ as there are fields left in $A$.
		
		\item
        We do parallel comparison between the remaining fields in $A$ and the word we computed just before.
        
        \item
        The result of rank$(x,A)$ is given by the number of fields whose leading bit was zero just before $A$ was shifted/masked plus the number of fields whose leading bit is zero after the parallel comparison.
    \end{enumerate}
    
\end{enumerate}

This operation takes $O(1)$ time, and we will run an example of this algorithm, explaining its intricacies.

\subsubsection{Parameters}

Since this algorithm branches depending on the leading bit of the query $x$, we will run the example with two queries $x_1$ and $x_2$ such that we explore both branches of the algorithm. Let $A$ be the concatenation of the keys of $S = \{0101_2, 0110_2, 1100_2, 1110_2 \}$. Note that if key $y_i < y_j$, then $y_i$ will be present in $A$ on a lesser significant position than $y_j$.
\begin{align*}
    A &= \underbrace{1110}_{A\langle 3 \rangle_4}\ \underbrace{1100}_{A\langle 2 \rangle_4}\ \underbrace{0110}_{A\langle 1\rangle_4}\ \underbrace{0101}_{A\langle 0 \rangle_4}{}_2 \\
    x_1 &= 1100_2 \\
    x_2 &= 0111_2 \\
    b &= 4 \\
    m &= 4
\end{align*}

\subsubsection{Step 1 --- Computing which fields have zero as their leading bit} \label{sec:computeM}

Since the keys in $A$ are sorted, we know that finding the position the least significant field whose first bit is one in $A$ will tell us how many fields there are with zero at their leading bit.

\begin{enumerate}
    \item
    We start by finding $M$. $M$ consists of a word with $m$ fields of $b$-bits, where each field is filled with zeroes excluding the least significant bit, which is set to one. In this particular example $M = 0001\ 0001\ 0001\ 0001_2$.
    
    \item % A & (M << (b - 1))
    We mask the non-leading bits of each field of $A$. This is achieved with:
    \begin{align*}
        A \wedge (M \ll (b - 1))
    \end{align*}
    
    Thus we have:
    \begin{align*}
        M &= 0001\ 0001\ 0001\ 0001_2 \\
        t_1 = M \ll (b - 1) &= 1000\ 1000\ 1000\ 1000_2 \\
        A &= \underline{1}110\ \underline{1}100\ \underline{0}110\ \underline{0}101_2 \\
        \cline{1-2}
        t_2 = A \wedge t_1 &= \underline{1}000\ \underline{1}000\ \underline{0}000\ \underline{0}000_2
    \end{align*}
    
    \item
    Computing lsb$(t_2)$ will give us the index of leading bit of the least significant field whose leading bit is one. Dividing the previous result by the field size $b$ will then give us the  field position results in total number of fields in $A$ whose leading bit is zero. In this particular example:
    \begin{align*}
        &\text{lsb}(t_2) = \text{lsb}(1000\ \underline{1}000\ 0000\ 0000_2) = 11 \\
        &t_3 = \frac{\text{lsb}(t_2)}{b} = \frac{11}{4} = 2 \\
    \end{align*}
\end{enumerate}

\subsubsection{Step 2 --- Computing the leading bit of the query}
In order to extract the value of the leading bit of our queries $x_1$ and $x_2$, we resort to the algorithm of section~\ref{sec:bit}. The leading bit of the query will be at position $b - 1$, thus we have for $x_1$:
\begin{align*}
    x_1 = \underline{1}100&_2\\
    \text{bit}(b - 1, x_1) = \text{bit}(3, x_1) = 1\\
\end{align*}
And for $x_2$:
\begin{align*}
    x_2 = \underline{0}111&_2\\
    \text{bit}(b - 1, x_2) = \text{bit}(3, x_2) = 0\\
\end{align*}

\subsubsection{Step 3 --- Computing rank with parallel comparison}

We will now run the algorithm for each of its branches. If the leading bit of the query is one, then we run the first branch; otherwise, the second.
\begin{itemize}
    \item
    In this branch our query is $x_1 = 1100_2$:
    \begin{enumerate}
        \item
        Since the leading bit of our query $x_1$ is one, we know now that its rank in $A$ is at least the number of fields in $A$ whose leading bit is zero. So we proceed by removing those fields from $A$, and for this purpose we resort to the getFields$(i, f, A)$ defined in Section~\ref{sec:fieldRetrieval}. In our example:
        \begin{align*}
            A &= \underline{1110}\ \underline{1100}\ 0110\ 0101_2 \\
            t_3 &= 2 \\
            A := \text{getFields}(t_3, b, A) &= 0000\ 0000\ \underline{1110}\ \underline{1100}_2 \\
        \end{align*}
        
        \item
        We apply the same principle to the $M$ word by doing the very same operation as just before.
        \begin{align*}
            M &= \underline{0001}\ \underline{0001}\ 0001\ 0001_2 \\
            t_3 &= 2 \\
            \cline{1-2}
            M := \text{getFields}(t_3, b, M) &= 0000\ 0000\ \underline{0001}\ \underline{0001}_2 \\
        \end{align*}
        
        \item
        We set the leading bit of $x_1$ to zero and multiply it by $M$ to produce a word containing concatenated copies of $x_1$.
        \begin{align*}
            x_1 = 1100_2 \\
            M = 0000\ 0000\ \underline{0001}\ \underline{0001}_2 \\
            \cline{1-2}
            x_1 := \text{deleteBit}(b - 1, x_1) = 0100_2 \\
            \cline{1-2}
            x_1 := x_1 \times M = 0000\ 0000\ \underline{0100}\ \underline{0100}_2 \\
        \end{align*}
        
        \item
        The last ingredient needed for the parallel comparison is a mask comprised of a word whose leading bit of each field is one. Shifting $M$ by $b - 1$ positions to the left will produce such result.
        \begin{align*}
            M = 0000\ 0000\ 000\underline{1}\ 000\underline{1}_2& \\
            \cline{1-2}
            M := M \ll (b - 1) = 0000\ 0000\ \underline{1}000\ \underline{1}000_2& \\
        \end{align*}
        
        \item
        We take the difference between $A$ and $x$ and mask out the bits at all positions except the leading bits of each field in the resulting word.
        \begin{align*}
            A &= 0000\ 0000\ 1\underline{110}\ 1\underline{100}_2 \\
            x_1 &= 0000\ 0000\ 0\underline{100}\ 0\underline{100}_2 \\
            M &= 0000\ 0000\ \underline{1}000\ \underline{1}000_2 \\
            \cline{1-2}
            A - x_1 &= 0000\ 0000\ \underline{1}???\ \underline{1}???_2 \\
            d_1 = (A - x_1) \wedge M &= 0000\ 0000\ \underline{1}000\ \underline{1}000_2 \\
        \end{align*}
        
        \item
        To learn how many of the remaining of fields in $A$ that are smaller than $x_1$, we compute lsb($d_1$) and divide it by $b$.
        \begin{align*}
            d_1 = 0000\ 0000\ 1000\ \underline{1}000_2 \\
            \text{lsb}(d_1) = 3 \\
            b = 4 \\
            \cline{1-2}
            t_4 = \frac{\text{lsb}(d_1)}{b} = \frac{3}{4} = 0 
        \end{align*}
        
        \item
        Computing rank$(x_1, A)$ consists of returning the number of fields in $A$ that are strictly smaller than $x$. In this specific context, we know that all fields whose leading bit is zero are smaller than $x_1$, and we have also just computed the number of fields whose leading bit is one but that are still smaller than $x_1$. So we just add those results, and we have:
        \begin{align*}
            \text{rank}(x_1, A) &= t_3 + t_4 = 2 + 0 \\
            \text{rank}(x_1, A) &= 2
        \end{align*}
        
    \end{enumerate}
    \item
    In this branch our query is $x_2 = 0111_2$:
    \begin{enumerate}
        \item
        Since the leading bit of our query $x_2$ is zero, we can safely disregard the fields in $A$ whose leading bit is one. Similarly to what was done in the first branch, $M$ suffers a similar change, and we will start with that by using the getFields$(i, j, f, A)$ function defined in Section~\ref{sec:fieldRetrieval}. Thus we have:
        \begin{align*}
            M &= 0001\ 0001\ \underline{0001}\ \underline{0001}_2 \\
            t_3 &= 2 \\
            \cline{1-2}
            M := \text{getFields}(0, t_3, b, M) &= 0000\ 0000\ \underline{0001}\ \underline{0001}_2 \\
        \end{align*}
        
        \item
        We need to have as many concatenated copies of $x_2$ as there are fields in $A$ whose leading bit is zero. So we multiply $M$ by $x_2$ and we end with:
        \begin{align*}
            x_2 = 0111_2 \\
            M = 0000\ 0000\ \underline{0001}\ \underline{0001}_2 \\
            \cline{1-2}
            x_2 := x_2 \times M = 0000\ 0000\ \underline{0111}\ \underline{0111}_2 \\
        \end{align*}
        
        \item
        As before, we need a mask to perform the parallel comparison. So we use the same technique as in the other branch and shift $M$ by $b-1$ positions to the left:
        \begin{align*}
            M = 0000\ 0000\ 000\underline{1}\ 000\underline{1}_2& \\
            \cline{1-2}
            M := M \ll (b - 1) = 0000\ 0000\ \underline{1}000\ \underline{1}000_2& \\
        \end{align*}
        
        \item
        Lastly, for the last ingredient of the parallel comparison, we discard the fields in $A$ whose leading bit is one, and set the leading bit of remaining fields to one. Thus we have:
        \begin{align*}
            A = &\ 1110\ 1100\ \underline{0110}\ \underline{0101}_2 \\
            t_3 = &\ 2 \\ 
            M = &\ 0000\ 0000\ \underline{1}000\ \underline{1}000_2 \\
            \cline{1-2}
            A := \text{getFields}(0, t_3, b, A) = &\ 0000\ 0000\ \underline{0110}\ \underline{0101}_2 \\
            \cline{1-2}
            A := M \vee A = &\ 0000\ 0000\ \underline{1}000\ \underline{1}000_2 \\
            \vee &\ 0000\ 0000\ \underline{0}110\ \underline{0}101_2 \\
            \cline{1-2}
            A = &\ 0000\ 0000\ \underline{1}110\ \underline{1}101_2
        \end{align*}
        
        \item
        We take the difference between $A$ and $x_2$ and mask out the bits at all positions except the leading bits of each field in the resulting word.
        \begin{align*}
            A &= 0000\ 0000\ 1\underline{110}\ 1\underline{101}_2 \\
            x_2 &= 0000\ 0000\ \underline{0111}\ \underline{0111}_2 \\
            M &= 0000\ 0000\ \underline{1}000\ \underline{1}000_2 \\
            \cline{1-2}
            A - x_2 &= 0000\ 0000\ \underline{0}???\ \underline{0}???_2 \\
            d_2 = (A - x_2) \wedge M &= 0000\ 0000\ \underline{0}000\ \underline{0}000_2 \\
        \end{align*}
        
        \item
        Note that $d_2$ is zero. Since there are no set bits in $d_2$ then $x_2$ is larger than all $x_2$ must be larger than all the remaining fields in $A$, so we just return $t_2$.
        \begin{align*}
            \text{rank}(x_2,A) &= t_3 = 2
        \end{align*}
        
    \end{enumerate}
\end{itemize}

\chapter{Implementation of theoretically optimal dynamic rank, select, and predecessor data structure}

% \subsection{Code base navigation}

All the implementing classes described in this section can be found in the {\ttfamily src\textbackslash java\textbackslash integersets} folder. The files names are self-explanatory, e.g., the {\ttfamily BinarySearchTrie.java} file implements the {\ttfamily BinarySearchTrie} whereas {\ttfamily RankSelectPredecessorUpdate.java} implements the {\ttfamily RankSelectPredecessorUpdate} interface.

Note that all the functions and implementations consider the integer keys as unsigned integers.

\section{Utility functions}

This project features a class, {\ttfamily Util}, which implements static utility functions. Below find listed the functions included in this class, together with a brief explanation. The class also includes 32 and 64-bit versions for the input word, making the method signature different solely on the input word type.
For brevity, the 32-bit version is omitted.

\subsection{Bit operations}
The algorithms which these functions implement are described in Section~\ref{sec:bit}.
The functions included are:

\begin{itemize}
    \item
    The method below returns the value of the bit at position $d$ in $A$. It is enforced that $d \in [0, w[$.
    \begin{lstlisting}
public static int bit(final int d, final long A)
    \end{lstlisting}
    
    \item
    The method below sets the bit at index $d$ in $A$ to 1 and returns $A$ after the change. If the bit was already 1 or if the provided index $d \not\in [0, w[$, then the function has no effect.
    \begin{lstlisting}
public static int setBit(final int d, int A)
    \end{lstlisting}
    
    \item
    The method below sets the bit at index $d$ to 0 and returns $A$ after the change. If the bit was already 0 or if the provided index $d \not\in [0, w[$, then the function has no effect.
    \begin{lstlisting}
public static int deleteBit(final int d, int A)
    \end{lstlisting}
\end{itemize}

\subsection{Fields of words}
The algorithms which these functions implement are described in Section~\ref{sec:fieldsOfWords}.
The functions included are:

\begin{itemize}
    \item
    The method below returns $A\langle i\rangle_f$. It is enforced that $f \in [0, w]$ and $i \times f \in [0, w]$.
    \begin{lstlisting}
public static long getField(final int i, final int f, final long A)
    \end{lstlisting}
    
    \item
    The method below returns $A\langle i, j \rangle_{g \times f}$. It is enforced that $f \in [0, w]$, $g < f$ and $i \times g + j \in [0, w]$.
    \begin{lstlisting}
public static int getField2d(final int i, final int j, final int g, final int f, final int A)
    \end{lstlisting}
    
    \item
    The method below returns the range of fields $A\langle i \dots j \rangle_f$. It is enforced that $f \in [0, w]$, $i \times f \in [0, w]$, $j \times f \in [0, w]$, $i < j$, and $f \cdot (j - i) < w$.
    \begin{lstlisting}
public static long getFields(final int i, final int j, final int f, final long A)
    \end{lstlisting}
    
    \item
    The method below returns the range of fields $A\langle i \dots * \rangle_f$. It is enforced that $f \in [0, w]$ and $i \times f \in [0, w]$.
    \begin{lstlisting}
public static long getFields(final int i, final int f, final long A)
    \end{lstlisting}
    
    \item
    The method below sets $A\langle i \rangle_f := y$ and returns $A$ after the change. It is enforced that $f \in [0, w]$ and $i \times f \in [0, w]$. Only the bits in $y\langle 0 \rangle_f$ are considered.
    \begin{lstlisting}
public static int setField(final int i, final int y, final int f, final long A)
    \end{lstlisting}
\end{itemize}

\subsection{String representation of an integer in binary}

\begin{itemize}
    \item
    The method below returns a string representation of integer $x$ in binary prefixed by {\ttfamily 0b}, including leading zeros (and suffixed by {\ttfamily l} if it is a 64-bit integer).
    \begin{lstlisting}
public static String bin(final long x)
    \end{lstlisting}
    
    \item
    The method below returns a string representation of integer $x$ in binary prefixed by {\ttfamily 0b}, including leading zeros, spaced by {\ttfamily \_} every $f$ bits counting from the least significant bit (and suffixed by {\ttfamily l} if it is a 64-bit integer).
    \begin{lstlisting}
public static String bin(final long x, final int f)
    \end{lstlisting}
\end{itemize}

\subsection{Helper functions}

\begin{itemize}
    \item
    The method below implements a helper function for the {\ttfamily rankLemma1} method, returning the index of the transition from zero to one in $field$, e.g., which powers of two are smaller than the input $field$.
    \begin{lstlisting}
private static int parallelComparison(final long cluster)
    \end{lstlisting}

    \item
    This method is a helper function for the {\ttfamily parallelComparison} method, and simply returns the value associated with a given $pow$ in a small lookup table.
    \begin{lstlisting}
private static int parallelLookup(final int pow)
    \end{lstlisting}
    
    \item
    The method below is a helper method for the most significant set bit lookup functions, as described in \cite{bittricks}\footnote{The following link redirects you to the function I took inspiration from: \url{https://graphics.stanford.edu/~seander/bithacks.html\#IntegerLogLookup}} and mentioned below. It populates a lookup table, allowing these functions to return the result quickly. 
    \begin{lstlisting}
private static void generateLookupTable()
    \end{lstlisting}
\end{itemize}

\subsection{Most and least significant set bit}

The algorithms which these functions implement are described in Sections~\ref{sec:msbAlgorithm} and \ref{sec:lsbAlgorithm}.
The functions included are:

\begin{itemize}
    \item
    The method below returns the index of the most significant set bit of the target $x$. It is used as a subroutine in many other functions. The actual operation used to compute the result can be easily changed in the body of the method by altering the function that is called. The version featured with this report calls {\ttfamily msbConstant}, defined a few bullet points below.
    \begin{lstlisting}
public static int msb(final long x)
    \end{lstlisting}
    
    \item
    The method below returns the index of the least significant set bit of $x$.
    \begin{lstlisting}
public static int lsb(final long x)
    \end{lstlisting}
    
    \item
    The method below returns the index of the most significant set bit of $x$ by calling a Java standard library function and computing the result with an expression.
    \begin{lstlisting}
public static int msbLibrary(final long x)
    \end{lstlisting}
    
    \item
    The method below implements a naive algorithm for computing the index of the most significant set bit of the target $x$, as described in \cite{bittricks}\footnote{The following link redirects you to the function I took inspiration from: \url{https://graphics.stanford.edu/~seander/bithacks.html\#IntegerLogObvious}}.
    \begin{lstlisting}
public static int msbObvious(long x)
    \end{lstlisting}
    
    \item
    The method below implements a lookup algorithm for computing the index of the most significant set bit of the target $x$, as described in \cite{bittricks}\footnote{The following link redirects the reader to the function I took inspiration from: \url{https://graphics.stanford.edu/~seander/bithacks.html\#IntegerLogLookup}}. For 64-bit integers, the function first splits the integer in two, calling the 32-bit method on the high half first, and then on the second in the first half is zero.
    \begin{lstlisting}
public static int msbLookupDistributedInput(final long x)
    \end{lstlisting}

    \item
    The method below implements the algorithm from Section~\ref{sec:msbO1}, which follows the lecture noted from \cite{erikdemainelec12} and \cite{nelsonjelanilec2}.
    \begin{lstlisting}
public static int msbConstant(long x)
    \end{lstlisting}
    
\end{itemize}

\subsection{Rank Lemma 1} \label{sec:rankLemma1Implementation}

The method below implements $\text{rank}(x,A)$ from Section~\ref{sec:rankLemma1}.
\begin{lstlisting}
public static int rankLemma1(long x, long A, final int m, final int b)
\end{lstlisting}
The input parameters are:
\begin{itemize}
    \item
    A query $x$, the integer to find the rank in $A$.
    
    \item
    A word $A$, containing keys with the same size as $x$, which must be sorted for the method to return a sound result.
    
    \item
    The number of keys in $A$, $m$.
    
    \item
    The length of each key in $A$, $b$, in bits.
\end{itemize}

\subsection{Additional Utility Functions}

\begin{itemize}
    \item
    The method below takes a 64-bit integer $x$ and returns a two-entry array, each position containing 32 of the 64 bits of $x$. The least significant bits of $x$ will be at index 0, whereas the most significant bits will be at position 0.
    \begin{lstlisting}
public static int[] splitLong(final long x)
    \end{lstlisting}
    
    \item
    The method below computes the reverse of the method just above. It takes a 32-bit integer array and combines its first two positions into a single 64-bit integer. Again, position 0 of the input array is used for the least significant bits of the resulting 64-bit integer, whereas position one will populate the remaining 32 most significant positions.
    \begin{lstlisting}
public static long mergeInts(final int[] x)
    \end{lstlisting}
    
    \item
    The helper method below produces a word comprised of $w / b$ fields of $b$ bits in length, having each field its least significant bit set to 1. E.g., the resulting word will have the bits at index zero and every $b$-th index set to 1.
    \begin{lstlisting}
public static long M(final int b, final int w)
    \end{lstlisting}

    \item
    The helper method below returns a string representation of interpreting the matrix stored in the word $A$, with $\#rows$ rows and $\#columns$ columns.
    \begin{lstlisting}
public static String matrixToString(final int rows, final int columns, final long A)
    \end{lstlisting}
    
    \item
    The helper method below returns an array containing $n$ distinct {\ttfamily long} keys between 0 and $bound$ (exclusive) produced with seed $seed$ and sorted with an unsigned comparator.
    \begin{lstlisting}
public static long[] distinctBoundedSortedLongs(final int n, final long bound, final long seed)
    \end{lstlisting}
    
    \item
    The helper method below returns an array containing $n$ distinct {\ttfamily long} keys between 0 and $bound$ (exclusive) produced with the default seed $42$ and sorted with an unsigned comparator.
    \begin{lstlisting}
public static long[] distinctBoundedSortedLongs(final int n, final long bound)
    \end{lstlisting}
    
    \item
    The helper method below returns an array containing $n$ distinct {\ttfamily long} keys between 0 and the maximum unsigned value (exclusive) produced with the seed $seed$ and sorted with an unsigned comparator.
    \begin{lstlisting}
public static long[] distinctSortedLongs(final int n, final long seed)
    \end{lstlisting}
    
    \item
    The helper method below returns an array containing $n$ distinct {\ttfamily long} keys between 0 and the maximum unsigned value (exclusive) produced with the default seed $42$ and sorted with an unsigned comparator.
    \begin{lstlisting}
public static long[] distinctSortedLongs(final int n)
    \end{lstlisting}
\end{itemize}

\newpage
\section{The {\ttfamily RankSelectPredecessorUpdate} interface}

As stated in Section~\ref{sec:predecessorProblem}, the data structure presented in \cite{patrascu2014dynamic} solves the dynamic predecessor problem. For this reason, an interface denoted {\ttfamily RankSelectPredecessorUpdate} was implemented with the method signatures and default methods:
\begin{itemize}
    \item
    The $\text{insert}(x)$ operation sets $S=S \cup \{x\}$ and it is to be implemented by a method with the signature:
    \begin{lstlisting}
void insert(long x);
    \end{lstlisting}
    
    \item
    The $\text{delete}(x)$ operation sets $S=S \setminus \{x\}$ and is to be implemented by a method with the signature:
    \begin{lstlisting}
void delete(long x);
    \end{lstlisting}
    
    \item
    The $\text{member}(x)$ operation returns $[x \in S]$ and it is implemented as a default method, making all implementing classes automatically inheriting the method:
    \begin{lstlisting}
default boolean member(final long x) {
    if (isEmpty()) {
        return false;
    }
    final Long res = successor(x);
    return res != null && res == x;
}
    \end{lstlisting}

    \item
    The $\text{predecessor}(x)$ operation returns $\text{max}\{y\in S\ |\ y < x\}$ and it is implemented as a default method, making all implementing classes automatically inheriting the method:
    \begin{lstlisting}
default Long predecessor(long x) {
    return select(rank(x) - 1);
}
    \end{lstlisting}

    \item
    The $\text{successor}(x)$ operation returns $\text{min}\{y\in S\ |\ y \geq x\}$ and it is implemented as a default method, making all implementing classes automatically inheriting the method:
    \begin{lstlisting}
default Long successor(long x) {
    return select(rank(x));
}
    \end{lstlisting}

    \item
    The $\text{rank}(x)$ operation returns $\#\{ y \in S\ |\ y < x\}$ and it is to be implemented by a method with the signature:
    \begin{lstlisting}
long rank(long x);
    \end{lstlisting}

    \item
    The $\text{select}(i)$ operation returns $y \in S$ with $rank(y) = i$ and it is to be implemented by a method with the signature:
    \begin{lstlisting}
Long select(long rank);
    \end{lstlisting}
\end{itemize}
Additionally, the following method signatures are included in the interface:
\begin{itemize}
    \item
    A {\ttfamily size()} method that returns the current number of keys in the set:
    \begin{lstlisting}
long size();
    \end{lstlisting}

    \item
    An {\ttfamily isEmpty()} default method that returns {\ttfamily true} if the set is empty and {\ttfamily false} otherwise:
    \begin{lstlisting}
default boolean isEmpty() {
    return size() == 0;
}
    \end{lstlisting}

    \item
    A {\ttfamily reset()} method that removes all current elements from the set:
    \begin{lstlisting}
void reset();
    \end{lstlisting}
\end{itemize}

Note that some of the methods return a primitive type, whereas some others return a boxed type. This is because some queries are not mapped to any answer, and the boxed type provides the perfect way to model this kind of scenario: in such a situation, {\ttfamily null} is returned.

\section{Naive implementation}
We start with a naive implementation of name {\ttfamily NaiveDynamicFusionNode}. It holds a $key$ array to store the keys, and a counter for the current number of keys in the data structure. The keys can be any 64-bit integer.

The basic idea behind this implementation is to store the keys in $key$, making their respective rank the same as their index in that array. In other words, $key$ is always sorted.

Updates, e.g., insert and delete, take $O(n)$ time. This is because whenever a key is inserted, its rank $i$ is found, and the key at that position as well as all following keys up to $n-1$ are updated. Since any given key index in $key$ is its rank, all the keys with rank larger than the new key have to be moved one position to the right in $key$ to make room for the new key and keeping rank consistent.

A rank query takes $O(\log_2(n))$ because a binary search is performed on $key$. Select is faster: $O(1)$, because we need only to access and return the key at position $i$ in $key$ to fulfill the query.

\newpage
\section{Dynamic Fusion Node with binary search for Rank} \label{sec:DynamicFusionNodeBinaryRank}
We take a step forward by improving the previous idea: this time, two additional words, $index$ and $bKey$, are kept in the fields. The goal is to use the concepts described in the \textit{Indexing} section of \cite{patrascu2014dynamic} to implement this data structure. The running times will be $O(\log_2 n)$ for updating and querying, and this is because the $rank$ operation resorts to binary search to produce the result.

We interpret $bKey$ as an array where the values first $k$ bits correspond to the positions in $key$. Like any other word, the bits in $bKey$ are indexed from $0$ to $k-1$, and if the $i^{th}$ bit is set to $1$, then position $i$ in $key$ is free to store a key, and vice-versa.

We interpret $index$ as an array of $k$ entries of $\lceil \log_2 k \rceil$ bits in length. It indexes the keys in $key$ by their rank the following way: Let $i$ be the rank of a key in the the set, then $index\langle i\rangle_{\lceil \log_2 k \rceil}$ will have the index in $key$ of the key with rank $i$. In order to maximize the use of the number of bits in $index$, and knowing that our program is working with 64-bit integers, we can solve the following equation:
\begin{align*}
    k \cdot \log_2(k) &\leq 64 \\
    \iff k &\leq 16
\end{align*}
If $k = 16$, then $\lceil \log_2(k) \rceil = 4$. Each $\lceil \log_2(k) \rceil$-bit field of $index$ stores the index of the key in $key$ in their sorted order.
It is important to note that \cite{patrascu2014dynamic} mentions only that $k$ has to be a power of two. The implementation allows for $k$ to take other values just as long as they are smaller than $16$ and a power of two.

\subsection{Fields} \label{sec:binaryRankFields}
The class holds the following fields:
\begin{itemize}
    \item
    The class constants $k$ and $\lceil \log_2(k) \rceil$:
    \begin{lstlisting}
private static final int k = 16;
private static final int ceilLgK = (int) Math.ceil(Math.log10(k)/Math.log10(2));
    \end{lstlisting}

    \item
    The array of keys, $key$:
    \begin{lstlisting}
private final long[] key = new long[k];
    \end{lstlisting}
    
    \item
    The $index$ word:
    \begin{lstlisting}
private long index;
    \end{lstlisting}

    \item
    The map of over empty entries in $key$, $bKey$:
    \begin{lstlisting}
private int bKey;
    \end{lstlisting}
    Note that only the first $k$ bits are relevant for any given instance.
    
    \item
    An integer $n$, containing the current number of keys in the set:
    \begin{lstlisting}
private int n;
    \end{lstlisting}
\end{itemize}

\subsection{Helper methods} \label{sec:binaryRankHelperMethods}
\begin{itemize}
    \item
    {\ttfamily firstEmptySlot()} returns the first available spot in $key$ by computing $\text{lsb}(bKey)$. Since only the first $k$ spots are valid results, a check is done to see if this result is within the range, returning $-1$ if not.
    
    \item
    {\ttfamily fillSlot(final int j)} sets position $j$ in $bKey$ to not empty. This is done with a call to $\text{deleteBit}(j, bKey)$.
    
    \item
    {\ttfamily vacantSlot(int j)} sets the $j^{th}$ position of $bKey$ to empty by calling $\text{setBit}(j, bKey)$.
    
    \item
    {\ttfamily getIndex(final long i)} returns the index in $key$ of the key with rank $i$. This operation is done with a call to $\text{getField}(i, \lceil \log_2 k\rceil, index)$.
    
    \item
    The purpose of the overloaded method {\ttfamily updateIndex} is to maintain the correspondence between the rank of the keys in the set and their position in $key$.
    The version with {\ttfamily updateIndex(final int i)} signature removes rank $i$ from $index$, whereas the {\ttfamily updateIndex(final int i, final int slot)} inserts in $index$ at position $i$ the index in $key$ (here denoted by $slot$). Both versions make calls to the $\text{getFields}$ methods with the adequate parameters, merge the results with bit-wise $\vee$ and write those back in $index$.
    
    \item
    {\ttfamily binaryRank(final long x)} returns the rank of $x$ in the set, using {\ttfamily select(final long rank)} as a subroutine. As the name implies, the algorithm used in this implementation is binary search.
\end{itemize}

\subsection{Implementation of the interface methods} \label{sec:binaryRankInterfaceImplementation}
\begin{itemize}
    \item \label{sec:binaryRankInsert}
    {\ttfamily insert(final long x)}:
    \begin{enumerate}
        \item
        If the $x$ is already in the set, or if the node has reached its limit ($k$), the method does not progress.
        
        \item
        The rank of the $x$ in the set is found with a call to  $\text{rank}(x)$ and stored in a local variable $i$.
        
        \item
        The first available spot in $key$ is found with a call to {\ttfamily firstEmptySlot()} and stored in a local variable $j$.
        
        \item
        We store $x$ in $key$ at the position returned by {\ttfamily firstEmptySlot()}.
        
        \item
        We set the position taken $x$ in $key$ to not empty by calling {\ttfamily fillSlot(j)}.
        
        \item
        We update the $index$ to reflect the new key's insertion with a call to {\ttfamily updateIndex(i, j)}.
        
        \item
        Lastly, we increment $n$ by one, updating the current total number of keys in the set.
    \end{enumerate}
    
    \item
    {\ttfamily delete(final long x)}:
    \begin{enumerate}
        \item
        If the $x$ is not in the set, the method does not progress. This is done with a call to $\text{member}(x)$.
        
        \item
        The rank of the $x$ in the set is found with a call to $\text{rank}(x)$ and stored in a local variable $i$.
        
        \item
        $bKey$ is updated by making the spot taken by $x$ in $key$ empty. This is done with the call {\ttfamily vacantSlot(getIndex(i))}.
        
        \item
        We update the $index$ to reflect the deletion of $x$ with a call to {\ttfamily updateIndex(i)}.
        
        \item
        Lastly, we decrement $n$ by one, updating the current total number of keys in the set.
    \end{enumerate}
    
    \item
    {\ttfamily rank(final long x)} returns the rank of $x$ in the set by calling the {\ttfamily binaryRank(final long x)} helper method.
    
    \item
    {\ttfamily select(final long rank)} starts by checking if the $rank$ is within range, returning {\ttfamily null} if not. Then it calls {\ttfamily getIndex(rank)} and returns the key at that position in $key$.
    
    \item
    {\ttfamily size()} returns the value of $n$.
    
    \item
    {\ttfamily reset()}.
    Resetting the set is easily done by setting $n$ to zero and $bKey$ to $-1$ (because $-1$ has all the bits set to one in its two's complement binary representation).
\end{itemize}

\subsection{Example}

The \textit{Indexing} technique combined with binary rank are best understood with an example, which we showcase in this section.


Assume that we have instantiated a {\ttfamily DynamicFusionNodeBinaryRank} and, for brevity, let $k = 8$. Then:
\begin{align*}
    k = 8 \implies \lceil \log_2 k \rceil = 3
\end{align*}

These will remain constant and are stored as static fields:
\begin{lstlisting}
private static final int k = 8;
private static final int ceilLgK = (int) Math.ceil(Math.log10(k) / Math.log10(2));
\end{lstlisting}

Assume that at this point the above-mentioned instance contains the keys from expression \ref{eq:keysInSet}, thus the mentioned instance maps to $S$.
\begin{equation} \label{eq:keysInSet}
    S = \{10, 12, 42, -1337, -42 \}
\end{equation}

The order in which keys are inserted will influence the order in which they will appear in the instance variable $key$. But, as mentioned in Section~\ref{sec:DynamicFusionNodeBinaryRank}, the instance variable $index$ will index the key indices in $key$ by their rank whereas the bit values of $bKey$ will specify if the corresponding position in $key$ is empty. Thus a possible state for the instance is the following:

\begin{figure}[H]
\centering
\input{04_Tables/029_indexKeyBKey.tex}
\caption[Set $S$ represented by the state of the instance variables]{Set $S$ represented as the $index$, $bKey$ and $key$ instance variables in a {\ttfamily DynamicFusionNodeBinaryRank} instance}
\label{fig:stateOfTheInstance}
\end{figure}

\subsubsection{Querying}

\paragraph{Select}
Let $i$ be the rank of the key we wish to query. Then
\begin{align*}
\text{select}(i) = key[ index\langle i\rangle_{\lceil \log_2 k \rceil}]
\end{align*}
Assume we wish to know the key with rank 2, then:
\begin{align*}
    i = 2 \\
    index\langle 2\rangle_3 = 110_2 = 6 \\
    \cline{1-2}
    \text{select}(2) = key[6] = 42
\end{align*}

\paragraph{Rank}
As previously mentioned, at this point, the rank operation has been implemented with binary search using select as a subroutine. This works in $O(\log_2 n)$ time because select queries take $O(1)$ time, the select method allows us to access the keys as if they were stored in their respective sorted order and therefore the running time is bound by the binary search algorithm itself.

\subsubsection{Updating}

\paragraph{Insert} \label{sec:binaryRankInsertExample}

Let $x = -1000$ be the key we wish to insert and $S$ the set we wish to insert it in, defined in expression~\ref{eq:keysInSet} and figure~\ref{fig:stateOfTheInstance}. The insertion of $x$ in $S$ on this data structure is comprised of the following:
\begin{enumerate}
    \item
    We check if $x$ is already in the set, returning in such a case.
    This is not the case, so we proceed.
    
    \item
    Then we check if the set has room for the new key by comparing {\ttfamily size()} with $k$. If it is full, then an exception is thrown.
    This is not the case, so we proceed.
    
    \item
    We compute $\text{rank}(x)$ and store it in a local variable $i$.
    \begin{align*}
        x = -1000 \\
        \cline{1-2}
        i := \text{rank}(-1000) = 4
    \end{align*}
    
    \item
    We find the first empty position in $key$ with a call to {\ttfamily firstEmptySlot()}, storing the result in a local variable $j$.
    \begin{align*}
        j := \text{{\ttfamily firstEmptySlot()}} = 2
    \end{align*}
    
    \item
    We store $x$ in $key$ at position $j$. We can see $key$ after this update on table~\ref{tab:keyAfterInsertion}.
    \begin{table}[H]
    \centering
    \input{04_Tables/030_keyAfterInsertion.tex}
    \caption[Example $key$ after the insertion of a new key]{Instance variable $key$ after setting $key[2] = -1000$}
    \label{tab:keyAfterInsertion}
    \end{table}
    
    \item
    We mark position $j$ as not empty, thus having table~\ref{tab:bKeyAfterInsertion} as the resulting $bKey$. This is done with the call {\ttfamily fillSlot(j)}.
    \begin{table}[H]
    \centering
    \input{04_Tables/031_bKeyAfterInsertion.tex}
    \caption[Example $bKey$ after the insertion of a new key]{Instance variable $bKey$ after marking position 2 as not empty}
    \label{tab:bKeyAfterInsertion}
    \end{table}
    
    \item
    With $i$ and $j$, we can now update $index$ such that the indices of the keys are once again sorted by the keys' ranks. This is done by calling {\ttfamily updateIndex(i, j)}. The resulting $index$ is shown in table~\ref{tab:indexAfterInsertion}.
    \begin{table}[H]
    \centering
    \input{04_Tables/032_indexAfterInsertion.tex}
    \caption[Example $index$ after the insertion of a new key]{Instance variable $index$ after the insertion of a key with rank 4 at position 2 in $key$}
    \label{tab:indexAfterInsertion}
    \end{table}
    
    \item
    Lastly, we increment the instance variable $n$.
\end{enumerate}

\paragraph{Delete}

We will now delete $x = -1000$, having as starting point the state the instance was right after the insertion described in \ref{sec:binaryRankInsertExample}. Deleting $x$ from $S$ on this data structure is comprised of the following:
\begin{enumerate}
    \item
    We check if $x$ is not in the set, returning in such a case.
    This is not the case, so we proceed.
    
    \item
    We compute $\text{rank}(x)$ and store it in a local variable $i$.
    \begin{align*}
        x = -1000 \\
        \cline{1-2}
        i := \text{rank}(-1000) = 4
    \end{align*}
    
    \item
    With a call to {\ttfamily getIndex(i)} we get the position in $key$ where $x$ is stored. We use that to mark that position as empty in $bKey$. This is done with {\ttfamily vacantSlot(getIndex(i))}. After this update, $bKey$ will be the same as in table~\ref{tab:binaryRankKey}.
    
    \item
    We need also to update $index$ by moving all the indices with rank larger than $i$, the rank of $x$, one position to the left. We do this by calling {\ttfamily updateIndex(i)}. This update will make $index$ be as shown in table~\ref{tab:binaryRankIndex}.
    
    \item
    Lastly, we decrement the instance variable $n$.
\end{enumerate}





\newpage
\section{Rank via matching with "don't cares"} \label{sec:rankWithDontCares}

Static fusion trees have less than optimal update time because adding a new key entails recomputing sketches. Pătrașcu and Thorup address this by introducing "don't cares", which provides a simulation of a Patricia trie at the node level. This is relevant because, differently to what happens at the fusion tree node from Fredman and Willard, inserting a new key in a Patricia trie corresponds to adding a new branch node \cite{patrascu2014dynamic}. By doing so, the data structure now supports queries and updates in $O(1)$ time.

In this incremental step, we keep the most of the implementation details of \ref{sec:DynamicFusionNodeBinaryRank}, plus we store the compressed keys with "don't cares" to enable the rank operation as described in the \textit{Matching with don't cares} section of \cite{patrascu2014dynamic}.

Enabling this operation entails the following:
\begin{itemize}
    \item
    Compressing keys (or \textit{sketching}) in the same style as fusion trees, from Fredman and Willard.
    
    In order to compress keys, we need a compressing key. A naive way to compute a compressing key is to store $\text{msb}(x_i \oplus x_j)$ of all $\{x_i, \dots, x_j\}$ keys in the set in a word.
    
    We denote the compressed version of $x$ by $\hat x $. A naive way to compress a key $x$ is to iterate through the set bits of the compressing key, storing the bit values at those positions of $x$ in $\hat x$.
    
    \item
    Encoding the information about "don't cares". We denote a compressed key with "don't cares" by $\hat x^?$. A compressed key with "don't cares" has length $k$ and can be any combination of the characters $\{0, 1, ?\}$. Since the bits of a word in a real machine can only take the values $\{0, 1\}$, we need an additional construct to enable the third character. This shows that a single word for storing the compressed keys with "don't cares" is not enough. So we keep two new instance variables, the words: $branch$ and $free$.
    
    These words are to be interpreted as two $k \times k$ bit matrices, and they are defined the following way:
    \begin{itemize}
        \item
        We see each $branch\langle i \rangle_k$ as a row in the matrix, and each row maps to a compressed key in the set with rank $i$.
        As its name implies, $branch$ will contain the values of the branching bits. 
        So each column $j$, e.g. $branch\langle i, j\rangle_{1 \times k}$, corresponds to a branching bit.
        We will store the compressed keys except for the "don't cares" positions, which are always stored with value zero.
        In other words, if a particular branching bit of a compressed key is not a "don't care", then the value of the bit at that position in $branch$ (in its corresponding row) will be the same as of bit at that position in the corresponding compressed key; otherwise, it is 0.
        
        \item
        In regards to $free$, its rows and columns have the same correspondence as in $branch$.
        When seeing the keys in a matrix and ordered by their rank, we can see that the value of some of those positions does not influence the rank of the (compressed) keys.
        These positions will be "don't cares".
        We will encode this data the following way: If a particular branching bit of a compressed key is not a "don't care", the bit at the same index in $free$ (in its corresponding row) is 0, otherwise it is one.
    \end{itemize}

    \item
    A subroutine $\text{match}(x)$ that uses all of the above and rank via Rank Lemma 1 (defined in Section~\ref{sec:rankLemma1} and implemented in Section~\ref{sec:rankLemma1Implementation}).
    
    Let $\hat x^k$ be the compressed version of $x$ copied $k$ times and stored in a word. After compressing the $x$, and by multiplying $\hat x$ with the mask $M$ (which has been computed via the {\ttfamily Util} helper function and stored as a class variable) we to achieve the intended result. Note that we have already used this multiplication operation in \ref{sec:computeM}.
    Then $\text{match}(x)$ is computed with the following expression \cite{patrascu2014dynamic}:
    \begin{align*}
        \text{match}(x) = \underbrace{\text{rank}(\hat x, branch \vee (\hat x^k \wedge free))}_{\text{Rank Lemma 1}}
    \end{align*}
\end{itemize}

The implementation of Section~\ref{sec:DynamicFusionNodeBinaryRank} had the $index$ word as the limiting factor of $k$ because we had to be able to index all the positions of the set. This time, the limiting factor for $k$ will be the $branch$ and $free$ matrices: since those have $k$ rows and $k$ columns and a word in our machine is of length 64, we have:
\begin{align*}
    k^2 \leq 64\\
    \implies k \leq \sqrt{64}\\
    \iff k \leq 8
\end{align*}

This class shares many implementation details with the Dynamic Fusion Node with binary Rank from Section~\ref{sec:DynamicFusionNodeBinaryRank}. For that reason, in the next few sections, we will see what is kept, added, or altered compared with that implementation while expanding only on the last two. The changes enable the new operations of this class.

\subsection{Fields} \label{sec:dontCaresRankFields}
The following fields were kept unchanged and stand for the same as in \ref{sec:binaryRankFields}:
\begin{lstlisting}
private final long[] key = new long[k];
private long index;
private int bKey;
private int n;
\end{lstlisting}

The following fields were either altered or introduced:
\begin{itemize}
    \item
    The parameter $k$ has been altered. This is because, as explained in \ref{sec:rankWithDontCares}, $branch$ and $free$ will limit further the capacity of the set:
    \begin{lstlisting}
private static final int k = 8;
    \end{lstlisting}
    
    \item
    We will need a constant $M$ to be used as mask in some of methods. We resort to the {\ttfamily M} function of the {\ttfamily Util} class, and store the result as a class variable.
    \begin{lstlisting}
private static final long M = Util.M(k, k * k);
    \end{lstlisting}

    \item
    The operations introduced in this implementation require us to compress keys. To this extent, we store a word, $compressingKey$, which will retain the information regarding the bits to keep when compressing a $key$. If a bit is significant, then it will be set to one in $compressingKey$.
    \begin{lstlisting}
private long compressingKey;
    \end{lstlisting}

    \item
    As explained in \ref{sec:rankWithDontCares}, the word $branch$ maps to one of the $k \times k$ bit matrices, $BRANCH$, that Pătrașcu and Thorup use to store the part of the data of compressed keys with "don't cares".
    We see each $branch\langle i \rangle_k$ as a row in the matrix, each row corresponding to the key with rank $i$ in the set.
    Each column $j$, e.g., $branch\langle i, j\rangle_{k \times 1}$ corresponds to a branching bit of the compressed key with "don't cares" of rank $i$.
    \begin{lstlisting}
private long branch;
    \end{lstlisting}
    
    \item
    Similarly to $branch$, the word $free$ is the second $k \times k$ bit matrix, $FREE$, which is also used for storing the rest of the data of the compressed keys with "don't cares". Indexing of rows and columns are mapped in the same way as in $branch$.
    \begin{lstlisting}
private long free;
    \end{lstlisting}
\end{itemize}

\subsection{Helper methods} \label{sec:dontCaresRankHelperMethods}

The following helper methods suffered no changes and serve the same purposed as the implementation from \ref{sec:binaryRankHelperMethods}:
\begin{itemize}
    \item
    {\ttfamily firstEmptySlot()}
    
    \item
    {\ttfamily fillSlot(final int j)}
    
    \item
    {\ttfamily vacantSlot(int j)}
    
    \item
    {\ttfamily getIndex(final long i)}
    
    \item
    The overloaded methods {\ttfamily updateIndex}
\end{itemize}

The following are helper methods introduced in this implementation:
\begin{itemize}
    \item
    {\ttfamily updateCompressingKey()} updates the compressing key by looping through all the combinations of keys in the set and setting all the first branching bits between those keys in $compressingKey$. E.g., let $x$ and $y$ be a particular combination of two keys in the set. The method sets in $compressingKey$ the $\text{msb}(x \oplus y)$ of all combinations of keys in the set. This approach is naive and slow, with $O(n^2)$ time.
    
    \item
    {\ttfamily compress(final long x)} uses $compressingKey$ in order to compute the compressed version of the input key, $x$. It loops through the set bits of $compressingKey$, setting the bits $\hat x$ by reading actual bit values at those positions in $x$. Since this is done naively, it takes $O(k)$ time.

    \item
    {\ttfamily long compressedKeys()} returns a word containing all the compressed keys present in the set and ordered by rank. This is done by looping through all keys in the set and calling the {\ttfamily compress(x)} method on every key. This method is called after upon updating the set, and since all the compressed keys are recomputed, this takes $O(n)$ time.
    
    \item
    The {\ttfamily updateFree(final long compressedKeys)} method makes a call to the recursive {\ttfamily dontCares} method (explained below) which updates $free$ after the insertion or deletion of a key.

    \item
    The {\ttfamily dontCares} method has the following signature:
    \begin{lstlisting}
private long dontCares(long compressedKeys, long free, final int bit, final int lo, final int hi)
    \end{lstlisting}
    The parameters $compressedKeys$ and $free$ are the compressed keys stored in a word and word where the method with store the data about "don't cares" as it iterates, respectively. $bit$ refers to index of the column (in both $compressedKeys$ and $free$), whereas $hi$ and $lo$ refers to a range of rows (also in both $compressedKeys$ and $free$).
    $free$ is updated by following the steps:
    \begin{enumerate}
        \item
        Starting from the most significant column (given by the parameter $bit$), e.g., the most significant bit of the compressed key and a range of keys that includes all rows:
        \begin{itemize}
            \item
            If all bits in that column are the same, then that position is a "don't care" for all keys. This is because, in this range, regardless of the value of the bit, the order of the keys is always the same.
            
            \item
            If at least one bit differs in that column, then we care for that position in all keys. Again, the particular value for these rows and column contributes to the order of the compressed keys.
        \end{itemize}
        
        \item
        The method is called recursively:
        \begin{itemize}
            \item
            If the bits were all the same for that range and in that column, then the method is called with the same range of rows, but now on the next lesser significant column.
            
            \item
            Otherwise, we do two recursive calls: one for the range of rows whose bit was set to 0 and another for the keys that had the bit set to 1 in that column.
        \end{itemize}
        
        \item
        The recursive call chain reaches its end when the column index, $bit$, is $-1$.
    \end{enumerate}
    Because we iterate through all columns in $free$, which are the significant bits, and the by row, which are the keys in the set, this algorithm takes $O(k \cdot n)$ time.
    
    \item
    After having $compressedKeys$ and $free$ computed, the {\ttfamily final long compressedKeys} method updates $branch$ with the expression:
    \begin{align*}
        branch := compressedKeys \wedge \neg free
    \end{align*}
    This takes $O(1)$ time.
    
    \item
    The helper method {\ttfamily match(x)} has the signature:
    \begin{lstlisting}
private int match(final long x)
    \end{lstlisting}
    As mentioned in \ref{sec:rankWithDontCares}, it implements the operation described in the \textit{Matching with don't cares} section of \cite{patrascu2014dynamic}.
    Since it uses {\ttfamily compress(final long x)} as a subroutine, its running time is bounded the running time of that operation.
    
    \item
    The {\ttfamily dontCaresRank(final long x)} returns the rank of $x$ in the set, using {\ttfamily match(final long x)}, {\ttfamily select(final long rank)} {\ttfamily msb(final int x)} as a subroutines.
    The implementation follows the algorithm presented by Pătrașcu and Thorup in the \textit{Matching with don't cares} section of \cite{patrascu2014dynamic}.
    Its running time is bound by the running time of its slowest subroutine, {\ttfamily match(final long x)}, which in turn calls {\ttfamily compress(final long x)}, which takes $O(k)$ time.

\end{itemize}

\subsection{Implementation of the interface methods} \label{sec:dontCaresRankInterfaceImplementation}

The following interface methods suffered no changes and serve the same purpose as the implementation from \ref{sec:binaryRankInterfaceImplementation}:
\begin{itemize}
    \item
    {\ttfamily select(final long rank)}
    
    \item
    {\ttfamily size()}
\end{itemize}

The following interface methods suffered changes in relation to \ref{sec:binaryRankInterfaceImplementation}:
\begin{itemize}
    \item
    {\ttfamily insert(final long x)} keeps all the steps from \ref{sec:binaryRankInsert} and adds the following right after inserting $x$ in the set:
    \begin{enumerate}
        \item
        The $compressingKey$ is updated with a call to {\ttfamily updateCompressingKey()}.
        
        \item
        All the keys a compressed and the result is stored in a local variable with the statement:
        \begin{lstlisting}
final long compressedKeys = compressedKeys();
        \end{lstlisting}
        
        \item
        $free$ is updated with the call:
        \begin{lstlisting}
updateFree(compressedKeys);
        \end{lstlisting}
        
        \item
        And the last step is to update $branch$, which is done with:
        \begin{lstlisting}
updateBranch(compressedKeys);
        \end{lstlisting}
    \end{enumerate}
    
    \item
    Similarly to {\ttfamily insert}, {\ttfamily delete(final long x)} keeps all the steps from \ref{sec:binaryRankHelperMethods} and adds the following right after removing $x$ from the set:
    \begin{enumerate}
        \item
        The $compressingKey$ is updated with a call to {\ttfamily updateCompressingKey()}.
        
        \item
        All the keys a compressed and the result is stored in a local variable with the statement:
        \begin{lstlisting}
final long compressedKeys = compressedKeys();
        \end{lstlisting}
        
        \item
        $free$ is updated with the call:
        \begin{lstlisting}
updateFree(compressedKeys);
        \end{lstlisting}
        
        \item
        And the last step is to update $branch$, which is done with:
        \begin{lstlisting}
updateBranch(compressedKeys);
        \end{lstlisting}
    \end{enumerate}
    
    \item
    {\ttfamily rank(final long x)} returns the rank of $x$ in the set by calling the {\ttfamily dontCaresRank(final long x)} helper method.
    
    \item
    {\ttfamily reset()}.
    Resetting the data structure now also entails resetting some of the instance variables. The additional operations are:
    \begin{itemize}
        \item
        Setting $compressingKey$ to zero because, in an empty set, there are no branching bits.
        
        \item
        Setting $branch$ to zero because, in an empty set, there are no compressed keys.
        
        \item
        Setting $free$ to $-1$, because in an empty set, there are no keys and bits set in $free$ mean that we do not care for those positions of the compressed keys.
    \end{itemize}
\end{itemize}

\subsection{Example} \label{sec:dontCaresRankExample}

This section is aimed at showcasing how the compressed keys with "don't cares" are stored in the data structure and what are the steps taken by the algorithm to return a $\text{rank}(x)$ query using the algorithm implemented in the {\ttfamily dontCaresRank(final long x)} method.

Our example starts with a set containing the keys from table~\ref{tab:keysInTheSetForRank} and a rank query key $x = 1010\ 1010\ 1111_2$. For brevity, the selected set of keys will only have bits set between the indices 0 and 11. This way, we know that the 52 leading bits will have no influence when running the algorithm.

\begin{table}[H]
\centering
\input{04_Tables/003_keysInTheSet.tex}
\caption[Example of keys present in the set stored in $key$ in binary]{Keys present in the set stored in $key$ in binary. The header row are the bit indices and the rank of the keys is the first column.}
\label{tab:keysInTheSetForRank}
\end{table}

\subsubsection{Key compression} \label{sec:keyCompression}

The keys from table~\ref{tab:keysInTheSetForRank} will produce the following compressing key (with the $52$ most significant bits omitted for brevity):
\begin{align*}
    compressingKey = 1111\ 1001\ 0010_2
\end{align*}

Having this compressing key implies that, when compressing keys, we keep only the bits at positions 1, 4, 7, 8, 9, 10, and 11. We can see these indices highlighted in table~\ref{tab:significantBitsHighlighted}.

\begin{table}[H]
\centering
\input{04_Tables/004_significantBitsHighlighted.tex}
\caption[Example of bits that are kept when compressing keys]{The highlighted columns correspond to the set bits of the compressing key. When compressing a key, we keep only the bits of the highlighted columns.}
\label{tab:significantBitsHighlighted}
\end{table}

After compressing our keys with our $compressingKey$, we end up with the result of table~\ref{tab:compressedKeys}.

\begin{table}[H]
\centering
\input{04_Tables/005_compressedKeys.tex}
\caption[Example of compressed keys]{Compressed Keys}
\label{tab:compressedKeys}
\end{table}

\subsubsection{Compressed keys with "don't cares"} \label{sec:keyCompressionWithDontCares}

As previously mentioned, the particular value of some of the bits at some positions has no influence in the rank of the keys. These positions have been replaced with "$?$" on table~\ref{tab:compressedKeysWithDontCares}. The operation of transforming compressed keys in compressed keys with "don't cares" corresponds to what the {\ttfamily dontCares} method described in \ref{sec:dontCaresRankHelperMethods} does.

\begin{table}[H]
\centering
\input{04_Tables/006_compressedKeysWithDontCares.tex}
\caption[Example of compressed keys with "don't cares"]{Compressed Keys with "don't cares"}
\label{tab:compressedKeysWithDontCares}
\end{table}

In the data structure, this data is stored in the two class variables $branch$ and $free$, which follows the logic explained in \ref{sec:rankWithDontCares}. They are each a single $w$-bit word. If we lay each of those words in a $k \times k$ matrix, then each row will correspond to a compressed key. This is precisely what we see in the tables from figure \ref{fig:branchAndFreeCompressedKeys}.% tables~\ref{tab:branchTable} and \ref{tab:freeTable}.

\begin{figure}[H]
\centering
\input{04_Tables/007_branchTable.tex}
\caption[Example of how the compressed keys with "don't cares" are stored in the instance variables $branch$ and $free$]{Compressed keys with "don't cares" stored in the resulting words $branch$ and $free$ displayed in $k \times k$ matrices}
\label{fig:branchAndFreeCompressedKeys}
\end{figure}

% \begin{table}[H]
% \centering
% \input{04_Tables/008_freeTable.tex}
% \caption{The resulting word $free$ laid in a $k \times k$ matrix}
% \label{tab:freeTable}
% \end{table}

\subsubsection{Querying} \label{sec:rankDontCaresQuery}

Sections \ref{sec:keyCompression} and \ref{sec:keyCompressionWithDontCares} have handled the contents of the set and the relevant class variables for this operation. We shall now see what unfolds as soon as we query $\text{rank}(1010\ 1010\ 1111_2)$.

\begin{enumerate}
    \item
    The method starts by checking if the set is empty, returning zero in such a situation. This is not the case, so we proceed.
    
    \item
    A call to {\ttfamily match} with the query $x$ is done. In $\text{match}(1010\ 1010\ 1111_2)$. The operation entails compressing the query, computing the word $branch \vee (\hat x^k \wedge free)$ and computing the rank of $\hat x$ in that word via Rank Lemma 1.
    \begin{enumerate}
        \item
        We compress the query with $\text{compress}(1010\ 1010\ 1111_2)$. Thus we have:
        \begin{align*}
            compressingKey = 1111\ 1001\ 0010_2\\
            x = \underline{1010}\ \underline{1}01\underline{0}\ 11\underline{1}1_2\\
            \cline{1-2}
            \hat x = \underbrace{0\underline{101}\ \underline{0101}_2}_k
        \end{align*}
        \item
        We make $k$ copies $\hat x$:
        \begin{align*}
            M = (0^{k-1}1)^k_2\\
            \hat x = 0101\ 0101_2\\
            \cline{1-2}
            \hat x^k = M \times \hat x = (0101\ 0101_2)^k\\
        \end{align*}
        
        If we lay the resulting word in a matrix we have:
        \begin{table}[H]
        \centering
        \input{04_Tables/009_xCompressedCopiedMatrix.tex}
        \caption[Example of a compressed key copied $k$ times and laid in a $k \times k$ matrix]{$k$ copies of $\hat x$ in a word laid in a $k \times k$ matrix}
        \label{tab:xCompressedCopied}
        \end{table}
        
        \item
        We compute $\hat x^k \wedge free$, which keeps only the "don't cares" bits in $\hat x^k$. By bit-wise $\wedge$ tables \ref{tab:xCompressedCopied} and \ref{tab:freeTable} we have:
        \begin{table}[H]
        \centering
        \input{04_Tables/010_xCompressedANDfree.tex}
        \caption[Example of $\hat x^k \wedge free$ in a word laid in a $k \times k$ matrix]{$\hat x^k \wedge free$ in a word laid in a $k \times k$ matrix}
        \label{tab:xCompressedANDfree}
        \end{table}
        
        \item
        We compute $branch \vee (\hat x^k \wedge free)$, which is done by bit-wise $\vee$ tables~\ref{tab:branchTable} and \ref{tab:xCompressedANDfree}. This will project the bits of $\hat x^k$ in the "don't cares" positions of all the compressed keys in the set. Thus we end up with:
        \begin{table}[H]
        \centering
        \input{04_Tables/011_branchORxCompressedANDfree.tex}
        \caption[Example of $branch \vee (\hat x^k \wedge free)$ in a word laid in a $k \times k$ matrix]{$branch \vee (\hat x^k \wedge free)$ in a word laid in a $k \times k$ matrix}
        \label{tab:branchORxCompressedANDfree}
        \end{table}
        
        \item
        Now, match returns $\text{rank}(\hat x, branch \vee (\hat x^k \wedge free))$ via Rank Lemma 1. In table~\ref{tab:branchORxCompressedANDfree}, we can see that $\hat x = 0101\ 0101_2$ is larger than the keys up to row 4, meaning that its rank is 5 (the highlighted row). Thus we have:
        \begin{align*}
            \text{match}(x) = 5
        \end{align*}
    \end{enumerate}
    This result is stored in a local variable, $i$.
    
    \item
    We perform the query $\text{select}(i)$:
    \begin{align*}
        i = 5\\
        \cline{1-2}
        \text{select}(5) = 1010\ 1100\ 1111_2
    \end{align*}
    This is stored in a local variable, $y$.
    
    \item
    We compare $x$ with $y$ using the library function {\ttfamily compareUnsigned}, storing the result in a local variable, $comp$.
    \begin{align*}
        x = 1010\ 1010\ 1111_2\\
        y = 1010\ 1100\ 1111_2\\
        \cline{1-2}
        x < y \implies comp = -1
    \end{align*}
    If $comp = 0$ then $x = y$, which means that $x$ is already present in the set, thus its rank will be $i$. In this case, the method would return $i$. This is not the case; thus, we proceed.
    
    \item
    We find the branching bit between $x$ and $y$ and store it in a local variable, $j$. This is done with $\text{msb}(x \oplus y)$:
    \begin{align*}
        x &= 1010\ 1010\ 1111_2\\
        y &= 1010\ 1100\ 1111_2\\
        \cline{1-2}
        x \oplus y &= 0000\ 0\underline{1}10\ 0000_2\\
        \cline{1-2}
        j &= \text{msb}(x \oplus y) = 6
    \end{align*}
    
    \item
    The idea behind the current step is described in the \textit{Desketchifying} chapter of \cite{erikdemainelec12}.
    
    To find the actual rank of $x$, we need to use the $\text{match}$ function once again. We know now that there is a key, $y$, that matched $x$ but branched away from $x$ in the $6^{th}$ bit.
    We have now two cases:
    \begin{itemize}
        \item
        If $comp < 0$ then $x < y$, so we apply a mask to $x$ that keeps only its $w-j$ most significant bits. Let the value of $x$ after this mask be $x_m$; when applying \textit{match} to $x_m$, we go down the tree to the left as much as possible after the branching bit $j$ because all the bits of $x_m$ after $j$ will be zero. The rank of $x$ will be the $\text{match}(x_m)$, which Pătrașcu and Thorup denote by $i_0$ in \cite{patrascu2014dynamic}.
        
        \item
        Otherwise, $x > y$. We apply a mask to $x$ that set its $j$ least significant bits to one. When calling $\text{match}$ with $x$ after this mask, we will go down the tree to the right as much as possible after the branching bit $j$ because all the bits of $x_m$ after $j$ will be one. The rank of $x$ will be the $\text{match}(x_m) + 1$, where, according to Pătrașcu and Thorup, $\text{match}(x_m) = i_1$ in \cite{patrascu2014dynamic}.
    \end{itemize}
    The above-mentioned masks have been defined in Section~\ref{sec:masks}.
    
    Since $x < y$, we are in the first case. We apply a mask to $x$ that keeps only the $w-j$ most significant bits of $x$. 
    \begin{align*}
        j = 6\\
        mask = \neg((1 \ll j) - 1)\\
        \cline{1-2}
        mask = \underbrace{1111\ 11}_{w-j}\underbrace{00\ 0000}_j{}_2\\
        x = \underline{1010}\ \underline{10}10\ 1111_2\\
        \cline{1-2}
        x_m = x \wedge mask = \underline{1010}\ \underline{10}00\ 0000_2
    \end{align*}

    Finally we call $\text{match}$ with $x_m$:
    \begin{enumerate}
        \item
        We compress the query with $\text{compress}(1010\ 1000\ 0000_2)$. Thus we have:
        \begin{align*}
            compressingKey = 1111\ 1001\ 0010_2\\
            x_m = \underline{1010}\ \underline{1}00\underline{0}\ 00\underline{0}0_2\\
            \cline{1-2}
            \hat x_m = 0\underline{101}\ \underline{0100}_2
        \end{align*}
        \item
        We make $k$ copies $\hat x$:
        \begin{align*}
            M = (0^{k-1}1)^k_2\\
            \hat x_m = 0101\ 0100_2\\
            \cline{1-2}
            \hat x^k_m = M \times \hat x_m = (0101\ 0100_2)^k\\
        \end{align*}
        
        If we lay the resulting word in a matrix we have:
        \begin{table}[H]
        \centering
        \input{04_Tables/012_xMaskedCompressedCopied.tex}
        \caption[Example of $k$ copies of $\hat x_m$ in a word laid in a $k \times k$ matrix]{$k$ copies of $\hat x_m$ in a word laid in a $k \times k$ matrix}
        \label{tab:xMaskedCompressedCopied}
        \end{table}
        
        \item
        
        We compute $\hat x^k_m \wedge free$, which keeps only the "don't cares" bits in $\hat x^k$. By bit-wise $\wedge$ the tables \ref{tab:xMaskedCompressedCopied} and \ref{tab:freeTable} we have:
        \begin{table}[H]
        \centering
        \input{04_Tables/013_freeANDxMaskedCompressedCopied.tex}
        \caption[Example of $\hat x^k_m \wedge free$ in a word laid in a $k \times k$ matrix]{$\hat x^k_m \wedge free$ in a word laid in a $k \times k$ matrix}
        \label{tab:freeANDxMaskedCompressedCopied}
        \end{table}
        
        \item
        We compute $branch \vee (\hat x^k_m \wedge free)$, which is done which bit-wise $\vee$ tables~\ref{tab:branchTable} and \ref{tab:freeANDxMaskedCompressedCopied}. This will project the bits of $\hat x^k_m$ in the "don't cares" positions of all the compressed keys in the set. Thus we end up with:
        \begin{table}[H]
        \centering
        \input{04_Tables/014_branchORfreeANDxMCopied.tex}
        \caption[Example of $branch \vee (\hat x^k_m \wedge free)$ in a word laid in a $k \times k$ matrix]{$branch \vee (\hat x^k_m \wedge free)$ in a word laid in a $k \times k$ matrix}
        \label{tab:branchORfreeANDxMCopied}
        \end{table}
        
        \item
        Now, match returns $\text{rank}(\hat x_m, branch \vee (\hat x^k_m \wedge free))$ via Rank Lemma 1. In table~\ref{tab:branchORfreeANDxMCopied}, we can see that $\hat x_m = 0101\ 0100_2$ is larger than the keys up to row 3, meaning that its rank is 4 (the highlighted row). Thus we have:
        \begin{align*}
            \text{match}(x_m) = 4
        \end{align*}
    \end{enumerate}
    
    \item
    We finish by returning the rank of $x$, which in this case:
    \begin{align*}
        i_0 = \text{match}(x_m) = 4& \\
        \implies \text{rank}(x) = i_0 = 4&
    \end{align*}
\end{enumerate}

\newpage
\section{Inserting while maintaining the compressed keys with "don't cares"} \label{sec:InsertDontCares}

In this section, we will address how to maintain the compressed keys with "don't cares" when inserting a new key, as described in section \textit{Inserting a key} of \cite{patrascu2014dynamic}. We take another incremental on the implementations from Sections~\ref{sec:DynamicFusionNodeBinaryRank} and \ref{sec:rankWithDontCares}, keeping most of their details with the exception of the {\ttfamily insert} method. To this extent, we also add some new helper methods.

The algorithm for inserting a key $x$ in the set while maintaining $branch$ and $free$ entails:
\begin{itemize}
    \item
    Rank via "don't cares", including its subroutines, as introduced and described in \ref{sec:rankWithDontCares}.
    
    \item
    Assessing if introducing a new key adds a new branching bit, e.g., a new column in $branch$ and $free$.
    
    \item
    Computing the rank of new significant positions. In other words, if adding a new key implies adding a new column $j$ in $branch$ and $free$ because it is a new significant position, then we need to know how many set bits are there in the $compressingKey$ up to index $j$.
    
    \item
    Matrix operations in $branch$ and $free$ such as:
    \begin{itemize}
        \item
        Adding rows and columns.
        
        \item
        Updating rows and columns.
        
        \item
        Setting and deleting ranges of bits or particular bits in rows or columns.
    \end{itemize}
    
    \item
    All of the operations described in the {\ttfamily insert (final long x)} method of Section~\ref{sec:binaryRankInterfaceImplementation}.
\end{itemize}

\subsection{Fields} \label{sec:dontCaresInsertFields}

All the class and instance variables remain unchanged in comparison with Section~\ref{sec:dontCaresRankFields}. They are:
\begin{lstlisting}
private static final int k = 8;
private static final int ceilLgK = (int) Math.ceil(Math.log10(k) / Math.log10(2));
private static final long M = Util.M(k, k * k);
private final long[] key = new long[k];
private long index;
private int bKey;
private int n;
private long compressingKey;
private long branch;
private long free;
\end{lstlisting}

\subsection{Helper methods} \label{sec:dontCaresInsertHelperMethods}

The following helper methods, which have already been implemented in \ref{sec:binaryRankHelperMethods} and \ref{sec:dontCaresRankHelperMethods} are kept:
\begin{itemize}
    \item
    {\ttfamily firstEmptySlot()}
    
    \item
    {\ttfamily fillSlot(final int j)}
    
    \item
    {\ttfamily vacantSlot(int j)}
    
    \item
    {\ttfamily getIndex(final long i)}
    
    \item
    The overloaded methods {\ttfamily updateIndex}
    
    \item
    {\ttfamily updateCompressingKey()}
    
    \item
    {\ttfamily compress(final long x)}
    
    \item
    {\ttfamily long compressedKeys()}
    
    \item
    {\ttfamily updateFree(final long compressedKeys)}
    
    \item
    {\ttfamily dontCares}
    
    \item
    {\ttfamily match(x)}
    
    \item
    {\ttfamily dontCaresRank(final long x)}
    
\end{itemize}

The following are helper methods introduced in this implementation:
\begin{itemize}
    \item
    {\ttfamily matrixM(final int h)} returns a word which when interpreted as a $k \times k$ matrix has only column $h$ set. Let $h = 5$, then {\ttfamily matrixM(5)} returns:
    \begin{table}[H]
    \centering
    \input{04_Tables/015_MatrixH.tex}
    \caption{{\ttfamily matrixM(5)}}
    \label{tab:matrixM}
    \end{table}
    
    \item
    {\ttfamily matrixMColumnRange(final int lo, final int hi)} returns a word which when interpreted as a $k \times k$ matrix will have the bits in the range of columns between $lo$ (inclusive) and $hi$ (inclusive) set. Let $lo = 3$ and $hi = 6$, then {\ttfamily matrixMColumnRange(3, 6)} returns:
    \begin{table}[H]
    \centering
    \input{04_Tables/016_MatrixColumnRange.tex}
    \caption{{\ttfamily matrixMColumnRange(3, 6)}}
    \label{tab:MatrixColumnRange}
    \end{table}
    
    \item
    {\ttfamily matrixMRowRange(final int lo, final int hi)} returns a word which when interpreted as a $k \times k$ matrix will have the bits in the range of rows between $lo$ (inclusive) and $hi$ (inclusive) set. Let $lo = 3$ and $hi = 6$, then {\ttfamily matrixMRowRange(3, 6)} returns:
    \begin{table}[H]
    \centering
    \input{04_Tables/019_MatrixRowRange.tex}
    \caption{{\ttfamily matrixMRowRange(3, 6)}}
    \label{tab:MatrixRowRange}
    \end{table}
    
    \item
    {\ttfamily insertAndInitializeColumn(final int h)} introduces a new column in $branch$ and $free$, initializing it to its default bit value ($0$ in $branch$ and $1$ in $free$).
    Let $branch$ and $free$ be the following:
    \begin{figure}[H]
    \centering
    \input{04_Tables/017_branchAndFreeExample.tex}
    \caption{Examples of $branch$ and $free$}
    \label{fig:branchAndFreeExample}
    \end{figure}
    A call to {\ttfamily insertAndInitializeColumn(2)} will move all columns larger than $2$ one position to the left and set values in the new column them to their respective default. In the tables from figure~\ref{fig:branchAndFreeAfterColumnInsertion} we can see the new column highlighted.
    \begin{figure}[H]
    \centering
    \input{04_Tables/018_branchAndFreeAfterInsertion.tex}
    \caption[Example of $branch$ and $free$ after insertion of column at position $2$]{$branch$ and $free$ after insertion of column at position $2$}
    \label{fig:branchAndFreeAfterColumnInsertion}
    \end{figure}
    
    \item
    {\ttfamily insertRow(final int rank)} introduces a new row in $branch$ and $free$ at position $rank$. All rows with rank larger than $rank$ will occupy their respective next row. Calling {\ttfamily insertRow(2)} while having $branch$ and $free$ as the tables from figure~\ref{fig:branchAndFreeExample} as instance variables will result on the following:
    \begin{figure}[H]
    \centering
    \input{04_Tables/020_InsertingRow.tex}
    \caption[Example of $branch$ and $free$ after insertion of row at position $2$]{$branch$ and $free$ after insertion of row at position $2$}
    \label{fig:branchAndFreeAfterRowInsertion}
    \end{figure}
\end{itemize}

\subsection{Implementation of the interface methods}  \label{sec:dontCaresInsertInterfaceImplementation}

The following interface methods suffered no changes and serve the same purpose as the implementation from Section~\ref{sec:dontCaresRankInterfaceImplementation}:
\begin{itemize}
    \item
    {\ttfamily select(final long rank)}
    
    \item
    {\ttfamily size()}
    
    \item
    {\ttfamily delete(final long x)}\footnote{At this stage, we still maintain the compressed keys with "don't cares" naively after removing a key from the set.}
    
    \item
    {\ttfamily rank(final long x)}
    
    \item
    {\ttfamily reset()}
\end{itemize}

The {\ttfamily insert(final long x)} is now implemented the following way:
\begin{enumerate}
    \item
    A local variable $rank$ is initialized to zero.
    
    \item
    If the set is not empty:
    \begin{enumerate}
        \item
        We compute $\text{match}(x)$ and store it in a local variable $i$.
        
        \item
        We query $\text{select}(i)$ and and store it in a local variable $y$.
        
        \item
        We use the unsigned comparator from the standard library, {\ttfamily compareUnsigned}, to assess if the keys, $x$ and $y$, are equal or if one is larger than the other. This is stored in a local variable $comp$.
        
        \item
        If $comp = 0$, then $x = y$, which means that $x$ is already present in the set. In such a case, the method returns, introducing no changes in the contents of the data structure.
        
        \item
        At this stage, we know that $x$ is a new key, so before inserting it, we perform another check to see if the data structure has reached its limit, throwing an exception in such a case.
        
        \item
        We find the branching bit between $x$ and $y$ and store it in a local variable, $j$.
        
        \item
        We compute the rank of $j$ in the $compressingKey$ by masking all the bits at indices larger than $j$ and calling the standard library function, {\ttfamily bitCount}, on the masked $compressingKey$. This is stored in a local variable, $h$.
        
        \item
        We compute $i_0$ and $i_1$, given by the calls $\text{match}(x \wedge \neg((1 \ll j) - 1))$ and $\text{match}(x \vee ((1 \ll j) - 1))$. These masks and queries have been explained in \ref{sec:rankDontCaresQuery} and they will correspond to rows in $branch$ and $free$, e.g. the rank of actual keys in the set.
        
        \item
        Just like in \ref{sec:rankDontCaresQuery}, we compute the rank of $x$ based on how its value compares with $y$, updating the local variable $rank$ accordingly.
        
        \item
        We compute and store locally {\ttfamily matrixM(h)}.
        
        \item
        If $j$ was not already a significant bit:
        \begin{itemize}
            \item
            We mark it as a significant bit in $compressingKey$.
            
            \item
            We update $branch$ and $free$ with a call to {\ttfamily insertAndInitializeColumn(h)}.
        \end{itemize}
        
        \item \label{blt:matrixRowColumnMask}
        We call {\ttfamily matrixMRowRange(i\_0, i\_1)} and intersect it with  {\ttfamily matrixM(h)}. This will produce a mask that has column $h$ in the range of rows between $i_0$ and $i_1$ set to one, and every other rows and columns set to zero.
        
        \item
        We use the mask from \ref{blt:matrixRowColumnMask} to mark column $h$ in the range of rows between $i_0$ and $i_1$ as a "care" position. This entails setting those positions to zero in $free$ and storing the bit value of position $j$ in $y$ in $branch$.
        
        \item
        We insert a new row in $branch$ and $free$ with a call to {\ttfamily insertRow(rank)}.
        
        \item
        The local variable $i$, which stores the rank of $y$, is updated. This means that if $x < y$, then after inserting $x$, the rank of $y$ will have incremented. In such a case, we increment $i$ to reflect that.
        
        \item
        The last steps consist of updating row $rank$, which stores the $\hat x^?$, with the appropriate values. These are:
        \begin{itemize}
            \item
            In $branch$:
            \begin{itemize}
                \item
                The values of the bits in positions between $0$ and $h - 1$ are set to zero:
                \begin{align*}
                    branch\langle rank, 0 \dots h - 1 \rangle_{k \times 1} := 0^h
                \end{align*}
                
                \item
                We read $x\langle j\rangle_1$ and store it at position $h$:
                \begin{align*}
                    branch\langle rank, h\rangle_{k \times 1} := x\langle j \rangle_1
                \end{align*}
                
                \item
                We copy the bit values in positions between $h+1$ and $k-1$ from the $\hat y^?$ to the same positions:
                \begin{align*}
                    branch\langle rank, h + 1 \dots k - 1\rangle_{k \times 1} := branch\langle i, h + 1 \dots k - 1\rangle_{k \times 1}
                \end{align*}
                
            \end{itemize}
            
            \item
            In $free$:
            \begin{itemize}
                \item
                The values of the bits in positions between $0$ and $h-1$ are set to one:
                \begin{align*}
                    free\langle rank, 0 \dots h - 1 \rangle_{k \times 1} := 1^h
                \end{align*}
                
                \item
                We set position $h$ to zero:
                \begin{align*}
                    free\langle rank, h\rangle_{k \times 1} := 0
                \end{align*}
                
                \item
                We copy the bit values in positions between $h+1$ and $k-1$ from the $\hat y^?$ to the same positions:
                \begin{align*}
                    free\langle rank, h + 1 \dots k - 1\rangle_{k \times 1} := free\langle i, h + 1 \dots k - 1\rangle_{k \times 1}
                \end{align*}
            \end{itemize}
        \end{itemize}
    \end{enumerate}
    
    \item
    We finish by computing the steps described in \ref{sec:binaryRankInsert}, effectively insert $x$ in the set.
\end{enumerate}

\subsection{Example} \label{sec:dontCaresInsertExample}

We will now insert the key $x = 1001\ 0101\ 0001_2$ in a set containing the keys from table~\ref{tab:keysInTheSetBeforeInsertion}, showcasing all the steps. For brevity, the chosen keys only have set bits up to position 11 such that the 52 most significant bits do not influence any of the steps in the algorithm, and can safely be omitted.

\begin{table}[H]
\centering
\input{04_Tables/021_keysInTheSetBeforeInsertion.tex}
\caption[Example set of keys in binary]{Binary representation of the keys present in the data structure. The table also shows their rank (on the first column) and the bit values at every index (on the first row).}
\label{tab:keysInTheSetBeforeInsertion}
\end{table}

This set of keys will produce the following compressing key:
\begin{align*}
    compressingKey = 1100\ 0001\ 0000_2
\end{align*}

The compressed keys with "don't cares" stored in $branch$ and $free$ are shown in the tables from figure~\ref{fig:branchAndFreeBeforeInsertion}.

\begin{figure}[H]
\centering
\input{04_Tables/022_branchAndFreeBeforeInsertion.tex}
\caption{Resulting $branch$ and $free$ after the compression of keys with "don't cares" from table~\ref{tab:keysInTheSetBeforeInsertion}}
\label{fig:branchAndFreeBeforeInsertion}
\end{figure}

Inserting $x$ in the given set is comprised of the following:

\begin{itemize}
    \item
    We start by initializing a local variable $rank$, which will be used to store the rank of our query, $x$. Its initial value will be zero.
    
    \item
    If the set is not empty (which for the moment it is not), then we have to run the steps from Sections~\ref{sec:updateI0_I1} to \ref{sec:updateRankRow}; otherwise we skip to \ref{sec:dontCaresInsert}. This is because when the set is empty, there is no need for updating the compressed keys with "don't cares".
\end{itemize}

\subsubsection{Updating the range of keys whose compressed key matches the insertion key} \label{sec:updateI0_I1}

\begin{enumerate}
    \item
    We start by computing some variables that are used for computing the rank of $x$ along with $i_0$ and $i_1$, which specify a range of compressed keys with "don't cares" (rows in $branch$ and $free$) which have to be updated upon the present insertion:
    \begin{enumerate}
        \item
        We run $\text{match}(x)$ and store it in a local variable $i$:
        \begin{align*}
            x = 1001\ 0101\ 0001_2\\
            \cline{1-2}
            i := \text{match}(x) = 3
        \end{align*}
        
        \item
        We query $\text{select}(i)$ and store it in a local variable $y$:
        \begin{align*}
            i = 3\\
            \cline{1-2}
            y := \text{select}(i) = 1010\ 1101\ 0110_2
        \end{align*}

        \item
        We compare $x$ and $y$ with the {\ttfamily compareUnsigned} function from the standard library, storing the result in a local variable $comp$.
        \begin{align*}
            x = 1001\ 0101\ 0001_2\\
            y = 1010\ 1101\ 0110_2\\
            \cline{1-2}
            x < y \implies comp = -1
        \end{align*}
        Since $comp \not= 0$, then $x$ is not in the set, so we proceed.
        
        \item
        We check also if the set has room for $x$ with {\ttfamily size() < k}. In this case, it is not, so we proceed.

        \item
        To find the branching bit between $x$ and $y$, we compute $\text{msb}(x \oplus y)$ and store it in a local variable, $j$.
        \begin{align*}
            x = 10\underline{0}1\ 0101\ 0001_2\\
            y = 10\underline{1}0\ 1101\ 0110_2\\
            \cline{1-2}
            x \oplus y = 00\underline{1}1\ 1000\ 0111_2\\
            \cline{1-2}
            j := \text{msb}(x \oplus y) = 9
        \end{align*}
        
        \item
        We need to find the rank of $j$ in the $compressingKey$ and store it in a local variable, $h$. This variable will specify the column where we will write the branching bit to. We mask the bits that are at higher positions than $j$ and call the standard library function, {\ttfamily bitCount}, on that result:
        \begin{align*}
            j = 9 \\
            compressingKey = 110\underline{0}\ \underline{0001}\ \underline{0000}_2 \\
            mask = (1 \ll j) - 1 = 0001\ 1111\ 1111_2\\
            \cline{1-2}
            h := \text{{\ttfamily bitCount}}(compressingKey \wedge mask) = 1
        \end{align*}
        
        \item
        We compute $i_0$ and $i_1$, which are computed by calling $\text{match}(x \wedge \neg((1 \ll j) - 1))$ and $\text{match}(x \vee ((1 \ll j) - 1))$:
        \begin{align*}
            j = 9 \\
            x = 100\underline{1}\ \underline{0101}\ \underline{0001}_2 \\
            \cline{1-2}
            \neg((1 \ll j) - 1) = 1110\ 0000\ 0000_2 \\
            x \wedge \neg((1 \ll j) - 1) = 100\underline{0}\ \underline{0000}\ \underline{0000}_2\\
            i_0 :=\text{match}(x \wedge \neg((1 \ll j) - 1)) = 2\\
            \cline{1-2}
            (1 \ll j) - 1 = 0001\ 1111\ 1111_2 \\
            x \vee ((1 \ll j) - 1) = 100\underline{1}\ \underline{1111}\ \underline{1111}_2\\
            i_1 := \text{match}(x \vee ((1 \ll j) - 1)) = 3\\
        \end{align*}
        
        \item
        We compute $\text{rank}(x)$. If $x < y$, then $\text{rank}(x) = i_0$; otherwise, it is $i_1 + 1$:
        \begin{align*}
            i_0 = 2 \\
            i_1 = 3 \\
            \cline{1-2}
            comp = -1 \implies \text{rank}(x) = i_0 \\
            rank := 2
        \end{align*}
    \end{enumerate}
    
    \item
    We compute the matrix mask needed for, among other things, adding a new column $h$ in $branch$ and $free$, storing the result in a local variable $matrixM_h$. This results in table~\ref{tab:matrixMh}, where we can also see column $h$ highlighted.
    \begin{table}[H]
    \centering
    \input{04_Tables/023_matrixMh.tex}
    \caption[{\ttfamily matrixM(1)}]{$matrixM_h$}
    \label{tab:matrixMh}
    \end{table}
    
    \item
    We check if $j$ was already a significant position:
    \begin{align*}
        j = 9 \\
        compressingKey = 11\underline{0}0\ 0001\ 0000_2 \\
        \cline{1-2}
        \text{bit}(j, compressingKey) = 0
    \end{align*}
    Since it was not:
    \begin{itemize}
        \item
        We mark it as a significant position by setting bit $j$ in $compressingKey$:
        \begin{align*}
            j = 9 \\
            compressingKey = 11\underline{0}0\ 0001\ 0000_2\\
            \cline{1-2}
             compressingKey := \text{setBit}(j, compressingKey) = 11\underline{1}0\ 0001\ 0000_2
        \end{align*}
        
        \item
        We update $branch$ and $free$ to include the new column $h$. The {\ttfamily insertAndInitializeColumn(h)} method is called thus altering $branch$ and $free$ as we see in the tables from figure~\ref{fig:branchAndFreeInsertHcolumn}.
        \begin{figure}[H]
        \centering
        \input{04_Tables/024_branchAndFreeInsertHcolumn.tex}
        \caption[Example of $branch$ and $free$ after insertion of column at position $1$]{Insertion of column $h$ in $branch$ and $free$}
        \label{fig:branchAndFreeInsertHcolumn}
        \end{figure}
    \end{itemize}

    \item
    We call the function {\ttfamily matrixMRowRange($i_0$, $i_1$)} which returns a mask comprised of the range of rows $\{ i_0, \dots, i_1 \}$. Bit-wise $\wedge$ that mask with $matrixM_h$ computes a mask where only the bits of rows $\{ i_0, \dots, i_1 \}$ and column $h$ are set. These are the bits that of the compressed keys that need to be updated due the insertion of the new key $x$. Thus the mask needed for this effect is the one from table~\ref{tab:matrixMi_0Mi_1h}.
    \begin{table}[H]
    \centering
    \input{04_Tables/025_matrixMi_0Mi_1h.tex}
    \caption[Example of the intersection of column matrix mask, $matrixM_1$, with the row matrix mask $matrixM^{2:3}$, resulting in the mask $matrixM^{2:3}_1$]{$matrixM^{i_0:i_1}_h$, which resulted from the intersection of the column matrix mask, $matrixM_h$, and the row matrix mask, $matrixM^{i_0:i_1}$}
    \label{tab:matrixMi_0Mi_1h}
    \end{table}
    
    \item
    We update $branch$ and $free$ accordingly. We know that we care for these positions because $i_0$ and $i_1$ have matched $x$, so we set these positions to zero in $free$. The value to store at those positions in $branch$ has to be read from $y$:
    \begin{align*}
        y = 10\underline{1}0\ 1101\ 0110_2 \\
        j = 9 \\
        \cline{1-2}
        \text{bit}(j, y) = 1
    \end{align*}
    We see that the bit value is one, thus this will be the value we will update $branch$ with. The result after this update can be seen in the tables from figure~\ref{fig:branchAndFreeAfterMatrixMi_0Mi_1h}.
    \begin{figure}[H]
    \centering
    \input{04_Tables/026_branchAndFreeAfterMatrixMi_0Mi_1h.tex}
    \caption[Example of $branch$ and $free$ after updating column $1$ in rows $2$ and $3$]{$branch$ and $free$ after updating column $h$ of the $i_0:i_1$ compressed keys}
    \label{fig:branchAndFreeAfterMatrixMi_0Mi_1h}
    \end{figure}
\end{enumerate}

\subsubsection{Updating the instance variables with the new compressed key} \label{sec:updateRankRow}

We now have to insert a row for the new key in $branch$ and $free$ and write its corresponding values. This entails the following:

\begin{enumerate}
    \item
    We call {\ttfamily insertRow(rank)}, making row for $\hat x^?$ in row $rank$ of $branch$ and $free$. The tables from figure~\ref{fig:insertRowRank} show the result of this operation.
    \begin{figure}[H]
    \centering
    \input{04_Tables/027_insertRowRank.tex}
    \caption[Example of $branch$ and $free$ after the insertion of a row]{Insertion of row $rank$ in $branch$ and $free$}
    \label{fig:insertRowRank}
    \end{figure}
    
    \item
    Some of the values of $\hat x^?$ will be copied from $\hat y^?$. For this reason we have to update $i$, the rank of $y$, such that the needed values are copied from the right key.
    \begin{align*}
        i = 3 \\
        x = 1001\ 0101\ 0001_2 \\
        y = 1010\ 1101\ 0110_2 \\
        \cline{1-2}
        x < y \implies i:= 4
    \end{align*}
    
    \item
    Lastly, we write $\hat x^?$ to $branch$ and $free$.
    \begin{itemize}
        \item
        Row $rank$ of $branch$ will be:
        \begin{align*}
            \textbf{(a)}\quad branch\langle rank, 0 \dots h - 1 \rangle_{k \times 1} &:= 0^h\\
            \textbf{(b)}\quad branch\langle rank, h\rangle_{k \times 1} &:= x\langle j \rangle_1\\
            \textbf{(c)}\quad branch\langle rank, h + 1 \dots k - 1\rangle_{k \times 1} &:= branch\langle i, h + 1 \dots k - 1\rangle_{k \times 1}\\
            \cline{1-2}
            branch\langle rank \rangle_k &:=\underbrace{000010}_{\textbf{(c)}} \underbrace{0}_{\textbf{(b)}} \underbrace{0}_{\textbf{(a)}}
        \end{align*}
        
        \item
        Row $rank$ of $free$ will be:
        \begin{align*}
            \textbf{(a)}\quad free\langle rank, 0 \dots h - 1 \rangle_{k \times 1} &:= 1^h \\
            \textbf{(b)}\quad free\langle rank, h\rangle_{k \times 1} &:= 0 \\
            \textbf{(c)}\quad free\langle rank, h + 1 \dots k - 1\rangle_{k \times 1} &:= free\langle i, h + 1 \dots k - 1\rangle_{k \times 1} \\
            \cline{1-2}
            free\langle rank \rangle_k &:=\underbrace{111101}_{\textbf{(c)}} \underbrace{0}_{\textbf{(b)}} \underbrace{1}_{\textbf{(a)}}
        \end{align*}
    \end{itemize}

    We can see the updates described above in the tables from figure~\ref{fig:branchAndFreeAfterUpdatingValuesForRank}.
    \begin{figure}[H]
    \centering
    \input{04_Tables/028_branchAndFreeAfterUpdatingValuesForRank.tex}
    \caption[Example of $branch$ and $free$ after the insertion of a $\hat x^?$ ]{$branch$ and $free$ after the insertion of $\hat x^?$}
    \label{fig:branchAndFreeAfterUpdatingValuesForRank}
    \end{figure}
    
\end{enumerate}

\subsubsection{Storing the key} \label{sec:dontCaresInsert}

With $branch$ and $free$ now updated, we proceed with remaining insertion operations, which have been described in Section~\ref{sec:binaryRankInsert}.

\chapter{Correctness tests}

\section{{\ttfamily Util} class tests}

All the tests concerning the {\ttfamily Util} class can be found in the {\ttfamily UtilTest} class in the {\ttfamily src\textbackslash test\textbackslash java} folder.

\subsection{msb series tests}

The {\ttfamily Util} class contains many different implementations of the msb$(x)$ operation. Since Java's standard library offers a {\ttfamily numberOfLeadingZeros} function, we can easily test the different msb$(x)$ implementations. Converting the result from the standard library function is done by subtracting its return value to $w - 1$.

Taking as an example the test on the {\ttfamily msbConstant()} implementation, for such a test to pass all instances in a given range have to assert that {\ttfamily Long.SIZE - 1 - Long.numberOfLeadingZeros(i)} and {\ttfamily Util.msbConstant(i)} are the same. Tests on the other implementations differ only either on $w$ (which can be either 32-bit {\ttfamily Integer} or 64-bit {\ttfamily Long}) and the function that is called, and each of them is named after the function they are testing, e.g. {\ttfamily msb32Obvious()} tests the 32-bit version the naive msb$(x)$ algorithm.

\subsection{{\ttfamily splitLong} and {\ttfamily mergeInts}}

The {\ttfamily splitMerge()} method tests the {\ttfamily splitLong} and {\ttfamily mergeInts} methods by evaluating if the following property holds for a determined range of 64-bit keys: {\ttfamily key == mergeInts(splitLong(key))}.

\subsection{Fields of words tests}
The {\ttfamily getField} and {\ttfamily setField} methods are tested in the {\ttfamily setAndGetField32()} and {\ttfamily setAndGetField64()} methods (the latter differ solely on the size of the word where the fields are to be written to). A pass of the test consists of:
\begin{enumerate}
    \item
    Varying $f$ (being $f$ the size of each field) between one and $w - 1$.
    
    \item
    For each value $f$ takes, the number of fields to be stored in $A$, $m$, is computed as a function of $f$. The goal is to fit as many fields as possible in $A$, having $f$ and $w$ as constraints. This is done with the expression $m = w / f$.
    
    \item
    Then, $m$ keys of $f$ size are pseudo-randomly generated. Each time a key is generated, $A$ is shifted to the left by $f$ bits, and the key is stored both in an auxiliary array and in $A$ with the {\ttfamily setField} function. 
    
    \item
    When all $m$ keys have been generated and inserted, the auxiliary array is iterated, and at each iteration $i$, it asserts that the key at index $i$ in the auxiliary array is the same as the one returned by the {\ttfamily getField} function.
\end{enumerate}

\subsection{Test for Rank Lemma 1}
The {\ttfamily rankLemma1} function is tested in a method with the same name.
A pass in this test consists of:
\begin{enumerate}
    \item
    Varying $b$ (size in bits of each key). This range is specified in the fields of the {\ttfamily UtilTest} class.
    
    \item
    For each value $b$ takes, the number of keys to be stored in $A$, $m$, is computed by taking the minimum between $2^b$ and $w/b$. This is because the method requires that all keys stored in $A$ must be distinct (and all combinations of keys of size $b$ are given by $2^b$), but also $A$ can only store up to $w/b$ keys.
    
    \item
    We produce $m$ distinct keys by using a pseudo-random generator and inserting them in a set. We stop once the size of the set is $m$.
    
    \item
    An additional key $x$ is generated. The rank of $x$ will be computed and used later as one of the last checks of this test.
    
    \item
    The keys are then copied to a list, where they are sorted in descending order.
    
    \item
    The list is then iterated from the largest key to the smallest. Each iteration consists of inserting the current key in $A$. That key is also compared with $x$ in order to compute the rank of $x$, which is determined by the index of the current key in the list.
    
    \item
    The list is iterated once more in order to assess if the rank of each key in the list agrees with the rank computed with {\ttfamily rankLemma1} function.
    
    \item
    Lastly, the rank of $x$, which has been computed before, is compared with its rank computed via the {\ttfamily rankLemma1} function.
\end{enumerate}

\section{Integer Data Structure tests} \label{sec:IntegerDataStructureTests}

Each implementation of {\ttfamily RankSelectPredecessorUpdate} has a corresponding test class, which in turn has {\ttfamily Test} appended to its name. For example, the {\ttfamily BinarySearchTrie} test class is called {\ttfamily BinarySearchTrieTest} and it can be found in the {\ttfamily src\textbackslash test\textbackslash java} folder.

\subsection{Test parameters}

Each test class creates an instance of {\ttfamily RankSelectPredecessorUpdateTest} whose methods take a concrete implementation of {\ttfamily RankSelectPredecessorUpdate} to be tested. The constructor takes the following parameters:

\begin{itemize}
    \item {\ttfamily long seed}. This seed is used as a parameter for instantiating a pseudo-random generator from the Java standard library --- {\ttfamily java.util.Random}. This instance will be later used to produce data for the test cases, such as seeds for passes (explained below), which in turn will produce keys to be used in the tests.
    \item {\ttfamily int passes}. Some tests can be executed in more than one pass. A pass in a particular test consists of generating data with its corresponding seed and running the test with that data. When $passes > 1$, then different seeds are generated, which will result in different pseudo-random values, and the test is run {\ttfamily passes} number of times.
    \item {\ttfamily int numKeys}. This parameter defines the size of the data set to be generated. It is particular important for testing for instance {\ttfamily DynamicFusionNode}, which size cannot exceed $k$.
\end{itemize}

\subsection{{\ttfamily insertAndMemberSmallTest()}}
The methods tested in this test are {\ttfamily insert} and {\ttfamily member}. A small set of predetermined keys is inserted in the set, and then {\ttfamily member} is called on the set with each of those keys. 

\subsection{{\ttfamily smallCorrectnessTest()}}

An instance of a {\ttfamily RankSelectPredecessorUpdate} implementation is instantiated and keys are inserted such that after these insertions $S = \{10, 12, 42, -1337, -42\}$.

It is defined that:
\begin{itemize}
    \item
    Select queries can range between $0$ and $|S|-1$. Should any query fall outside this range, then {\ttfamily null} is returned, meaning, no result.
    \item
    $Select(0) = min\{y \in S \}$.
    \item
    $Select(|S|-1) = max\{y \in S\}$.
    \item
    Rank queries be any $w$-bit integer, and their possible range of results $\big[ 0, |S| \big]$
    \item
    Any given predecessor query returns the largest key in the subset of keys that are \textbf{strictly} smaller than the query, otherwise {\ttfamily null}.
    \item
    Whereas a successor query returns the queried key if present, otherwise the smallest key in the subset of keys that are larger than the query if any (and in such case {\ttfamily null} is returned).
\end{itemize}

With the given set and the above-mentioned rules, a small test is performed. Table~\ref{tab:smallCorrectnessTests} shows the expressions to be evaluated, and all of them must evaluate to {\ttfamily true} for the test to pass.

\begin{table}[H]
\centering
\input{04_Tables/002_CorrectnessTestSmall.tex}
\caption[Small correctness tests]{Small correctness tests.}
\label{tab:smallCorrectnessTests}
\end{table}


\subsection{{\ttfamily insertThenMemberTest()}}

The methods tested in this test are {\ttfamily insert} and {\ttfamily member}, and it can be executed in passes. It consists of:
\begin{enumerate}
    \item
    Iterating through all the pseudo-randomly-generated keys and inserting them all in the instance to be tested.
    \item
    Iterating in random order through all the keys and asserting $key \in S$.
\end{enumerate}

\subsection{{\ttfamily insertThenDeleteRangeOfKeysTest()}}

The methods tested in this test are {\ttfamily insert} and {\ttfamily member}. It consists of iterating the whole range (which goes from $0$ to {\ttfamily numKeys}), where each iteration {\ttfamily i} consists of:
\begin{enumerate}
    \item
    Asserting that the key, {\ttfamily i} is not in the set by calling {\ttfamily member} on the set with the key.
    \item
    Inserting the key {\ttfamily i} in the set.
    \item
    Asserting that the key {\ttfamily i} is in the set.
\end{enumerate}
Should the number of keys exceed 9, then every $1/10$ of {\ttfamily numKeys} the data structure is reset, and all keys are removed.

\subsection{{\ttfamily insertThenDeleteRandomKeysTest()}}

The methods tested in this test are {\ttfamily insert} and {\ttfamily delete}, and it can be executed in passes. After inserting all the pseudo-randomly-generated keys in the set, the keys are iterated in random order. Each iteration consists of:
\begin{enumerate}
    \item
    Asserting that $key \in S$.
    \item
    Removing the key.
    \item
    Asserting that $key \not\in S$.
\end{enumerate}

\subsection{{\ttfamily deleteTest()}}

This test aims at asserting that only when deleting an existing key, the cardinality of the set is altered. It tests the methods {\ttfamily delete} and size, and it can be executed in passes. At each pass:
\begin{enumerate}
    \item
    Pseudo-random keys are generated and delete on the set is called with that key.
    \item
    If the key was in the set, then the size must have decreased; otherwise, it must remain the same.
\end{enumerate}

\subsection{{\ttfamily sizeTest()}}

The methods tested in this test are {\ttfamily insert}, {\ttfamily size} and {\ttfamily delete} and it can be executed in passes. Each pass consists of:
\begin{enumerate}
    \item
    Iterating the pseudo-randomly-generated keys in random order. At each iteration, the key is inserted, and it is asserted that {\ttfamily size} has increased by 1.
    \item
    After all the keys have been inserted, the keys are iterated in random order once more, and at each iteration, the key is removed, and it is asserted that {\ttfamily size} has decreased by 1.
\end{enumerate}

\subsection{{\ttfamily growingRankTest()}}

This test aims at ensuring that the following property holds for all the keys in the set: the rank of keys in sorted order is a monotone increasing function. It can be executed in passes, and it works the following way:
\begin{itemize}
    \item
    After inserting all the keys in the set, a copy of those keys is kept on a {\ttfamily TreeSet} (a set that keeps its values in sorted order) such that we can iterate them in their sorted order.
    \item
    A counter {\ttfamily i} is kept and initialized as $0$. It is incremented at each iteration.
    \item
    The test then asserts that the key's rank is the same as the number of the current iteration. Note that we can assume that this condition must hold because the keys are iterated in sorted order. 
\end{itemize}

\subsection{{\ttfamily selectOfRankTest()}}

This test aims at ensuring that the following property holds for all the keys in the set: if a key is present in the set, knowing its rank and them querying for select of that must return the key. It can be executed in passes, and it works by iterating through the pseudo-randomly-generated keys, and at each iteration, it is asserted that {\ttfamily key == select(rank(key))}.

\subsection{{\ttfamily rankOfSelectTest()}}

This test aims at ensuring that the following property holds for all the keys in the set: the rank of select a query is the query. It can be executed in passes, and it works by iterating from {\ttfamily 0} to {\ttfamily numKeys}. At each iteration {\ttfamily i}, it is asserted that {\ttfamily i == rank(select(i))}.

\chapter{Validation}

mention what and which implementations pass which tests and why this shows that there is a certain degree of certainty that they are correct.
