% \part{Implementation}

% \addsec{Unnumbered level}

% \section{First level}
% \subsection{Second level}
% \subsubsection{Third level}
% \paragraph{Forth level}
% \subparagraph{Fifth level}

% \subsection{Dummy subsection}

% This is some text to showcase the features of this thesis template. For example, it is possible to add a side note with\myMarginnote{I am a side note!}.

% In this paragraph, I will add an image as a template:
% \begin{figure}[H]
% \centering
% 	\includegraphics[width=0.9\textwidth]%
% 	{03_GraphicFiles/CowLickingNose.jpg}%
% \caption[A cow]{A cow licking its nose. Usage with permission of the photographer \textsc{Nicole Barth}, taken from \url{www.flickr.com/photos/46311827@N07/14885545396}.}
% \label{fig:CowLickingNose}
% \end{figure}

% In \figurename~\ref{fig:CowLickingNose}\myMarginnote{Reference to a figure} you see a cow that is licking its nose. The picture was taken by Nicole Barth on 11.08.2014 using a Canon EOS 500D. The original file has a resolution of $4247 \times 2831$ pixels.
% Note that the image is also referenced.

\chapter{Background} \label{sec:backgroundChapter}

The \cite{patrascu2014dynamic} paper presents a data structure for solving the dynamic predecessor problem and claims that its running times are optimal.
In this chapter, a series of data structures, techniques, and other relevant aspects will be presented, laying the foundation for the implementation of the data structure presented by Pătrașcu and Thorup.

\section{Basic Concepts}

\subsection{Word} \label{sec:word}
A word consists of a $w$-bit integer.
The bits which a word is comprised of are indexed from the least (right) to the most (left) significant bit, having the least significant bit index $0$, whereas the most significant has index $w-1$.
The universe of all possible keys, denoted by $\mathcal U$, has size $u = 2^{w}$ thus we are bound to an universe $\mathcal U = \{0, 1, ..., 2^{w}-1\}$, e.g., all combinations of $w$-bit words.

Since we will be implementing algorithms and data structures on a modern computer, we set $w = 64$. We might use different values of $w$ for illustration purposes, but the implemented programs will be working with the value defined here unless stated otherwise.

\subsection{The Predecessor Problem} \label{sec:predecessorProblem}
Data structures that maintain a set $S$ of (integer) keys and enable the following operations are said to solve the static predecessor problem \cite{beame1999optimal}:
\begin{itemize}
    \item
    $\text{member}(x)$ returns {\ttfamily true} if $x \in S$ and {\ttfamily false} otherwise.
    
    \item
    $\text{predecessor}(x)$ returns $\text{max}\{y\in S\ |\ y < x\}$.
    
    \item
    $\text{successor}(x)$ returns $\text{min}\{y\in S\ |\ y \geq x\}$.
\end{itemize}

The predecessor problem can also be dynamic if the said data structure also allows \cite{beame1999optimal}:
\begin{itemize}
    \item
    $\text{insert}(x)$ sets $S=S \cup \{x\}$.
    
    \item
    $\text{delete}(x)$ sets $S=S \setminus \{x\}$.
\end{itemize}

In this context, the following operations might also be relevant:
\begin{itemize}
    \item
    $\text{rank}(x)$ returns $\#\{ y \in S\ |\ y < x\}$.
    \item
    $\text{select}(i)$ returns $y \in S$ with $\text{rank}(y) = i$, if any.
\end{itemize}

The data structure presented in \cite{patrascu2014dynamic} implements all of the above. The publication also mentions the following invariants:
\begin{itemize}
    \item
    $\text{predecessor}(x) = \text{select}(\text{rank}(x - 1))$
    \item
    $\text{successor}(x) = \text{select}(\text{rank}(x))$
\end{itemize}

\subsection{Models of Computation} \label{sec:modelsofcomputation}

In order to analyze and describe running times, computer scientists use models of computation. Each model states which operations have an associated cost and which ones do not.
In the models used here, all the given operations either have one unit of cost or none.

Despite their theoretical relevance, when having a data structure and its operations measured against wall clock, one might be surprised with the results.
This is because theoretical bounds have the potential to hide big constants, which are brought to light when wall clock measurements are performed.
Nevertheless, we will enumerate some models of computation, as many of the data structures here presented have their running times described in terms of a given model, and therefore, it is of interest to provide this context.

The models are presented in descending order from strongest to the least strong. This means that a less restrictive model, such as the cell-probe model, is more suited to describe the theoretical lower bounds of a data structure than the weaker ones \cite{erikdemainelec11}.

\subsubsection{The Cell-Probe Model}
In the cell-probe model, memory is divided into cells of size $w$, a parameter of the model.
The only operations that come with an associated cost are reading or writing to memory, which are the memory accesses.
Due to its simplicity, as stated in \ref{sec:modelsofcomputation}, it is widely used to prove lower bounds \cite{erikdemainelec11}.

\subsubsection{Trans-dichotomous RAM} \label{sec:transdichotomousRAM}
In the trans-dichotomous RAM model, memory consists of an array of size $S$ of $w$-bit words.
Reading or writing to one of the memory cells costs $O(1)$.
Additionally, memory cells can be used as pointers to other cells, e.g., a single $w$-bit word can be used to access another cell.
This implies that the word length $w$ has to be large enough to be able to index all cells in the memory.
Let the problem size be $n$:
\begin{equation} \label{eq:problemSize}
    w \ge \log_2(S) \implies w \ge \log_2(n)
\end{equation}

Let us take a concrete example:
\begin{align*}
    &w = 4 \\
    \cline{1-2}
    &w = 4 \geq \log_2(n) \\
    \implies &2^4 \geq n \\
    \implies &16 \geq n
\end{align*}
We can see that if $w = 4$, then we can at most index $16$ keys. This is sound because in binary representation of integers, with $4$ bits, we can produce $16$ different combinations of those bits, e.g., $2^4$ combinations. This is exactly what expression~\ref{eq:problemSize} means: having a set word length defines the maximum number of keys we can index with a single word.

This model gets its name because it relates two dichotomies: problem size $n$; and the model of computation with words of size $w$ \cite{erikdemainelec11}. 

\subsubsection{Word RAM} \label{sec:wordRAM}
Like the trans-dichotomous RAM model, the word RAM also operates with fixed size $w$-bit words. Additionally, the following operations have an associated cost \cite{nelsonjelanilec1}:
\begin{itemize}
    \item Integer arithmetic (addition $+$, subtraction $-$, multiplication $\times$, division $\div$ and remainder of division (modulo) $\bmod$);
    \item Bitwise operations (negation $\neg$, and $\wedge$, or $\vee$, exclusive or $\oplus$);
    \item Bitwise shifting operations (right bit-shift $\gg$, left bit-shift $\ll$).
\end{itemize}

\newpage
\section{Predecessor Problem Data Structures} \label{sec:IntegerSets}

This section highlights some data structures that maintain integer sets and implement the (dynamic) predecessor problem, e.g., integer sets whose methods answer the queries mentioned in Section~\ref{sec:predecessorProblem}.
The data structures are ordered by what they improve on from the previous, or by complexity because they add a new way of looking at the problem.
We will also analyze, on a high level, their running times, and how the queries can be implemented.
Note that we do not need to be concerned about the successor and predecessor queries for most of them, as they can be trivially implemented by using the definitions from Section~\ref{sec:predecessorProblem}.

\subsection{Array} \label{sec:array}

Perhaps the most naive way to maintain a set of integers is to implement it while having an underlying array. By ensuring that the array is always sorted after updates, we know that select queries are implemented by returning the key at the specified index, while rank queries are implemented by doing a binary search. These queries take $O(1)$ and $O(\log_2 n)$ time, respectively. Updating, e.g., inserting and deleting, would take $O(n)$ time because:
\begin{enumerate}
    \item
    We would first need to find the rank of the key to be inserted (or deleted), $i$.
    
    \item
    And then, all the keys whose rank is larger than $i$ would have to be moved by one position in the array. For insertion, those keys would have to be moved to the right; for deletion, those keys would have to be moved to the left.
\end{enumerate}

\subsection{Red-Black BST}

Using a self-balancing Binary Search Tree to implement the set, such as a red-black tree, could improve the running times quite substantially.
This data structure guarantees $O(\log_2 n)$ for all of the dynamic predecessor problem queries.
When searching, this guarantee is given by the height invariant of the tree, which is always $O(\log_2 n)$ \cite{cormen2009introduction}.
Updates consist of:
\begin{enumerate}
    \item
    Searching, which takes $O(\log_2 n)$ time.
    
    \item
    Once the rightful place of the key in the tree is found, a $O(1)$ number of operations take place in order to maintain the invariant of the tree. 
\end{enumerate}

Another advantage of this data structure is that, since the elements are sorted internally, select and rank queries can be trivially implemented by storing the size of each subtree at every node, which is then used to compute the result from those queries.

\subsection{Binary Search Tries}

The previous two data structures use comparison-based algorithms to order the keys internally, e.g., searching entails comparing the keys' full length.
Radix algorithms take a different approach by examining portions of the key.
Tries are radix-based data structures where the path from the root to a particular node is the prefix of the keys stored at the subtree rooted at that node.
In this context, we will use them to store words (as defined in Section~\ref{sec:word}), but they can be used to store other types of data, for instance, strings, which can be of fixed or variable length.
The chosen radix is related to the data we want to store in the Trie: for instance, when storing strings written with the English alphabet, the radix is 26, whereas in our case, base two integers, the radix is 2. Bitwise Tries can also denote Tries of radix two.

A Binary Search Trie is a Trie for storing integer words, where the keys are kept at leaf nodes. We use the bit values of a key to guide us when searching the following way: starting from the most significant bit of the key,
\begin{itemize}
    \item
    If the bit value is $0$, then we take the left child node.
    \item 
    Otherwise, we take the right one.
\end{itemize}

We then consider the following less significant bit of the search key and repeat until the search ends.
This happens when either we hit a leaf or a null link.
A successful search is when the search key and the key at the leaf node were the same.
An unsuccessful search is when either we end up on a null link or the search key, and the key at the leaf node are not the same.
This last case happens when those keys share a prefix.

We can infer from the search algorithm's description that this data structure uses a considerable amount of space for storing paths consisting of prefixes shared among keys.

Since this tree is ordered and balanced, and even though it will have on average $44\%$ more nodes than keys, searching and inserting take on average $O(\log_2 n)$ time for random and distinct keys, but the length of the keys bounds the worst-case running time, $O(w)$ \cite{sedgewick2002algorithms}.
Rank and select queries are implemented with a similar approach as in the red-black tree: every node has the number of leaf nodes stored in its fields, which is used for these queries.

\subsection{Patricia Tries}

Patricia Tries, which name is an acronym for "practical algorithm to retrieve information coded in alphanumeric", also known as compressed Binary Tries, improve the space consumption in comparison with Binary Search Tries \cite{sedgewick2002algorithms}.
They embody a different way to encode the same Trie abstraction as Binary Search Tries.
They achieve this by allowing the internal nodes to store keys and by compressing the paths between nodes.
Each node will have an associated branching bit stored, allowing us to skip the bits that belong to shared prefixes, fast-forwarding to the branching bits.
The result is a Trie with exactly as many nodes as there are keys, which also improves the worst running times of updating and querying from $O(w)$ to $O(\log_2 n)$ \cite{sedgewick2002algorithms}.

\subsection{van Emde Boas Trees}

The van Emde Boas tree (vEB) data structure, despite its excessive space consumption ($O(u)$), introduces a big running time improvement, as all queries take $O(\log_2 w)$.
If, as discussed in Section~\ref{sec:word}, $u = 2^w$ is the size of the universe of keys we can store in this data structure, then we can also express the running time as being $O(\log_2(\log_2 u))$.
This means that queries are now sub-logarithmic, a substantial improvement from all the data structures we have seen so far.
It uses the fact that the keys themselves can be used as memory addresses to access other keys \cite{nelsonjelanilec1}.

The intuition behind this data structure is to superimpose a Binary Tree structure on a bit-vector.
The bit values in this bit-vector will be $0$ if the key at that index is not in the set, and $1$ otherwise.
To build the Binary Tree, we assume that each position of the bit-vector is a leaf.
To compute the parent nodes of the leaf nodes, we take the bitwise $\vee$ of each consecutive pair of positions.
We then do the same for the next level, taking the nodes that we just computed as the children and repeating until we reach the root.
If the set contains at least one key, then the value at the root will be $1$; otherwise, it will be $0$.
This rule also applies to each of the subtrees \cite{bille2020massive}.
On this preliminary example:
\begin{itemize}
    \item
    To find the minimum, starting at the root, we traverse the tree by always taking the left child if that node is $1$. Otherwise, we take the right child.
    
    \item
    To find the maximum, we do the same as in finding the minimum, but giving preference to the right child.
    
    \item
    To find the successor, we would start at the leaf node of our query and go up the tree until we find a node whose right child we have not visited and whose value is $1$. The successor of our query is the minimum of the subtree rooted at that node.
    
    \item
    Finding the predecessor will be similar to the successor: we find the maximum of the subtree whose root's left child we have not visited and had the value $1$ when going up the tree from the query's leaf node.
    
    \item
    Searching is done in $O(1)$ time, as we have direct access to the bit-vector.
    
    \item
    To update, e.g., inserting and deleting, we have to update the bit value in the bit array and the nodes above that position.
\end{itemize}

All the mentioned operations, except for searching, take $O(\log_2 u)$ time. 

To improve this and achieve the sub-logarithmic running times, we superimpose a tree of varying degrees on the bit-vector.
The value of the root node will be the summary of the whole range. Its children will cover $u^{1/2}$, and its grandchildren $u^{1/4}$.
If at each level we store the minimum, the maximum, and a summary of the vEB trees below, we can compute queries in $O(\sqrt{w})$ time plus a constant number of operations, $O(1)$.
Thus we have the following recurrence relation: $\text{T}(u) = \text{T}(\sqrt{u}) + O(1)$, resulting in a running time for the whole tree of $O(\log_2(\log_2 u))$ \cite{erikdemainelec11}.

As mentioned, van Emde Boas trees have the space complexity drawback: $O(u)$.
This is due to the bit-vectors used, which in total allocate space for all the possible keys in the universe, $\mathcal U$.

\subsection{Fusion Trees}

The Fusion Trees description we summarize here is based on the \cite{nelsonjelanilec2} and \cite{erikdemainelec12} lectures.

Fusion Trees are understood as $k$-ary trees, e.g., each node stores roughly $k$ keys.
We define $k = \Theta(w^{1/5})$.
With this definition, the height of the tree will be $O(\log_w n)$.
This is also the running time for querying in a Fusion Tree.
So the problem we have to solve is to ensure that searching within nodes takes only $O(1)$ time.
This way, the overall data structure's query time will be the same as the bound of the tree's height.

In the word RAM model, and having set $k = \Theta(w^{1/5})$, each node will require $k \cdot w = w^{6/5}$ bits to store all the keys.
This means that, without any additional tools and algorithms, we cannot process each node in $O(1)$ time.

Fusion Nodes only use algorithms based on word RAM operations, listed in Section~\ref{sec:wordRAM}, such that we can query a Fusion Node with $O(1)$ number of operations.
The first challenge is to fit $w^{6/5}$ bits in a word, such that we can use this result to query the node.

\subsubsection{Pre-processing Phase}

Since this is a static data structure, we use the pre-processing phase to build the $k$-ary tree with the given set of keys, disregarding its running time.
Upon its construction, each node will contain at most $k$ keys.

\paragraph*{Bitwise Binary Tree Abstraction}\label{par:bitwiseTrieAbstraction} We note that, for any given node, when looking at the keys' values in binary and building a Bitwise Trie with the keys at that node, we need only to know at most $k - 1$ bit indices in order to differentiate its keys.
These are the branching bits in the Bitwise Trie built with those keys.


Let $x$ be a key in the Fusion Node, a \textit{sketching} function, $\text{sketch}(x)$ is defined by keeping only the branching bits of $x$, as we have just defined.

We note that the sketches of the keys have the same order as the keys.
Note also that if the \textit{sketching} needs at most $k - 1$ bits per key in the node, then in total, we need $k \cdot (k - 1) = O(w^{2/5})$ bits to store all the bits of the key sketches; thus we can fit that in a single word, which is kept at each node.

Because it is difficult to compute perfect \textit{sketches} (defined in the paragraph above) in $O(1)$ time using only word RAM operations, an \textit{approximate sketch} is used instead.
The key difference between the \textit{perfect sketches} and \textit{approximate sketches} is the amount of bits used to store the \textit{sketches} of the keys: \textit{approximate sketches} use at most $(k - 1)^4 = O(w^{4/5})$ instead of the  $O(w^{2/5})$ bits of the \textit{perfect sketches}.
By using \textit{approximate sketches}, we can define constants and masks to be kept at each node that will help us define a function that will return us the \textit{approximate sketch} of a query in $O(1)$ time.
This is also the reason for the choice of the value $k = w^{1/5}$.

\subsubsection{Querying} \label{sec:fusionTreeQuerying}

At this stage, we know that we have pre-computed all the \textit{sketches} of the keys at every node.

To query in a Fusion Node, we need to be able to find the rank of a \textit{sketch} within a word containing the \textit{sketches} the keys in that node.
To do so, we use the Rank Lemma 1 algorithm, thoroughly described in Section~\ref{sec:rankLemma1}.

There is a scenario where we might query a key that does not belong in the node, thus computing the \textit{sketch} of such key might produce a result that does not reflect the order of the keys.
This happens when the queried key branches at a node whose corresponding bit was not considered in the \textit{sketching} function.

Assume that we wish to query a key $q$ among the set of keys in a Fusion Node, $\{x_0, x_1, \dots, x_i\}$.
Computing the rank of $\text{sketch}(q)$ among the \textit{sketches} of the keys at that node will give us other two keys in the node, $x_i$ and $x_{i+1}$, such that $\text{sketch}(x_i) < \text{sketch}(q) < \text{sketch}(x_{i+1})$.
As mentioned, this does not mean that $x_i < q < x_{i+1}$, but by computing the index of the bit where $q$ branched from those keys, $y$, we can learn where $q$ lies among all the other keys in the node.
We achieve this by computing a mask, $e$, that:
\begin{itemize}
    \item
    If $q$ branched to the right in $y$, e.g., bit $y$ was $1$ in $q$, then $e = y011\dots1$;
    
    \item
    Otherwise if $q$ branched to the left, then $e = y100\dots1$.
\end{itemize}
A claim states that finding where $\text{sketch}(e)$ fits among the \textit{sketches} of the keys at that node is the same as where $q$ fits among the keys in the node, thus solving the problem \cite{nelsonjelanilec2}.

Learning the most significant set bit of a word in $O(1)$ time will also play an important role when querying. An algorithm that achieves this has been thoroughly described in Section~\ref{sec:msbO1}.
Let $\text{msb}(z)$ denote the function that returns the most significant set bit of a word, $z$. After finding one of the $x_i$'s (described above), we can easily find the branching bit, $y$, the expression:
\begin{align*}
    y = \text{msb}(x_i \oplus q)
\end{align*}

By knowing where query $q$ fits among the keys in the node, the remaining operations are trivially implemented, thus completing the description of Fusion Trees with $O(\log_w n)$ query time.

\subsection{Summary}

Table~\ref{tab:dataStructComparison} is a summary of relevant data structures that incrementally lead to the data structure presented in this project. The running times are given in the word RAM model.

\begin{table}[H]
\centering
\input{04_Tables/001_DataStructuresComparison.tex}
\caption[Predecessor problem data structure comparison]{Data structures used to solve the predecessor problem and their respective theoretical running times}
\label{tab:dataStructComparison}
\end{table}

\newpage
\section{Summary of Techniques used in the Present Implementation} \label{sec:summaryOfTechniques}

All of the algorithms presented in this section have been implemented as static functions in the {\ttfamily Util} class, present in the repository.

\subsection{Bit Operations} \label{sec:bit}

Let $A$ be a $w$-bit length word. This section features a set of functions that operate on $A$'s bits. Since these operations only use bitwise shifting and masking, all the algorithms presented in this section take $O(1)$ time.

\subsubsection{Is the Bit Set}

This operation aims at extracting the bit at position $d$ in $A$ or, in other words, getting the value of the bit at position $d$. Let us denote this operation by $\text{bit}(d, A)$. We have:
\begin{align*}
    \text{bit}(d, A) = (A \gg d) \wedge 1
\end{align*}

Example:
\begin{align*}
    w = 16\\
    d = 8\\
    A = 0101\ 110\underline{1}\ 1100\ 0111_2& \\
    \text{bit}(8,A) = (0101\ 110\underline{1}\ 1100\ 0111_2& \gg 8) \wedge 1 \\
    \cline{1-2}
    \text{bit}(8,A) = 0000\ 0000\ 0101\ 110\underline{1}_2& \\
    \wedge\ 0000\ 0000\ 0000\ 000\underline{1}_2 \\
    \cline{1-2}
    \text{bit}(8,A) = 1 &
\end{align*}

\subsubsection{Set Bit}
This operation sets the bit at position $d$ in $A$ to $1$. Let us denote this operation by $\text{setBit}(d, A)$. We have:
\begin{align*}
    \text{setBit}(d, A) = A \vee (1 \ll d)
\end{align*}

Example:
\begin{align*}
    w = 16\\
    d = 4\\
    A = 0101\ 1101\ 110\underline{0}\ 0111_2& \\
    \text{setBit}(4,A) = 0101\ 1101\ 110\underline{0}\ 0111_2& \vee (1 \ll 4) \\
    \cline{1-2}
    \text{setBit}(4,A) = 0101\ 1101\ 110\underline{0}\ 0111_2& \\
    \vee\  0000\ 0000\ 000\underline{1}\ 0000_2& \\
    \cline{1-2}
    \text{setBit}(4,A) = 0101\ 1101\ 110\underline{1}\ 0111_2&
\end{align*}
Note that, if the bit a index $d$ is alredy set, then $A$ is returned unchanged.

\subsubsection{Delete Bit}
This operation sets the bit at position $d$ in $A$ to $0$. Let us denote this operation by $\text{deleteBit}(d, A)$. We have:
\begin{align*}
    \text{deleteBit}(d, A) = A \wedge \neg(1 \ll d)
\end{align*}

Example:
\begin{align*}
    w = 16\\
    d = 6\\
    A = 0101\ 1101\ 1\underline{1}00\ 0111_2& \\
    \text{deleteBit}(6,A) = 0101\ 1101\ 1\underline{1}00\ 0111_2& \wedge \neg(1 \ll 6) \\
    \text{deleteBit}(6,A) = 0101\ 1101\ 1\underline{1}00\ 0111_2&\\
    \wedge\ \neg(0000\ 0000\ 0\underline{1}00\ 0000_2&) \\
    \cline{1-2}
    \text{deleteBit}(6,A) = 0101\ 1101\ 1\underline{1}00\ 0111_2& \\
    \wedge\ 1111\ 1111\ 1\underline{0}11\ 1111_2 \\
    \cline{1-2}
    \text{deleteBit}(6,A) = 0101\ 1101\ 1\underline{0}00\ 0111_2&
\end{align*}
Note that, if the bit a index $d$ is alredy $0$, then $A$ is returned unchanged.

\newpage
\subsection{Masks} \label{sec:masks}

Pătrașcu and Thorup refer constants that we will denote by masks, which are useful for bitwise operations. In this section, we will see how we can compute them.

\begin{itemize}
    \item
    The mask $0^{w-j} 1^j_2$ consists of a word with the $w-j$ most significant bits set to $0$, and the least $j$ significant bits set to $1$. It is useful, for instance, to mask the first $j$ least significant bits of a word and it is computed with the expression:
    \begin{align*}
        0^{w-j} 1^j_2 = (1 \ll j) - 1
    \end{align*}
    Example:
    \begin{align*}
        w &= 16\\
        j &= 4\\
        \cline{1-2}
        0^{16-4} 1^4_2 &= (1 \ll 4) - 1\\
        &= (0000\ 0000\ 0000\ 0001_2 \ll 4) - 1\\
        &= 0000\ 0000\ 0001\ 0000_2 - 1\\
        &= \underbrace{0000\ 0000\ 0000}_{w-j}\ \underbrace{1111}_{j}{}_2
    \end{align*}
    Note that when $j = w$, then this mask is simply $-1$, because in the two's complement, the binary representation of $-1$ is $1^w$.
    
    \item
    The mask $1^{w-j} 0^j_2$ consists of a word with $w-j$ significant bits set to $1$, and the least $j$ significant bits set to $0$. For instance, it is useful to mask the first $w - j$ most significant bits of a word. It is easily computed by negating the result from the previous expression:
    \begin{align*}
        1^{w-j} 0^j_2= \neg((1 \ll j) - 1)
    \end{align*}
    Example:
    \begin{align*}
        w &= 16\\
        j &= 4\\
        \cline{1-2}
        1^{16-4} 0^4_2 &= \neg((1 \ll 4) - 1)\\
        &= \neg((0000\ 0000\ 0000\ 0001_2 \ll 4) - 1)\\
        &= \neg(0000\ 0000\ 0001\ 0000_2 - 1)\\
        &= \neg0000\ 0000\ 0000\ 1111_2\\
        &= \underbrace{1111\ 1111\ 1111}_{w-j}\ \underbrace{0000}_{j}{}_2
    \end{align*}
    Note that when $j = w$, then this mask is simply $0$.
\end{itemize}

\newpage
\subsection{Fields of Words} \label{sec:fieldsOfWords}

We follow the definitions from \cite{patrascu2014dynamic} in regards to viewing words as sets of fields of some length $f \leq w$. Let $A$ be a $w$-bit length word, then if $A$ is comprised of fields, analogously to bit indexing of a word, its least significant field is the rightmost one, denoted $A\langle0\rangle_f$; its most significant field is the leftmost one, denoted $A\langle \lfloor w/f \rfloor \rangle_f$, and so on.
Note that the functions presented in this section consist of simple bitwise shifting and masking with the expressions defined in \ref{sec:masks}. Regarding running times, all these algorithms take $O(1)$ time.

\subsubsection{Field Retrieval} \label{sec:fieldRetrieval}

This operation consists of retrieving field $A\langle i\rangle_f$ and it is denoted by $\text{getField}(i, f, A)$. It is defined by:
\begin{align*}
    \text{getField}(i, f, A) = (A \gg (i \times f)) \wedge ((1 \ll f) - 1)
\end{align*}

Example:
\begin{align*}
    i = 1\\
    f = 4\\
    A = 0101\ 1101\ \underline{1100}\ 0111_2& \\
    \text{getField}(1, 4, A) = (0101\ 1101\ \underline{1100}\ 0111_2& \gg (\underbrace{1 \times 4}_{4})) \wedge (\underbrace{(1 \ll 4) - 1}_{1111_2})\\
    \cline{1-2}
    \text{getField}(1, 4, A) = 0000\ 0101\ 1101\ \underline{1100}_2& \\
    \wedge\ 0000\ 0000\ 0000\ 1111_2& \\
    \cline{1-2}
    \text{getField}(1, 4, A) = 0000\ 0000\ 0000\ \underline{1100}_2&
\end{align*}

A range of fields can be retrieved in a single operation. We denote by $\text{getFields}(i, j, f, A)$ the operation consisting of the retrieval of the fields $\{A\langle i\rangle_f,\dots , A\langle j-1\rangle_f\}$, which is defined by:
\begin{align*}
    \text{getFields}(i, j, f, A) = (A \gg (i \times f)) \wedge ((1 \ll ((j - i) \times f)) - 1)
\end{align*}

Example:
\begin{align*}
    i = 1\\
    j = 3\\
    f = 4\\
    A = 0101\ \underline{1101}\ \underline{1100}\ 0111_2& \\
    \text{getFields}(1, 2, 4, A) = (0101\ \underline{1101}\ \underline{1100}\ 0111_2& \gg (\underbrace{1 \times 4}_{4})) \wedge (\underbrace{(1 \ll ((3 - 1) \times 4)) - 1}_{1111\ 1111_2})\\
    \cline{1-2}
    \text{getFields}(1, 2, 4, A) = 0000\ 0101\ \underline{1101}\ \underline{1100}_2&\\
    \wedge\ 0000\ 0000\ 1111\ 1111_2 \\
    \cline{1-2}
    \text{getFields}(1, 2, 4, A) = 0000\ 0000\ \underline{1101}\ \underline{1100}_2&
\end{align*}

We can also specify a lower field and retrieve all the fields from that position up to the end of the word. This is denoted by $\text{getFields}(i, f, A)$ and it is defined by:
\begin{align*}
    \text{getFields}(i, f, A) = A \gg (i \times f)
\end{align*}

Example:
\begin{align*}
    i = 2\\
    f = 4\\
    A = \underline{0101}\ \underline{1101}\ 1100\ 0111_2& \\
    \text{getFields}(2, 4, A) = \underline{0101}\ \underline{1101}\ 1100\ 0111_2& \gg (\underbrace{2 \times 4}_{8})\\
    \cline{1-2}
    \text{getFields}(1, 2, 4, A) = 0000\ 0000\ \underline{0101}\ \underline{1101}_2&
\end{align*}

\subsubsection{Field Assignment}

Conversely, it is also possible to assign a value to a particular field. To do so, a mask $m$ is required, and it is computed as a function of $i$ (the position of the field to be set) and $f$ (the length of the fields in $A$). Thus we have:
\begin{align*}
    m = ((1 \ll f) - 1) \ll (i \times f)
\end{align*}
 Setting field $y$ in $A$, denoted by setField$(i, y, f, A)$, is defined by:
\begin{equation*}
    \text{setField}(i, y, f, A) = \underbrace{(A \wedge \neg m)}_{\text{(a) Reset field}} \vee \ \underbrace{(y \ll (i \times f) \wedge m)}_{\text{(b) Set field}}
\end{equation*}
Example:
\begin{align*}
    i = 1\\
    y = 1001_2\\
    f = 4\\
    m = (\underbrace{(1 \ll 4)  - 1} _{1111_2}) \ll (\underbrace{1 \times 4}_{4}) = 0000\ 0000\ 1111\ 0000_2\\
    A = 0101\ 1101\ \underline{1100}\ 0111_2& \\
    \cline{1-2}
    \text{(a)}\quad A \wedge \neg m = 0101\ 1101\ \underline{1100}\ 0111_2 \\
    \wedge\ 1111\ 1111\ 0000\ 1111_2\\
    \text{(a)}\quad = 0101\ 1101\ 0000\ 0111_2\\
    \cline{1-2}
    y \ll (1 \times 4) = 0000\ 0000\ 0000\ \underline{1001}_2& \ll 4\\
    = 0000\ 0000\ \underline{1001}\ 0000_2\\
    \text{(b)}\quad (y \ll 4) \wedge m = 0000\ 0000\ \underline{1001}\ 0000_2\\ 
    \wedge\ 0000\ 0000\ 1111\ 0000_2\\
    \text{(b)}\quad = 0000\ 0000\ \underline{1001}\ 0000_2\\
    \cline{1-2}
    \text{setField}(1, y, 4, A) = \text{(a)} \vee \text{(b)} = 0101\ 1101\ \underline{0000}\ 0111_2\\
    \vee\ 0000\ 0000\ \underline{1001}\ 0000_2 \\
    \cline{1-2}
    \text{setField}(1, y, 4, A) = 0101\ 1101\ \underline{1001}\ 0111_2&
\end{align*}

\newpage
\subsection{Most Significant Set Bit} \label{sec:msbAlgorithm}

Learning about the most significant set bit of a word will be an important operation in the implementation. For this reason, we will look at different ways to achieve this result. Since it is to be used as a subroutine in certain operations, it has the potential to become a bottleneck if not implemented carefully. We denote the most significant set bit of $x$ by msb$(x)$.

\subsubsection{Naive}

The simplest way to achieve the intended outcome is to loop through the word until the first non-zero bit is found, returning the word length minus the number of iterations that it took to find that bit.

This approach takes $O(w)$ time.

\subsubsection{Lookup}

In this approach, a lookup table containing the most significant bit answers for all combinations of 8 bits is pre-computed.

When a query comes, it is iterated in fields of 8 bits, starting from the most significant field. If that field is not $0$, then the most significant bit of the queried word lies in that block.
In this case, the answer will be the most significant set bit of that field plus all the bits in the non-iterated fields. Since the answer to any combination of 8 bits is pre-computed, we know the answer in constant time.

Otherwise, if the most significant field is $0$, the algorithm looks at the second most significant field and does the same operation as described in the previous paragraph.
It will iterate the fields until a non-zero is found, returning the answer which is given by the lookup table and the position of the field where the first non-zero bit was found.

This approach takes $O(1)$ time after the lookup table has been computed but, not only the lookup table takes time to compute, it also uses some space.

\subsubsection{Constant Time with Parallel Comparison} \label{sec:msbO1}

This operation here described is based on the materials from the lectures whose scribe notes are \cite{nelsonjelanilec2} and \cite{erikdemainelec12}.
It comprises four main steps.
Let $x$ be the query for the most significant set bit:
\begin{enumerate}
    \item
    We divide $x$ in $\sqrt{w}$ fields of $\sqrt{w}$ bits. The goal is to \textit{summarize} the fields in $x$ such that if a field is not empty, then its summary is $1$, and it is $0$ otherwise.
    
    \item
    We \textit{compress} the summary such that it fits in a single $\sqrt{w}$-bit field. A bitwise shift operation is also carried in order to compute a word containing the resulting summary on its least significant field.
    
    \item \label{blt:O1parallel3}
    Then we do \textit{parallel comparison} of the summary word to find the first non-empty field of $x$ because it will be that field that contains the most significant bit of $x$.
    
    \item
    We use the same technique as in step~\ref{blt:O1parallel3}, but now on the first non-empty field of $x$. We end with simple arithmetic to return the most significant set bit. 
\end{enumerate}

This approach takes $O(1)$ time and requires a small lookup table of $\sqrt{w}/2$ size, which can easily be explicitly stored together with the algorithm.

We now run a small example where every step is illustrated. For simplicity, let $w=16$. This implies that we have $\sqrt{16} = 4$ fields of $4$ bits each. Let us also assume that our query is $x = 0101\ 0000\ 1000\ 1101_2$.

\paragraph{Step 1 --- Summarize the query fields} \label{sec:summaryfields}

The goal of this step is to compute a summary word of $w$ size, whose leading bit of each of its $\sqrt{w}$-bit fields is a summary of each $\sqrt{w}$-bit field of the query word $x$. If in a given field, the leading bit in the summary word is $1$, then that field in $x$ was not empty (one or more bits were set), and vice-versa.

\begin{enumerate}
    \item \label{blt:msb1}
    We start by defining $F$. $F$ is a $w$-bit word where the most significant position of every field is set to $1$ and every other position is set to $0$. In this particular example $F = 1000\ 1000\ 1000\ 1000_2$
    
    \item \label{blt:msb2}
    In a local variable $t_1$, we store information about the leading bits of each field of $x$. This is done with $x \wedge F$.
    \begin{align*}
                       x &= \underline{0}101\ \underline{0}000\ \underline{1}000\ \underline{1}101_2 \\
                       F &= 1000\ 1000\ 1000\ 1000_2 \\ \cline{1-2} 
        t_1 = x \wedge F &= \underline{0}000\ \underline{0}000\ \underline{1}000\ \underline{1}000_2
    \end{align*}
    
    \item \label{blt:msb3}
    In another local variable $t_2$, we store $x$ after setting the leading bits of each field to $0$. This is done with $x \oplus t_1$.
    \begin{align*}
                         x &= 0\underline{101}\ 0\underline{000}\ 1\underline{000}\ 1\underline{101}_2 \\
                       t_1 &= 0000\ 0000\ 1000\ 1000_2 \\ \cline{1-2}
        t_2 = x \oplus t_1 &= 0\underline{101}\ 0\underline{000}\ 0\underline{000}\ 0\underline{101}_2
    \end{align*}
    
    \item \label{blt:msb4}
    We subtract $t_2$ from $F$ and save it to a local variable $t_3$. Since the leading bit of every field of $F$ is $1$, after subtracting $t_2$ from $F$, what remains is the information about if that field was empty (all zeros) or not. This information is given by the bit that remains at the most significant position of each resulting field. In other words, if in any given field of the resulting word, the most significant bit is $1$, then the corresponding field in $x$ was empty; otherwise, it was not empty.
    
    Since we only care about what remains of the most significant position of each field, in the example below, the remaining noise has been replaced with $?$.
    \begin{align*}
                    F &= 1000\ 1000\ 1000\ 1000_2 \\
                  t_2 &= 0\underline{101}\ 0\underline{000}\ 0\underline{000}\ 0\underline{101}_2 \\ \cline{1-2} 
        t_3 = F - t_2 &= \underline{0}???\ \underline{1}000\ \underline{1}000\ \underline{0}???_2
    \end{align*}
    
    \item \label{blt:msb5}
    This step consists of clearing the noise from $t_3$ since we care only about knowing which fields in $x$ were empty or not. To do so, we use $(\neg t_3) \wedge F$.
    \begin{align*}
                       t_3 &= \underline{0}???\ \underline{1}000\ \underline{1}000\ \underline{0}???_2 \\ \cline{1-2} 
            t_4 = \neg t_3 &= \underline{1}???\ \underline{0}111\ \underline{0}111\ \underline{1}???_2 \\
                         F &= 1000\ 1000\ 1000\ 1000_2 \\ \cline{1-2} 
        t_5 = t_4 \wedge F &= \underline{1}000\ \underline{0}000\ \underline{0}000\ \underline{1}000_2
    \end{align*}
    
    \item \label{blt:msb6}
    The value calculated in step~\ref{blt:msb2} for $t_1$ holds information about the leading bits of each field, whereas $t_5$ from step~\ref{blt:msb5} contains the information about the non-leading bits. By merging both words, the resulting word will hold information about the whole word $x$. We achieve this with $t_1 \vee t_5$.
    \begin{align*}
                       t_1 &= \underline{0}000\ \underline{0}000\ \underline{1}000\ \underline{1}000_2 \\
                       t_5 &= \underline{1}000\ \underline{0}000\ \underline{0}000\ \underline{1}000_2 \\ \cline{1-2} 
        t_6 = t_1 \vee t_5 &= \underline{1}000\ \underline{0}000\ \underline{1}000\ \underline{1}000_2
    \end{align*}
\end{enumerate}

In fact, once $F$ is defined, steps \ref{blt:msb2} to \ref{blt:msb5} can be computed all at once with the expression:
\begin{equation}
    t_6 = (x \wedge F) \vee ((\neg(F - (x \oplus(x \wedge F)))) \wedge F)
\end{equation}

\paragraph{Step 2 --- Summary compression} \label{sec:summaryCompression}
% minuto 1.12: https://www.youtube.com/watch?v=xSGorVW8j6Q&list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&index=12

The goal of this step is to compress the summary word down to a single field.

\begin{enumerate}
    \item \label{blt:summCompression1}
    The first step consists of shifting the leading bits of each field to the least significant position of each field. This is done with $t_6 \gg (\sqrt{w} - 1)$. 
    \begin{align*}
                    t_6 &= \underline{1}000\ \underline{0}000\ \underline{1}000\ \underline{1}000_2 \\ \cline{1-2} 
        t_7 = t_6 \gg \underbrace{(\sqrt{w} - 1)}_{3} &= 000\underline{1}\ 000\underline{0}\ 000\underline{1}\ 000\underline{1}_2
    \end{align*}
    
    \item \label{blt:summCompression2}
    We wish now to copy the least significant bit of each field to a single field, keeping their relative order.
    Similarly to \ref{sec:summaryfields}.\ref{blt:msb1}, we need to find a word $C$, which, when multiplied by $t_7$, will produce the result we are looking for.
    Let $C$ be also partitioned in fields indexed $\{f_0, ..., f_{\sqrt{w} - 1}\}$ where $f_{\sqrt{w} - 1}$ is the most significant field. At every field $f_i$, the only set bit is $b_{\sqrt{w} - 1 - i}$).
    In our example $C = 0001\ 0010\ 0100\ 1000_2$.
    
    \item \label{blt:summCompression3}
    Multiplying $C$ with $t_7$ produces a result $t_8$ with all the important bits in their relative order in the most significant field. There will be some additional noise in the least significant fields, which we can easily clear by $t_8 \gg ((\sqrt{w})\cdot(\sqrt{w} - 1))$.
        \begin{align*}
                         t_7 &= 000\underline{1}\ 000\underline{0}\ 000\underline{1}\ 000\underline{1}_2 \\
                           C &= 0001\ 0010\ 0100\ 1000_2 \\ \cline{1-2} 
          t_8 = t_7 \times C &= \underline{1011}\ ????\ ????\ ????_2\\ \cline{1-2}
        x_s = t_8 \gg \underbrace{((\sqrt{w})\cdot(\sqrt{w} - 1))}_{(16-4)} &= 0000\ 0000\ 0000\ \underline{1011}_2
    \end{align*}
\end{enumerate}

\paragraph{Step 3 --- First non-empty field with parallel comparison} \label{sec:parallel}
At this stage, the goal is to compute the first non-empty field of $x$. To do so, we need to do a parallel comparison between $x_s$ (the summary of $x$'s fields) and the first $\sqrt{w}$ powers of two.

The parallel comparison consists of:
\begin{enumerate}
    \item
    Taking a query $x$ of length $l < w$, making as many copies of it as there are other vectors we wish to compare it with while padding these copies with $0$. The resulting vector is stored in a word.
    
    \item
    The vectors we wish to compare $x$ with are stored in word $A$ with each of their leading bits padded with $1$.
    
    \item
    We take the difference between $A$ and the copies of $x$, checking how many of the padding bits remain $1$ in $A$ after this operation. The result stands for the number of vectors in $A$ that were strictly smaller than $x$.
\end{enumerate}

Since the vector we want to compare $x_s$ with consists of $\sqrt{w}$ powers of two, we know that we will $\sqrt{w}\cdot(\sqrt{w} + 1)$ bits to store all such vectors. This extra bit per vector is due to the padding bit mentioned earlier. Since $\sqrt{w}\cdot(\sqrt{w} + 1) > w$, we know also that it might be necessary to do this operation in two iterations. Since a word does not hold enough bits to perform the comparison with a single word, we will split the vectors in two words: one representing the higher $\sqrt{w}/2$ powers of two, and another for the lower ones.

If the power of two vectors are sorted, this parallel comparison will be a monotone function, meaning that once the transition on the leading bit is found, the result is found. This also implies that if the result is found in the higher powers of two, then it is unnecessary to look for it in the lower end.

\begin{enumerate}
    \item \label{blt:parallel1}
    We define two bit-vectors, $hi$ and $lo$, with $hi > lo$. These vectors are comprised of the concatenation of the $\sqrt{w}$ powers of two in sorted in descending order and padded with $1$. From each power of two, we have to subtract $1$ for this operation to work, because if we do not and the query is an exact power of two, the corresponding padding $1$ will not be borrowed. Thus, in our example we have:
    \begin{align*}
        hi &= 1\ \underbrace{0111}_{2^3-1=7}\ 1\ \underbrace{0011}_{2^2-1=3}{}_2\\
        lo &= 1\ \underbrace{0001}_{2^1-1=1}\ 1\ \underbrace{0000}_{2^0-1=0}{}_2
    \end{align*}
    
    \item \label{blt:parallel2}
    We define another vector $t_9$ consisting of $\sqrt{w}/2$ concatenated copies of $x_s$ where each of the copies is prefixed by $0$. This vector is achieved by multiplying $x_s$ with a word $M$ consisting of $\sqrt{w}/2$ fields of size $\sqrt{w} + 1$ where the least significant bit of each field is set to $1$. Note that, because we have set the size of each field of $M$ to have an additional bit, this corresponds to prefix a $0$ to each $\sqrt{w}$ field:
    \begin{align*}
        x_s = 0000\ 0000\ 0000\ &\underline{1011}_2\\ 
        M = 0\ 0001\ 0\ &0001_2\\ \cline{1-2}
        t_9 = x_s \times M = 0\ \underline{1011}\ 0\ &\underline{1011}_2
    \end{align*}
    
    \item \label{blt:parallel3}
    To find the first non-empty field of $x$, we take the differences between $t_9$ and $hi$ and $lo$ respectively. The answer will lie in the first field whose leading bit resulted in a $0$ after the operation.
    \begin{align*}
                          hi &= \underline{1}\ \underline{1}000\ \underline{1}\ \underline{01}00_2\\
                          lo &= \underline{1}\ \underline{001}0\ \underline{1}\ \underline{0001}_2 \\
                      t_9 &= 0\ 1011\ 0\ 1011_2\\ \cline{1-2}
        t_{10} = hi - t_9 &= \underline{0}\ ????\ \underline{0}\ ????_2 \\
        t_{11} = lo - t_9 &= \underline{0}\ ????\ \underline{0}\ ????_2
    \end{align*}
    
    \item \label{blt:parallel4}
    Looking at $t_{10}$, we note that the first non-empty field of $x$ is the most significant one because the leading bit of the first field resulting from the difference between $hi$ and $t_9$ is now $0$. Nevertheless, we will do the same operations on both $t_{10}$ and $t_{11}$ and concatenate the results, so we end up with a single result for the whole query. Note that in the previous step, the actual values within each field besides the leading bit are irrelevant, so we do some masking and shifting, similar to what was done in \ref{sec:summaryfields} and \ref{sec:summaryCompression}.
    \begin{enumerate}
        \item
        The first step is to clear all the irrelevant bits in the fields and turn the leading bits from $0$ to $1$. We choose a mask for this specific purpose.
        \begin{align*}
            t_{10} = \underline{0}\ ????\ \underline{0}\ ????_2&\\
            t_{11} = \underline{0}\ ????\ \underline{0}\ ????_2&\\
            Mask_1 = 1\ 0000\ 1\ 0000_2&\\ \cline{1-2}
            t_{12} = (t_{10} \wedge Mask_1) \oplus Mask_1 = \underline{1}\ 0000\ \underline{1}\ 0000_2&\\
            t_{13} = (t_{11} \wedge Mask_1) \oplus Mask_1 = \underline{1}\ 0000\ \underline{1}\ 0000_2&
        \end{align*}
        \item
        Secondly, we wish to summarize the results in a single field. To achieve so, we first multiply the vectors by an integer $V$, which construction follows what we have done for \ref{sec:summaryCompression}.\ref{blt:summCompression2}, and that result will put all the important bits consecutive in the most significant field.
        
        \begin{align*}
            t_{14} = t_{12} \gg \sqrt{w} = 0\ 000\underline{1}\ 0\ 000\underline{1}_2& \\
            t_{15} = t_{13} \gg \sqrt{w} = 0\ 000\underline{1}\ 0\ 000\underline{1}_2& \\
            \cline{1-2}
            V =\ 01000\ 10000_2 & \\
            t_{16} = t_{14} \times V =\ ???????\ \underline{11}00?\ ?????_2& \\
            t_{17} = t_{15} \times V =\ ???????\ \underline{11}00?\ ?????_2& \\
        \end{align*}
        \item
        After the multiplication, we have to remove the noise and move the result to the least significant field. We achieve this by defining another mask for this purpose, followed by the necessary bitwise shifts. The final step will be to merge the results of the higher and the lower powers of two: $t_{hi} \vee t_{lo}$.
        
        \begin{align*}
            Mask_2 = (1 \ll (\sqrt{w}/2)) - 1 = 11_2&\\
            t_{18} = t_{16} \wedge (Mask_2 \ll 2\cdot \sqrt{w}) =\ \underline{11}\ 0000\ 0000_2& \\
            t_{19} = t_{17} \wedge (Mask_2 \ll 2\cdot \sqrt{w}) =\ \underline{11}\ 0000\ 0000_2& \\
            \cline{1-2}
            t_{hi} = t_{18} \gg (\sqrt{w} + \sqrt{w}/2) = 00\ 0000\ \underline{11}00_2 &\\
            t_{lo} = t_{19} \gg (\sqrt{w} \cdot \sqrt{w} / 2) = 00\ 0000\ 00 \underline{11}_2 &\\
            \cline{1-2}
            t_{q} = t_{hi} \vee t_{lo} = \underline{1111}_2 &\\
        \end{align*}
    \end{enumerate}
    \item
    Note that $t_q$ can only be one of $\sqrt{w}$ possibilities: $0001_2$, $0011_2$, $0111_2$, or $1111_2$. For this reason, we implement a lookup table of size $\sqrt{w}$ for these values, which we return at the end of the method. We can even halve the size of the lookup table by applying the following trick: instead of merging $t_{hi}$ and $t_{lo}$ into a single field, shift $t_{hi}$ all the way to the right. In this scenario, $t_{hi}$ can either be $11_2$, $01_2$ or $0$. The values of the lookup table, in this case, will be only $11_2$ and $01_2$, so if $t_{hi}$ takes one of those values, we return the value in the lookup table plus a constant corresponding to the least significant positions ($\sqrt{w}/2$). Should it be $0$, then we do the lookup for $t_{lo}$ and return the corresponding value in the lookup table.
    
    In our example, since $t_{q} = 1111_2$ the result of this parallel comparison would be $3$ (three), meaning, the method should now look at $x\langle 3\rangle_4$ (the most significant field).
\end{enumerate}

\paragraph{Step 4 --- Final result}
After learning in which field lies the most significant bit, we now run the same method as in \ref{sec:parallel} but now with the actual field.

\begin{enumerate}
    \item
    We start by extracting the field from our query $x$. Let $i$ be the result returned from \ref{sec:parallel}, e.g. the index of the field. We extract $f_i$ by shifting $(\sqrt{w} - 1 - i)$ fields in $x$ to the right and bitwise $\wedge$ the result with a mask for this purpose.
    \begin{align*}
        x = \underline{0101}\ 0000\ 1000\ 1101_2 &\\
        Mask_3 = (1 \ll \sqrt{w}) - 1 = 0000\ 0000\ 0000\ 1111_2 &\\
        \cline{1-2}
        t_{20} = (x \gg \underbrace{(\sqrt{w} \cdot (\sqrt{w} - 1 - i))}_{4\times(4-1-0)}\ \wedge\ Mask_3 = 0000\ 0000\ 0000\ \underline{0101}_2 &
    \end{align*}
    \item
    We run another parallel comparison with $0101_2$. Let $d$ be the result of computing the parallel comparison of the first non-empty field of $x$, then in our example $d = 2$.
    \item
    We can now compute the overall most significant bit of $x$. The final result is given the expression:
    \begin{equation*}
        \text{msb}(x) = d + i\cdot\sqrt{w}
    \end{equation*}
    In our example, this will evaluate to:
    \begin{equation*}
        \text{msb}(0101\ 0000\ 1000\ 1101_2) = 2 + 3\cdot\sqrt{16} = 2 + 3 \times 4 = 14
    \end{equation*}
\end{enumerate}

\newpage
\subsection{Least Significant Set Bit} \label{sec:lsbAlgorithm}

Let $\text{lsb}(x)$ denote the least significant set bit of $x$. According to Pătrașcu and Thorup, after computing $\text{msb}(x)$ we can in $O(1)$ time compute $\text{lsb}(x)$ with the expression:
\begin{equation*}
    \text{lsb}(x) = \text{msb}((x - 1) \oplus x)
\end{equation*}

Example:
\begin{align*}
    x = 0101\ 1101\ 1100\ 0\underline{1}00_2& \\
    x - 1 = 0101\ 1101\ 1100\ 0\underline{0}11_2& \\
    (x - 1) \oplus x = 0000\ 0000\ 0000\ 0\underline{1}00_2& \\
    \cline{1-2}
    \text{lsb}(x) = \text{msb}((x - 1) \oplus x) = \text{msb}(0000\ 0000\ 0000\ 0\underline{1}00_2&) = 2
\end{align*}

\newpage
\subsection{Rank Lemma 1} \label{sec:rankLemma1}

Another important operation in the context of the implementation of the data structure presented in \cite{patrascu2014dynamic} is to compute the rank of a word. For this purpose, some subroutines are required, and the algorithm described in this section is one of them. This algorithm consists of the implementation of Lemma~\ref{lemma1} by Fredman and Willard, cited by Pătrașcu and Thorup. It reads:
\begin{lemma} \label{lemma1}
Let $m \cdot b \leq w$. If we are given a b-bit number x and a word A with m b-bit numbers stored in sorted order, that is, $A\langle 0 \rangle_b < A\langle 1 \rangle_b < \dots < A\langle m - 1 \rangle_b$, then in constant time, we can find the rank of x in A, denoted \text{rank}(x,A).
\end{lemma}
An algorithm that implements $\text{rank}(x,A)$ works as the following:
\begin{enumerate}
    \item
    Computing how many fields in $A$ have $0$ as their leading bit.
    
    \item
    Computing the leading bit of $x$.
    
    \item
    If the leading bit of $x$ is $0$, then:
    \begin{enumerate}
        \item
        We bitwise shift and mask $A$ as needed, such that the fields whose leading bit are $1$ are no longer present in $A$.
        
        \item
        We compute a word consisting of as many concatenated copies of $x$ as there are fields left in $A$.
        
        \item
        We do parallel comparison\footnote{See Section~\ref{sec:parallel} to learn more about \textit{parallel comparison}.} between (the shifted/masked) $A$ and (copies of) $x$ by setting the leading bit of each of the remaining fields of $A$ to $1$ and computing the difference between those words.
        
        \item
        The result of rank$(x,A)$ is given by the number of fields whose leading bit is now $0$ because if the leading bit (that has been set to $1$ in the previous step) is borrowed in the subtraction, then $x$ is larger than the key stored at that field.
    \end{enumerate}
    
    Otherwise, if the leading bit of $x$ is $1$, then:
    \begin{enumerate}
        \item
        We bitwise shift and/or mask $A$ such that the fields whose leading bit is $0$ are no longer present in $A$, storing the number of fields removed from $A$ on a local variable.
        
        \item
		We set the leading bit of $x$ to $0$ and compute a word consisting of as many concatenated copies of $x$ as there are fields left in $A$.
		
		\item
        We do parallel comparison between the remaining fields in $A$ and the word we computed just before.
        
        \item
        The result of rank$(x,A)$ is given by the number of fields whose leading bit was $0$ just before $A$ was shifted/masked plus the number of fields whose leading bit is $0$ after the parallel comparison.
    \end{enumerate}
    
\end{enumerate}

This operation takes $O(1)$ time, and we will run an example of this algorithm, explaining its intricacies.

\subsubsection{Parameters}

Since this algorithm branches depending on the leading bit of the query $x$, we will run the example with two queries $x_1$ and $x_2$ such that we explore both branches of the algorithm. Let $A$ be the concatenation of the keys of $S = \{0101_2, 0110_2, 1100_2, 1110_2 \}$. Note that since the keys in $A$ are sorted, if key $y_i < y_j$, then $y_i$ will be present in $A$ on a less significant position than $y_j$.
\begin{align*}
    A &= \underbrace{1110}_{A\langle 3 \rangle_4}\ \underbrace{1100}_{A\langle 2 \rangle_4}\ \underbrace{0110}_{A\langle 1\rangle_4}\ \underbrace{0101}_{A\langle 0 \rangle_4}{}_2 \\
    x_1 &= 1100_2 \\
    x_2 &= 0111_2 \\
    b &= 4 \\
    m &= 4
\end{align*}

\subsubsection{Step 1 --- Computing which fields have zero as their leading bit} \label{sec:computeM}

Since the keys in $A$ are sorted, we know that finding the position the least significant field whose first bit is $1$ in $A$ will tell us how many fields there are with $0$ at their leading bit.

\begin{enumerate}
    \item
    We start by finding $M$. $M$ consists of a word with $m$ fields of $b$-bits, where each field is filled with zeroes excluding the least significant bit, which is set to $1$. In this particular example $M = 0001\ 0001\ 0001\ 0001_2$.
    
    \item % A & (M << (b - 1))
    We mask the non-leading bits of each field of $A$. This is achieved with:
    \begin{align*}
        A \wedge (M \ll (b - 1))
    \end{align*}
    
    Thus we have:
    \begin{align*}
        M &= 0001\ 0001\ 0001\ 0001_2 \\
        t_1 = M \ll (b - 1) &= 1000\ 1000\ 1000\ 1000_2 \\
        A &= \underline{1}110\ \underline{1}100\ \underline{0}110\ \underline{0}101_2 \\
        \cline{1-2}
        t_2 = A \wedge t_1 &= \underline{1}000\ \underline{1}000\ \underline{0}000\ \underline{0}000_2
    \end{align*}
    
    \item
    Computing lsb$(t_2)$ will give us the index of leading bit of the least significant field whose leading bit is $1$. Dividing the previous result by the field size, $b$, gives us the position of the first least significant field whose leading bit is $0$. In this particular example:
    \begin{align*}
        &b = 4 \\
        &\text{lsb}(t_2) = \text{lsb}(1000\ \underline{1}000\ 0000\ 0000_2) = 11 \\
        \cline{1-2}
        &t_3 = \frac{\text{lsb}(t_2)}{b} = \frac{11}{4} = 2 \\
    \end{align*}
    We know now that the first $2$ least significant fields of $A$ have $0$ as their leading bit.
\end{enumerate}

\subsubsection{Step 2 --- Computing the leading bit of the query}
In order to extract the value of the leading bit of our queries $x_1$ and $x_2$, we resort to the algorithm of section~\ref{sec:bit}. The leading bit of the query will be at position $b - 1$, thus we have for $x_1$:
\begin{align*}
    x_1 = \underline{1}100&_2\\
    \text{bit}(b - 1, x_1) = \text{bit}(3, x_1) = 1\\
\end{align*}
And for $x_2$:
\begin{align*}
    x_2 = \underline{0}111&_2\\
    \text{bit}(b - 1, x_2) = \text{bit}(3, x_2) = 0\\
\end{align*}

\subsubsection{Step 3 --- Computing rank with parallel comparison}

We will now run the algorithm for each of its branches. If the leading bit of the query is $1$, then we run the first branch; otherwise, the second.
\begin{itemize}
    \item
    In this branch our query is $x_1 = 1100_2$:
    \begin{enumerate}
        \item
        Since the leading bit of our query $x_1$ is $1$, we know now that its rank in $A$ is at least the number of fields in $A$ whose leading bit is $0$. So we proceed by removing those fields from $A$, and for this purpose we resort to the getFields$(i, f, A)$ method defined in Section~\ref{sec:fieldRetrieval}. In our example:
        \begin{align*}
            A &= \underline{1110}\ \underline{1100}\ 0110\ 0101_2 \\
            b &= 4 \\
            t_3 &= 2 \\
            A \coloneqq \text{getFields}(t_3, b, A) &= 0000\ 0000\ \underline{1110}\ \underline{1100}_2 \\
        \end{align*}
        
        \item
        We apply the same principle to the $M$ word by doing the very same operation as just before.
        \begin{align*}
            M &= \underline{0001}\ \underline{0001}\ 0001\ 0001_2 \\
            b &= 4 \\
            t_3 &= 2 \\
            \cline{1-2}
            M \coloneqq \text{getFields}(t_3, b, M) &= 0000\ 0000\ \underline{0001}\ \underline{0001}_2 \\
        \end{align*}
        
        \item
        We set the leading bit of $x_1$ to $0$ and multiply the result by $M$ to produce a word containing concatenated copies of $x_1$.
        \begin{align*}
            x_1 = 1100_2 \\
            M = 0000\ 0000\ \underline{0001}\ \underline{0001}_2 \\
            \cline{1-2}
            x_1' \coloneqq \text{deleteBit}(b - 1, x_1) = 0100_2 \\
            \cline{1-2}
            x_1'' \coloneqq x_1 \times M = 0000\ 0000\ \underline{0100}\ \underline{0100}_2 \\
        \end{align*}
        
        \item
        The last ingredient needed for the parallel comparison is a mask comprised of a word whose leading bit of each field is $1$. Shifting $M$ by $b - 1$ positions to the left will produce such result.
        \begin{align*}
            M = 0000\ 0000\ 000\underline{1}\ 000\underline{1}_2& \\
            \cline{1-2}
            M \coloneqq M \ll (b - 1) = 0000\ 0000\ \underline{1}000\ \underline{1}000_2& \\
        \end{align*}
        
        \item
        We take the difference between $A$ and $x_1''$ and mask out the bits at all positions except the leading bits of each field in the resulting word.
        \begin{align*}
            A &= 0000\ 0000\ 1\underline{110}\ 1\underline{100}_2 \\
            x_1'' &= 0000\ 0000\ 0\underline{100}\ 0\underline{100}_2 \\
            M &= 0000\ 0000\ \underline{1}000\ \underline{1}000_2 \\
            \cline{1-2}
            A - x_1'' &= 0000\ 0000\ \underline{1}???\ \underline{1}???_2 \\
            d_1 = (A - x_1) \wedge M &= 0000\ 0000\ \underline{1}000\ \underline{1}000_2 \\
        \end{align*}
        
        \item
        To learn how many of the remaining fields in $A$ are smaller than $x_1$, we compute lsb($d_1$) and divide it by $b$.
        \begin{align*}
            d_1 = 0000\ 0000\ 1000\ \underline{1}000_2 \\
            \text{lsb}(d_1) = 3 \\
            b = 4 \\
            \cline{1-2}
            t_4 = \frac{\text{lsb}(d_1)}{b} = \frac{3}{4} = 0 
        \end{align*}
        
        \item
        Computing rank$(x_1, A)$ consists of returning the number of fields in $A$ that are strictly smaller than $x_1$. In this specific context, we know that all fields whose leading bit is $0$ are smaller than $x_1$, and we have also just computed the number of fields whose leading bit is $1$ but that are still smaller than $x_1$. So we just add those results, and we have:
        \begin{align*}
            \text{rank}(x_1, A) &= t_3 + t_4 = 2 + 0 \\
            \text{rank}(x_1, A) &= 2
        \end{align*}
        
    \end{enumerate}
    \item
    In this branch our query is $x_2 = 0111_2$:
    \begin{enumerate}
        \item
        Since the leading bit of our query $x_2$ is $0$, we can safely disregard the fields in $A$ whose leading bit is $1$. Similarly to what was done in the first branch, $M$ suffers a similar change, and we will start with that by using the getFields$(i, j, f, A)$ function defined in Section~\ref{sec:fieldRetrieval}. Thus we have:
        \begin{align*}
            M &= 0001\ 0001\ \underline{0001}\ \underline{0001}_2 \\
            b &= 4 \\
            t_3 &= 2 \\
            \cline{1-2}
            M \coloneqq \text{getFields}(0, t_3, b, M) &= 0000\ 0000\ \underline{0001}\ \underline{0001}_2 \\
        \end{align*}
        
        \item
        We need to have as many concatenated copies of $x_2$ as there are fields in $A$ whose leading bit is $0$. So we multiply $M$ by $x_2$ and we end with:
        \begin{align*}
            x_2 = 0111_2 \\
            M = 0000\ 0000\ \underline{0001}\ \underline{0001}_2 \\
            \cline{1-2}
            x_2' \coloneqq x_2 \times M = 0000\ 0000\ \underline{0111}\ \underline{0111}_2 \\
        \end{align*}
        
        \item
        As before, we need a mask to perform the parallel comparison. So we use the same technique as in the other branch and shift $M$ by $b-1$ positions to the left:
        \begin{align*}
            M = 0000\ 0000\ 000\underline{1}\ 000\underline{1}_2& \\
            \cline{1-2}
            M \coloneqq M \ll (b - 1) = 0000\ 0000\ \underline{1}000\ \underline{1}000_2& \\
        \end{align*}
        
        \item
        Lastly, for the last ingredient of the parallel comparison, we discard the fields in $A$ whose leading bit is $1$, and set the leading bit of the remaining fields to $1$. Thus we have:
        \begin{align*}
            A = &\ 1110\ 1100\ \underline{0110}\ \underline{0101}_2 \\
            b = &\ 4 \\
            t_3 = &\ 2 \\ 
            M = &\ 0000\ 0000\ \underline{1}000\ \underline{1}000_2 \\
            \cline{1-2}
            A \coloneqq \text{getFields}(0, t_3, b, A) = &\ 0000\ 0000\ \underline{0110}\ \underline{0101}_2 \\
            \cline{1-2}
            A \coloneqq M \vee A = &\ 0000\ 0000\ \underline{1}000\ \underline{1}000_2 \\
            \vee &\ 0000\ 0000\ \underline{0}110\ \underline{0}101_2 \\
            \cline{1-2}
            A = &\ 0000\ 0000\ \underline{1}110\ \underline{1}101_2
        \end{align*}
        
        \item
        We take the difference between $A$ and $x_2'$ and mask out the bits at all positions except the leading bits of each field in the resulting word.
        \begin{align*}
            A &= 0000\ 0000\ 1\underline{110}\ 1\underline{101}_2 \\
            x_2' &= 0000\ 0000\ \underline{0111}\ \underline{0111}_2 \\
            M &= 0000\ 0000\ \underline{1}000\ \underline{1}000_2 \\
            \cline{1-2}
            A - x_2' &= 0000\ 0000\ \underline{0}???\ \underline{0}???_2 \\
            d_2 = (A - x_2') \wedge M &= 0000\ 0000\ \underline{0}000\ \underline{0}000_2 \\
        \end{align*}
        
        \item
        Note that $d_2$ is $0$. Since there are no set bits in $d_2$ then $x_2$ is larger than all $x_2$ must be larger than all the remaining fields in $A$, so we just return $t_2$.
        \begin{align*}
            \text{rank}(x_2,A) &= t_3 = 2
        \end{align*}
        
    \end{enumerate}
\end{itemize}

\chapter{Implementations} \label{sec:implementationsChapter}

All the implementing classes described and discussed in this chapter can be found in the folder shown in figure~\ref{fig:implementationsFolderTree}.

\begin{figure}[H]
\dirtree{% 
.1 /. 
.2 src. 
.3 main. 
.4 java. 
.5 \textbf{integersets}. 
}
\caption{Location of the folder containing the implementations}
\label{fig:implementationsFolderTree}
\end{figure}

Note that all the functions and implementations consider the integer keys as unsigned integers.

\section{Utility Functions} \label{sec:utilFuctionsImplementation}

This project features a class, {\ttfamily Util}, which implements static utility functions. In can be found in the path specified in figure~\ref{fig:utilFunctionsTree}.

\begin{figure}[H]
\dirtree{% 
.1 /. 
.2 src. 
.3 main. 
.4 java. 
.5 integersets. 
.6 \textbf{Util.java}. 
}
\caption{Location of the {\ttfamily Util.java} file in the folder structure}
\label{fig:utilFunctionsTree}
\end{figure}

Below find listed the functions included in this class, together with a brief explanation.
The implemented functions feature 32-bit versions, which, for brevity, were omitted. These differ solely on the input word type.

\subsection{Bit Operations}
The algorithms which these functions implement are described in Section~\ref{sec:bit}.
The functions included are:

\begin{itemize}
    \item
    The method below returns the value of the bit at position $d$ in $A$. It is enforced that $d \in [0, w[$.
    \begin{lstlisting}
public static int bit(final int d, final long A)
    \end{lstlisting}
    
    \item
    The method below sets the bit at index $d$ in $A$ to 1 and returns $A$ after the change. If the bit was already 1 or if the provided index $d \not\in [0, w[$, then the function has no effect.
    \begin{lstlisting}
public static int setBit(final int d, int A)
    \end{lstlisting}
    
    \item
    The method below sets the bit at index $d$ to 0 and returns $A$ after the change. If the bit was already 0 or if the provided index $d \not\in [0, w[$, then the function has no effect.
    \begin{lstlisting}
public static int deleteBit(final int d, int A)
    \end{lstlisting}
\end{itemize}

\subsection{Fields of Words}
The algorithms which these functions implement are described in Section~\ref{sec:fieldsOfWords}.
The functions included are:

\begin{itemize}
    \item
    The method below returns $A\langle i\rangle_f$. It is enforced that $f \in [0, w]$ and $i \times f \in [0, w]$.
    \begin{lstlisting}
public static long getField(final int i, final int f, final long A)
    \end{lstlisting}
    
    \item
    The method below returns $A\langle i, j \rangle_{g \times f}$. It is enforced that $f \in [0, w]$, $g < f$ and $i \times g + j \in [0, w]$.
    \begin{lstlisting}
public static int getField2d(final int i, final int j, final int g, final int f, final int A)
    \end{lstlisting}
    
    \item
    The method below returns the range of fields $A\langle i \dots j \rangle_f$. It is enforced that $f \in [0, w]$, $i \times f \in [0, w]$, $j \times f \in [0, w]$, $i < j$, and $f \cdot (j - i) < w$.
    \begin{lstlisting}
public static long getFields(final int i, final int j, final int f, final long A)
    \end{lstlisting}
    
    \item
    The method below returns the range of fields $A\langle i \dots * \rangle_f$. It is enforced that $f \in [0, w]$ and $i \times f \in [0, w]$.
    \begin{lstlisting}
public static long getFields(final int i, final int f, final long A)
    \end{lstlisting}
    
    \item
    The method below sets $A\langle i \rangle_f \coloneqq y$ and returns $A$ after the change. It is enforced that $f \in [0, w]$ and $i \times f \in [0, w]$. Only the bits in $y\langle 0 \rangle_f$ are considered.
    \begin{lstlisting}
public static int setField(final int i, final int y, final int f, final long A)
    \end{lstlisting}
\end{itemize}

\subsection{String Representation of an Integer in Binary}

\begin{itemize}
    \item
    The method below returns a string representation of integer $x$ in binary prefixed by {\ttfamily 0b}, including leading zeros (and suffixed by {\ttfamily l} if it is a 64-bit integer).
    \begin{lstlisting}
public static String bin(final long x)
    \end{lstlisting}
    
    \item
    The method below returns a string representation of integer $x$ in binary prefixed by {\ttfamily 0b}, including leading zeros, spaced by {\ttfamily \_} every $f$ bits counting from the least significant bit (and suffixed by {\ttfamily l} if it is a 64-bit integer).
    \begin{lstlisting}
public static String bin(final long x, final int f)
    \end{lstlisting}
\end{itemize}

\subsection{Helper Functions}

\begin{itemize}
    \item
    The method below implements a helper function for the {\ttfamily rankLemma1} method, returning the index of the transition from $0$ to $1$ in $field$, e.g., which powers of two are smaller than the input $field$.
    \begin{lstlisting}
private static int parallelComparison(final long field)
    \end{lstlisting}

    \item
    This method is a helper function for the {\ttfamily parallelComparison} method, and simply returns the value associated with a given $pow$ in a small lookup table.
    \begin{lstlisting}
private static int parallelLookup(final int pow)
    \end{lstlisting}
    
    \item
    The method below is a helper method for the most significant set bit lookup functions, as described in \cite{bittricks}\footnote{The following link redirects to the function that inspired this implementation: \url{https://graphics.stanford.edu/~seander/bithacks.html\#IntegerLogLookup}} and mentioned below. It populates a lookup table, allowing these functions to return the result quickly. 
    \begin{lstlisting}
private static void generateLookupTable()
    \end{lstlisting}
\end{itemize}

\subsection{Most and Least Significant Set Bit}

The algorithms which these functions implement are described in Sections~\ref{sec:msbAlgorithm} and \ref{sec:lsbAlgorithm}.
The functions included are:

\begin{itemize}
    \item
    The method below returns the index of the most significant set bit of the target $x$. It is used as a subroutine in many other functions. The actual operation used to compute the result can be easily changed in the body of the method by altering the function that is called. The version featured with this report calls {\ttfamily msbConstant}, defined a few bullet points below.
    \begin{lstlisting}
public static int msb(final long x)
    \end{lstlisting}
    
    \item
    The method below returns the index of the least significant set bit of $x$.
    \begin{lstlisting}
public static int lsb(final long x)
    \end{lstlisting}
    
    \item
    The method below returns the index of the most significant set bit of $x$ by calling a Java standard library function and computing the result with an expression.
    \begin{lstlisting}
public static int msbLibrary(final long x)
    \end{lstlisting}
    
    \item
    The method below implements a naive algorithm for computing the index of the most significant set bit of the target $x$, as described in \cite{bittricks}\footnote{The following link redirects to the function that inspired this implementation: \url{https://graphics.stanford.edu/~seander/bithacks.html\#IntegerLogObvious}}.
    \begin{lstlisting}
public static int msbObvious(long x)
    \end{lstlisting}
    
    \item
    The method below implements a lookup algorithm for computing the index of the most significant set bit of the target $x$, as described in \cite{bittricks}\footnote{The following link redirects to the function that inspired this implementation: \url{https://graphics.stanford.edu/~seander/bithacks.html\#IntegerLogLookup}}. For 64-bit integers, the function first splits the integer in two, calling the 32-bit method on the high half first, and then on the second in the first half is $0$.
    \begin{lstlisting}
public static int msbLookupDistributedInput(final long x)
    \end{lstlisting}

    \item
    The method below implements the algorithm from Section~\ref{sec:msbO1}, which follows the lecture notes from \cite{erikdemainelec12} and \cite{nelsonjelanilec2}.
    \begin{lstlisting}
public static int msbConstant(long x)
    \end{lstlisting}
    
\end{itemize}

\subsection{Rank Lemma 1} \label{sec:rankLemma1Implementation}

The method below implements $\text{rank}(x,A)$ from Section~\ref{sec:rankLemma1}.
\begin{lstlisting}
public static int rankLemma1(long x, long A, final int m, final int b)
\end{lstlisting}
The input parameters are:
\begin{itemize}
    \item
    A query $x$, the integer to find the rank in $A$.
    
    \item
    A word $A$, containing keys with the same size as $x$, which must be sorted for the method to return a sound result.
    
    \item
    The number of keys in $A$, $m$.
    
    \item
    The length of each key in $A$, $b$, in bits.
\end{itemize}

\subsection{Additional Utility Functions}

\begin{itemize}
    \item
    The method below takes a 64-bit integer $x$ and returns a two-entry array, each position containing 32 of the 64 bits of $x$. The least significant bits of $x$ will be at index 0, whereas the most significant bits will be at position 1.
    \begin{lstlisting}
public static int[] splitLong(final long x)
    \end{lstlisting}
    
    \item
    The method below computes the reverse of the method just above. It takes a 32-bit integer array and combines its first two positions into a single 64-bit integer. Again, position $0$ of the input array is used for the least significant bits of the resulting 64-bit integer, whereas position $1$ will populate the remaining $32$ most significant positions.
    \begin{lstlisting}
public static long mergeInts(final int[] x)
    \end{lstlisting}
    
    \item
    The helper method below produces a word comprised of $w / b$ fields of $b$ bits in length, having each field its least significant bit set to $1$. E.g., the resulting word will have the bits at index $0$ and every $b^{\text{th}}$ index set to $1$. This function computes the result in $O(w/b)$ time.
    \begin{lstlisting}
public static long M(final int b, final int w)
    \end{lstlisting}

    \item
    The helper method below returns a string representation of interpreting the matrix stored in the word $A$, with $\#rows$ rows and $\#columns$ columns.
    \begin{lstlisting}
public static String matrixToString(final int rows, final int columns, final long A)
    \end{lstlisting}
    
    \item
    The helper method below returns an array containing $n$ distinct {\ttfamily long} keys between $0$ and $bound$ (exclusive) produced with seed $seed$ and sorted with an unsigned comparator.
    \begin{lstlisting}
public static long[] distinctBoundedSortedLongs(final int n, final long bound, final long seed)
    \end{lstlisting}
    
    \item
    The helper method below returns an array containing $n$ distinct {\ttfamily long} keys between $0$ and $bound$ (exclusive) produced with the default seed $42$ and sorted with an unsigned comparator.
    \begin{lstlisting}
public static long[] distinctBoundedSortedLongs(final int n, final long bound)
    \end{lstlisting}
    
    \item
    The helper method below returns an array containing $n$ distinct {\ttfamily long} keys between $0$ and the maximum unsigned value (exclusive) produced with the seed $seed$ and sorted with an unsigned comparator.
    \begin{lstlisting}
public static long[] distinctSortedLongs(final int n, final long seed)
    \end{lstlisting}
    
    \item
    The helper method below returns an array containing $n$ distinct {\ttfamily long} keys between $0$ and the maximum unsigned value (exclusive) produced with the default seed $42$ and sorted with an unsigned comparator.
    \begin{lstlisting}
public static long[] distinctSortedLongs(final int n)
    \end{lstlisting}
\end{itemize}

\newpage
\section{The {\ttfamily RankSelectPredecessorUpdate} Interface}

\begin{figure}[H]
\dirtree{% 
.1 /. 
.2 src. 
.3 main. 
.4 java. 
.5 integersets. 
.6 \textbf{RankSelectPredecessorUpdate.java}. 
}
\caption{Location of the {\ttfamily RankSelectPredecessorUpdate.java} file in the folder structure}
\label{fig:RankSelectPredecessorUpdateTree}
\end{figure}

As stated in Section~\ref{sec:predecessorProblem}, the data structure presented in \cite{patrascu2014dynamic} solves the dynamic predecessor problem.
For this reason, an interface denoted {\ttfamily RankSelectPredecessorUpdate} was implemented and it can be found in the path specified in figure~\ref{fig:RankSelectPredecessorUpdateTree}. It features the following the method signatures and default methods:
\begin{itemize}
    \item
    The $\text{insert}(x)$ operation sets $S=S \cup \{x\}$ and it is to be implemented by a method with the signature:
    \begin{lstlisting}
void insert(long x);
    \end{lstlisting}
    
    \item
    The $\text{delete}(x)$ operation sets $S=S \setminus \{x\}$ and is to be implemented by a method with the signature:
    \begin{lstlisting}
void delete(long x);
    \end{lstlisting}
    
    \item
    The $\text{member}(x)$ operation returns {\ttfamily true} if $x \in S$, and {\ttfamily false} otherwise. It is implemented as a default method, making all implementing classes automatically inheriting the method:
    \begin{lstlisting}
default boolean member(final long x) {
    if (isEmpty()) {
        return false;
    }
    final Long res = successor(x);
    return res != null && res == x;
}
    \end{lstlisting}

    \item
    The $\text{predecessor}(x)$ operation returns $\text{max}\{y\in S\ |\ y < x\}$ and it is implemented as a default method, making all implementing classes automatically inheriting the method:
    \begin{lstlisting}
default Long predecessor(long x) {
    return select(rank(x) - 1);
}
    \end{lstlisting}

    \item
    The $\text{successor}(x)$ operation returns $\text{min}\{y\in S\ |\ y \geq x\}$ and it is implemented as a default method, making all implementing classes automatically inheriting the method:
    \begin{lstlisting}
default Long successor(long x) {
    return select(rank(x));
}
    \end{lstlisting}

    \item
    The $\text{rank}(x)$ operation returns $\#\{ y \in S\ |\ y < x\}$ and it is to be implemented by a method with the signature:
    \begin{lstlisting}
long rank(long x);
    \end{lstlisting}

    \item
    The $\text{select}(i)$ operation returns $y \in S$ with $rank(y) = i$ and it is to be implemented by a method with the signature:
    \begin{lstlisting}
Long select(long rank);
    \end{lstlisting}
\end{itemize}
Additionally, the following method signatures/default method are included in the interface:
\begin{itemize}
    \item
    A {\ttfamily size()} method that returns the current number of keys in the set:
    \begin{lstlisting}
long size();
    \end{lstlisting}

    \item
    An {\ttfamily isEmpty()} default method that returns {\ttfamily true} if the set is empty and {\ttfamily false} otherwise:
    \begin{lstlisting}
default boolean isEmpty() {
    return size() == 0;
}
    \end{lstlisting}

    \item
    A {\ttfamily reset()} method that removes all current elements from the set:
    \begin{lstlisting}
void reset();
    \end{lstlisting}
\end{itemize}

Note that some of the methods return a primitive type, whereas some others return a boxed type. This is because some queries are not mapped to any answer, and the boxed type provides the perfect way to model this kind of scenario: in this situation, {\ttfamily null} is returned.

\newpage
\section{Naive Implementation} \label{sec:naiveImplementation}

\paragraph*{Goal}
To implement a naive dynamic predecessor data structure with an array.

\begin{figure}[H]
\dirtree{% 
.1 /. 
.2 src. 
.3 main. 
.4 java. 
.5 integersets. 
.6 \textbf{NaiveDynamicFusionNode.java}. 
}
\caption{Location of the {\ttfamily NaiveDynamicFusionNode.java} file in the folder structure}
\label{fig:NaiveDynamicFusionNodeTree}
\end{figure}

We start with a naive implementation of name {\ttfamily NaiveDynamicFusionNode}, which follows closely the Array approach mentioned in Section~\ref{sec:array}.
It holds a $key$ array to store the keys, and a counter for the current number of keys in the data structure. The keys can be any 64-bit integer.

The basic idea behind this implementation is to store the keys in $key$, making their respective rank the same as their index in the array. In other words, $key$ is always sorted.

Updates, e.g., insert and delete, take $O(n)$ time. This is because whenever a key is inserted, its rank $i$ is found, and the key at that position as well as all following keys up to $n-1$ are updated. Since any given key index in $key$ is its rank, all the keys with rank larger than the new key have to be moved one position to the right in $key$ to make room for the new key and keeping rank consistent.

A rank query takes $O(\log_2 n)$ because a binary search is performed on $key$. Select is faster: $O(1)$, because we need only to access and return the key at position $i$ in $key$ to fulfill the query.

\newpage
\section{Dynamic Fusion Node with Binary Search for Rank} \label{sec:DynamicFusionNodeBinaryRank}

\paragraph*{Goal}
To improve the time performance of the implementation presented in Section~\ref{sec:naiveImplementation} by adding instance variables that enable indexing the keys by their rank. By doing so, updates and rank queries now take $O(\log_2 n)$ time. Select takes $O(1)$ time.

This implementation can be found in the file highlighted in figure~\ref{fig:DynamicFusionNodeBinaryRankTree}.
\begin{figure}[H]
\dirtree{% 
.1 /. 
.2 src. 
.3 main. 
.4 java. 
.5 integersets. 
.6 \textbf{DynamicFusionNodeBinaryRank.java}. 
}
\caption{Location of the {\ttfamily DynamicFusionNodeBinaryRank.java} file in the folder structure}
\label{fig:DynamicFusionNodeBinaryRankTree}
\end{figure}

We take a step forward by improving the previous idea: this time, two additional words, $index$ and $bKey$, are kept in the fields. The goal is to use the concepts described in the \textit{Indexing} section of \cite{patrascu2014dynamic} to implement this data structure. The running times will be $O(\log_2 n)$ for updating and querying, and this is because the rank operation resorts to binary search to produce the result.

An important parameter introduced in this implementation is $k$. It defines the capacity limit of the set. We wish to maximize this parameter, but we will see below that the word size, $w$, will be this parameter's constraining factor in this implementation.

This time, $key$ is no longer sorted, but we still have access to the keys in their sorted order by using a simple device: we interpret $index$ as an array of $k$ fields of $\lceil \log_2 k \rceil$ bits in length. It indexes the keys in $key$ by their rank the following way: Let $i$ be the rank of a key in the set, then $index\langle i\rangle_{\lceil \log_2 k \rceil}$ will have the index in $key$ of the key with rank $i$.
In order to maximize the use of the number of bits in $index$, and knowing that our program is working with 64-bit, as stated in Section~\ref{sec:word}, we maximize $k$ by solving the following inequation:
\begin{equation} \label{eq:problemSizeBinaryRank}
    \begin{aligned}
        &k \cdot \log_2(k) \leq 64 \\
        \iff &k \leq 16
    \end{aligned}
\end{equation}
Note that this is precisely what we have mentioned in Section~\ref{sec:transdichotomousRAM} with expression~\ref{eq:problemSize}.
We maximized the capacity of the set by solving $k$ in inequation~\ref{eq:problemSizeBinaryRank}.
Thus we know now that if $k = 16$, then $\lceil \log_2(k) \rceil = 4$.
So, each $\lceil \log_2(k) \rceil$-bit field of $index$ stores the index of the key in $key$ in their sorted order.

We interpret $bKey$ as an array where the values of the first $k$ bits correspond to the positions in $key$. Like any other word, the bits in $bKey$ are indexed from $0$ to $k-1$, and if the $i^{\text{th}}$ bit is set to $1$, then position $i$ in $key$ is free to store a key, and vice-versa. We initialize $bKey$ as $-1$, which represents the case where the set is empty.

\subsection{Fields} \label{sec:binaryRankFields}
The class holds the following fields:
\begin{itemize}
    \item
    The class constants $k$ and $\lceil \log_2(k) \rceil$:
    \begin{lstlisting}
private static final int k = 16;
private static final int ceilLgK = (int) Math.ceil(Math.log10(k)/Math.log10(2));
    \end{lstlisting}

    \item
    The array of keys, $key$:
    \begin{lstlisting}
private final long[] key = new long[k];
    \end{lstlisting}
    
    \item
    The $index$ word:
    \begin{lstlisting}
private long index;
    \end{lstlisting}

    \item
    The map of the empty entries in $key$, $bKey$:
    \begin{lstlisting}
private int bKey;
    \end{lstlisting}
    Note that only the first $k$ bits are relevant for any given instance.
    
    \item
    An integer $n$, containing the current number of keys in the set:
    \begin{lstlisting}
private int n;
    \end{lstlisting}
\end{itemize}

\subsection{Helper Methods} \label{sec:binaryRankHelperMethods}
\begin{itemize}
    \item
    {\ttfamily firstEmptySlot()} returns the first available spot in $key$ by computing $\text{lsb}(bKey)$. Since only the first $k$ spots are valid results, a check is done to see if this result is within the range, returning $-1$ if not.
    
    \item
    {\ttfamily fillSlot(final int j)} sets position $j$ in $bKey$ to not empty. This is done with a call to $\text{deleteBit}(j, bKey)$.
    
    \item
    {\ttfamily vacantSlot(int j)} sets the $j^{\text{th}}$ position of $bKey$ to empty by calling $\text{setBit}(j, bKey)$.
    
    \item
    {\ttfamily getIndex(final long i)} returns the index in $key$ of the key with rank $i$. This operation is done with a call to $\text{getField}(i, \lceil \log_2 k\rceil, index)$.
    
    \item
    The purpose of the overloaded method {\ttfamily updateIndex} is to maintain the correspondence between the rank of the keys in the set and their position in $key$.
    The version with {\ttfamily updateIndex(final int i)} signature removes rank $i$ from $index$, whereas the {\ttfamily updateIndex(final int i, final int slot)} inserts in $index$ at position $i$ the index in $key$ (here denoted by $slot$). Both versions make calls to the $\text{getFields}$ methods with the adequate parameters, merge the results with bitwise $\vee$ and write those back in $index$.
    
    \item
    {\ttfamily binaryRank(final long x)} returns the rank of $x$ in the set, using {\ttfamily select(final long rank)} as a subroutine. As the name implies, the algorithm used in this implementation is binary search.
\end{itemize}

\subsection{Implementation of the Interface Methods} \label{sec:binaryRankInterfaceImplementation}
\begin{itemize}
    \item \label{sec:binaryRankInsert}
    {\ttfamily insert(final long x)}:
    \begin{enumerate}
        \item
        We call $\text{member}(x)$ to know if the $x$ is already in the set. If it is, then the method returns.
        
        \item
        We compare {\ttfamily size()} with $k$. This is because we can only insert if there is room for another key. We progress if there is room for $x$.
        
        \item
        The rank of $x$ in the set is found with a call to  $\text{rank}(x)$ and stored in a local variable $i$.
        
        \item
        The first available spot in $key$ is found with a call to {\ttfamily firstEmptySlot()} and stored in a local variable $j$.
        
        \item
        We store $x$ in $key$ at the position returned by {\ttfamily firstEmptySlot()}.
        
        \item
        We set the position taken $x$ in $key$ to not empty by calling {\ttfamily fillSlot(j)}.
        
        \item
        We update the $index$ to reflect the new key's insertion with a call to {\ttfamily updateIndex(i, j)}.
        
        \item
        Lastly, we increment $n$ by $1$, updating the current total number of keys in the set.
    \end{enumerate}
    
    \item
    {\ttfamily delete(final long x)}:
    \begin{enumerate}
        \item
        If the $x$ is not in the set, the method does not progress. This is done with a call to $\text{member}(x)$.
        
        \item
        The rank of the $x$ in the set is found with a call to $\text{rank}(x)$ and stored in a local variable $i$.
        
        \item
        $bKey$ is updated by making the spot taken by $x$ in $key$ empty. This is done with the call {\ttfamily vacantSlot(getIndex(i))}.
        
        \item
        We update the $index$ to reflect the deletion of $x$ with a call to {\ttfamily updateIndex(i)}.
        
        \item
        Lastly, we decrement $n$ by $1$, updating the current total number of keys in the set.
    \end{enumerate}
    
    \item
    {\ttfamily rank(final long x)} returns the rank of $x$ in the set by calling the {\ttfamily binaryRank(final long x)} helper method.
    
    \item
    {\ttfamily select(final long rank)} starts by checking if the $rank$ is within range, returning {\ttfamily null} if not. Then it calls {\ttfamily getIndex(rank)} and returns the key at that position in $key$.
    
    \item
    {\ttfamily size()} returns the value of $n$.
    
    \item
    {\ttfamily reset()}.
    Resetting the set is easily done by setting $n$ to $0$ and $bKey$ to $-1$ (because $-1$ has all the bits set to $1$ in its two's complement binary representation).
\end{itemize}

\subsection{Example}

The \textit{Indexing} technique combined with binary rank is best understood with an example, which we showcase in this section.


Assume that we have instantiated a {\ttfamily DynamicFusionNodeBinaryRank} and, for brevity, let $k = 8$. Then:
\begin{align*}
    k = 8 \implies \lceil \log_2 k \rceil = 3
\end{align*}

These will remain constant and are stored as static fields:
\begin{lstlisting}
private static final int k = 8;
private static final int ceilLgK = (int) Math.ceil(Math.log10(k) / Math.log10(2));
\end{lstlisting}

Assume that at this point the above-mentioned instance contains the keys from expression \ref{eq:keysInSet}, thus the mentioned instance maps to $S$.
\begin{equation} \label{eq:keysInSet}
    S = \{10, 12, 42, -1337, -42 \}
\end{equation}

The order in which keys are inserted will influence the order in which they will appear in the instance variable $key$. But, as mentioned in Section~\ref{sec:DynamicFusionNodeBinaryRank}, the instance variable $index$ will index the key indices in $key$ by their rank whereas the bit values of $bKey$ will specify if the corresponding position in $key$ is empty. Thus a possible state for the instance is the following:

\begin{figure}[H]
\centering
\input{04_Tables/029_indexKeyBKey.tex}
\caption[Set $S$ represented by the state of the instance variables]{Set $S$ represented as the $index$, $bKey$ and $key$ instance variables in a {\ttfamily DynamicFusionNodeBinaryRank} instance}
\label{fig:stateOfTheInstance}
\end{figure}

An important note is that the values at indices in $key$ marked with "$?$" might hold values, but these are not accessible since they are not index in $index$.

\subsubsection{Querying}

\paragraph{Select}
Let $i$ be the rank of the key we wish to query. Then
\begin{align*}
\text{select}(i) = key[ index\langle i\rangle_{\lceil \log_2 k \rceil}]
\end{align*}
Assume we wish to know the key with rank 2, then:
\begin{align*}
    i = 2 \\
    index\langle 2\rangle_3 = 110_2 = 6 \\
    \cline{1-2}
    \text{select}(2) = key[6] = 42
\end{align*}

\paragraph{Rank}
As previously mentioned, at this point, the rank operation has been implemented with binary search using select as a subroutine. This works in $O(\log_2 n)$ time because select queries take $O(1)$ time, the select method allows us to access the keys as if they were stored in their respective sorted order and therefore, the running time is bound by the binary search algorithm itself.

\subsubsection{Updating}

\paragraph{Insert} \label{sec:binaryRankInsertExample}

Let $x = -1000$ be the key we wish to insert and $S$ the set we wish to insert it in, defined in expression~\ref{eq:keysInSet} and figure~\ref{fig:stateOfTheInstance}. The insertion of $x$ in $S$ on this data structure is comprised of the following:
\begin{enumerate}
    \item
    We check if $x$ is already in the set, returning in such a case.
    This is not the case, so we proceed.
    
    \item
    Then we check if the set has room for the new key by comparing {\ttfamily size()} with $k$. If it is full, then an exception is thrown.
    This is not the case, so we proceed.
    
    \item
    We compute $\text{rank}(x)$ and store it in a local variable $i$.
    \begin{align*}
        x = -1000 \\
        \cline{1-2}
        i \coloneqq \text{rank}(-1000) = 4
    \end{align*}
    
    \item
    We find the first empty position in $key$ with a call to {\ttfamily firstEmptySlot()}, storing the result in a local variable $j$.
    \begin{align*}
        j \coloneqq \text{{\ttfamily firstEmptySlot()}} = 2
    \end{align*}
    
    \item
    We store $x$ in $key$ at position $j$. We can see $key$ after this update on table~\ref{tab:keyAfterInsertion}.
    \begin{table}[H]
    \centering
    \input{04_Tables/030_keyAfterInsertion.tex}
    \caption[Example $key$ after the insertion of a new key]{Instance variable $key$ after setting $key[2] = -1000$}
    \label{tab:keyAfterInsertion}
    \end{table}
    
    \item
    We mark position $j$ as not empty, thus having table~\ref{tab:bKeyAfterInsertion} as the resulting $bKey$. This is done with the call {\ttfamily fillSlot(j)}.
    \begin{table}[H]
    \centering
    \input{04_Tables/031_bKeyAfterInsertion.tex}
    \caption[Example $bKey$ after the insertion of a new key]{Instance variable $bKey$ after marking position 2 as not empty}
    \label{tab:bKeyAfterInsertion}
    \end{table}
    
    \item
    With $i$ and $j$, we can now update $index$ such that the indices of the keys are once again sorted by the keys' ranks. This is done by calling {\ttfamily updateIndex(i, j)}. The resulting $index$ is shown in table~\ref{tab:indexAfterInsertion}.
    \begin{table}[H]
    \centering
    \input{04_Tables/032_indexAfterInsertion.tex}
    \caption[Example $index$ after the insertion of a new key]{Instance variable $index$ after the insertion of a key with rank 4 at position 2 in $key$}
    \label{tab:indexAfterInsertion}
    \end{table}
    
    \item
    Lastly, we increment the instance variable $n$.
\end{enumerate}

\paragraph{Delete}

We will now delete $x = -1000$, having as starting point the state the instance was right after the insertion described in \ref{sec:binaryRankInsertExample}. Deleting $x$ from $S$ on this data structure is comprised of the following:
\begin{enumerate}
    \item
    We check if $x$ is not in the set, returning in such a case.
    This is not the case, so we proceed.
    
    \item
    We compute $\text{rank}(x)$ and store it in a local variable $i$.
    \begin{align*}
        x = -1000 \\
        \cline{1-2}
        i \coloneqq \text{rank}(-1000) = 4
    \end{align*}
    
    \item
    With a call to {\ttfamily getIndex(i)} we get the position in $key$ where $x$ is stored. We use that to mark that position as empty in $bKey$. This is done with {\ttfamily vacantSlot(getIndex(i))}. After this update, $bKey$ will be the same as in table~\ref{tab:binaryRankKey}.
    
    \item
    We also need to update $index$ by moving all the indices with rank larger than $i$, the rank of $x$, $1$ position to the left. We do this by calling {\ttfamily updateIndex(i)}. This update will make $index$ be as shown in table~\ref{tab:binaryRankIndex}.
    
    \item
    Lastly, we decrement the instance variable $n$.
\end{enumerate}

\newpage
\section{Rank via Matching with "Don't Cares"} \label{sec:rankWithDontCares}

\paragraph*{Goal}
Having the implementation from Section~\ref{sec:DynamicFusionNodeBinaryRank} as a starting point, the goal is to implement rank queries via matching with "don't cares". Rank will now take $O(k)$ time, and this is due to a subroutine, {\ttfamily match}, which at this stage is computed naively. Select queries keep their $O(1)$ time, whereas updates now take $O(k\cdot n)$ because the instance variables introduced in this implementation are maintained naively.

Static Fusion Trees have less than optimal update time because adding a new key entails recomputing sketches. Pătrașcu and Thorup address this by introducing "don't cares", which provides a simulation of a Patricia Trie at the node level. This is relevant because, differently to what happens at the Fusion Tree node from Fredman and Willard, inserting a new key in a Patricia Trie corresponds to adding a new branch node \cite{patrascu2014dynamic}.

In this incremental step, we keep the most of the implementation details of Section~\ref{sec:DynamicFusionNodeBinaryRank}, plus we store the compressed keys with "don't cares" to enable the rank operation as described in the \textit{Matching with don't cares} section of \cite{patrascu2014dynamic}.

The implementation discussed in this section can be found in the file highlighted in figure~\ref{fig:DynamicFusionNodeBinaryRankTree}.
\begin{figure}[H]
\dirtree{% 
.1 /. 
.2 src. 
.3 main. 
.4 java. 
.5 integersets. 
.6 \textbf{DynamicFusionNodeDontCaresRank.java}. 
}
\caption{Location of the {\ttfamily DynamicFusionNodeDontCaresRank.java} file in the folder structure}
\label{fig:DynamicFusionNodeDontCaresRankTree}
\end{figure}

Enabling rank via matching with "don't cares" entails the following:
\begin{itemize}
    \item
    Compressing keys (or \textit{sketching}) in the same style as Fusion Trees, from Fredman and Willard.
    
    In order to compress keys, we need a compressing key. Let $S = \{x_i, \dots, x_j\}$. A naive way to compute a compressing key is to set the $\text{msb}(x_i \oplus x_j)$ bit by of all combinations of $\{x_i, \dots, x_j\}$ keys in $S$ in a word.
    
    We denote the compressed version of $x$ by $\hat x $. A naive way to compress a key $x$ is to iterate through the set bits of the compressing key, storing the bit values at those positions of $x$ in $\hat x$.
    
    \item
    Encoding the information about "don't cares". We denote a compressed key with "don't cares" by $\hat x^?$. A compressed key with "don't cares" has length $k$ and can be any combination of the characters $\{0, 1, ?\}$. Since the bits of a word in a real machine can only take the values $\{0, 1\}$, we need an additional construct to enable the third character. This shows that a single word for storing the compressed keys with "don't cares" is not enough. So we keep two new instance variables, the words: $branch$ and $free$.
    
    These words are to be interpreted as two $k \times k$ bit matrices, and they are defined in the following way:
    \begin{itemize}
        \item
        We see each field $branch\langle i \rangle_k$ as a row in the matrix, and each row maps to a compressed key in the set with rank $i$.
        As its name implies, $branch$ will contain the values of the branching bits. 
        So each column $j$, e.g. $branch\langle i, j\rangle_{1 \times k}$, corresponds to a branching bit.
        We will store the compressed keys except for the "don't cares" positions, which are always stored with value $0$.
        In other words, if a particular branching bit of a compressed key is not a "don't care", then the value of the bit at that position in $branch$ (in its corresponding row) will be the same as of bit at that position in the corresponding compressed key; otherwise, it is 0.
        
        \item
        In regards to $free$, its rows and columns have the same correspondence as in $branch$.
        When seeing the keys in a matrix and ordered by their rank, we can see that the value of some of those positions does not influence the rank of the (compressed) keys.
        These positions will be "don't cares".
        We will encode this data in the following way: If a particular branching bit of a compressed key is a "don't care", the bit at the same index in $free$ (in its corresponding row) is $1$, otherwise it is $0$.
    \end{itemize}

    \item
    A subroutine $\text{match}(x)$ that uses all of the above and rank via Rank Lemma 1 (defined in Section~\ref{sec:rankLemma1} and implemented in Section~\ref{sec:rankLemma1Implementation}).
    
    Let $\hat x^k$ be the compressed version of $x$ copied $k$ times and stored in a word. After compressing $x$ and multiplying $\hat x$ with the mask $M$ (which has been computed via the {\ttfamily Util} helper function and stored as a class variable), we achieve the intended result. Note that we have already used multiplication in a similar context in Section~\ref{sec:computeM}.
    Then $\text{match}(x)$ is computed with the following expression \cite{patrascu2014dynamic}:
    \begin{align*}
        \text{match}(x) = \underbrace{\text{rank}(\hat x, branch \vee (\hat x^k \wedge free))}_{\text{Rank Lemma 1}}
    \end{align*}
\end{itemize}

The implementation of Section~\ref{sec:DynamicFusionNodeBinaryRank} had the word $index$ as the limiting factor of $k$ because we had to be able to index all the positions of the set. This time, the limiting factor for $k$ will be the $branch$ and $free$ matrices: since those have $k$ rows and $k$ columns and a word in our machine is of length 64, we have:
\begin{align*}
    k^2 \leq 64\\
    \implies k \leq \sqrt{64}\\
    \iff k \leq 8
\end{align*}

This class shares many implementation details with the \textit{Dynamic Fusion Node} with binary Rank from Section~\ref{sec:DynamicFusionNodeBinaryRank}. For that reason, in the next few sections, we will see what is kept, added, or altered compared with that implementation while expanding only on the last two. The highlighted changes enable the new operations of this class.

\subsection{Fields} \label{sec:dontCaresRankFields}
The following fields were kept unchanged and stand for the same as in \ref{sec:binaryRankFields}:
\begin{lstlisting}
private final long[] key = new long[k];
private long index;
private int bKey;
private int n;
\end{lstlisting}

The following fields were either altered or introduced:
\begin{itemize}
    \item
    The parameter $k$ has been altered. This is because, as explained in \ref{sec:rankWithDontCares}, $branch$ and $free$ will limit further the capacity of the set:
    \begin{lstlisting}
private static final int k = 8;
    \end{lstlisting}
    
    \item
    We will need a constant $M$ to be used as mask in some of methods. We resort to the {\ttfamily M} function of the {\ttfamily Util} class, and store the result as a class variable.
    \begin{lstlisting}
private static final long M = Util.M(k, k * k);
    \end{lstlisting}

    \item
    The operations introduced in this implementation require us to compress keys. To this extent, we store a word, $compressingKey$, which will retain the information regarding the bits to keep when compressing a $key$. If a bit is significant, then it will be set to $1$ in $compressingKey$.
    \begin{lstlisting}
private long compressingKey;
    \end{lstlisting}

    \item
    As explained in \ref{sec:rankWithDontCares}, the word $branch$ is interpreted as a $k \times k$ bit matrix, $BRANCH$, that Pătrașcu and Thorup use to store the part of the data of compressed keys with "don't cares".
    We see each $branch\langle i \rangle_k$ as a row in the matrix, each row corresponding to the compressed version of the key with rank $i$ in the set.
    Each column $j$, e.g., $branch\langle i, j\rangle_{k \times 1}$ corresponds to a branching bit of the compressed key with "don't cares" of rank $i$.
    \begin{lstlisting}
private long branch;
    \end{lstlisting}
    
    \item
    The word $free$ is the $k \times k$ bit matrix $FREE$, which is used for storing the rest of the data of the compressed keys with "don't cares". Indexing of rows and columns are mapped in the same way as in $branch$.
    \begin{lstlisting}
private long free;
    \end{lstlisting}
\end{itemize}

\subsection{Helper Methods} \label{sec:dontCaresRankHelperMethods}

The following helper methods suffered no changes and serve the same purpose as in the implementation from Section~\ref{sec:binaryRankHelperMethods}:
\begin{itemize}
    \item
    {\ttfamily firstEmptySlot()}
    
    \item
    {\ttfamily fillSlot(final int j)}
    
    \item
    {\ttfamily vacantSlot(int j)}
    
    \item
    {\ttfamily getIndex(final long i)}
    
    \item
    The overloaded methods {\ttfamily updateIndex}
\end{itemize}

The following are helper methods introduced in this implementation:
\begin{itemize}
    \item
    {\ttfamily updateCompressingKey()} updates the compressing key by looping through all the combinations of keys in the set and setting all the first branching bits between those keys in $compressingKey$. E.g., let $x$ and $y$ be a particular combination of two keys in the set. The method sets in $compressingKey$ the $\text{msb}(x \oplus y)$ of all combinations of keys in the set. This approach is naive and slow, with $O(n^2)$ time.
    
    \item
    {\ttfamily compress(final long x)} uses $compressingKey$ in order to compute the compressed version of the input key, $x$. It loops through the set bits of $compressingKey$, setting the bits $\hat x$ by reading actual bit values at those positions in $x$. Since this is done naively, it takes $O(k)$ time.

    \item
    {\ttfamily long compressedKeys()} returns a word containing all the compressed keys present in the set and ordered by rank. This is done by looping through all keys in the set and calling the {\ttfamily compress(x)} method on every key. This method is called after upon updating the set, and since all the compressed keys are recomputed, this takes $O(n)$ time.
    
    \item
    The {\ttfamily updateFree(final long compressedKeys)} method makes a call to the recursive {\ttfamily dontCares} method (explained below) which updates $free$ after the insertion or deletion of a key.

    \item
    The {\ttfamily dontCares} method has the following signature:
    \begin{lstlisting}
private long dontCares(long compressedKeys, long free, final int bit, final int lo, final int hi)
    \end{lstlisting}
    It uses the $compressedKeys$ word to compute $free$ recursively. The method with store the data about "don't cares" in $free$ as it iterates.
    The $compressedKeys$ parameter is not to be confused with $branch$, which is computed after $free$ is computed, and it is computed by the {\ttfamily compressedKeys()} method, described above, containing only the compressed keys. It is because we need to compute which positions are "don't cares" that we use the plain compressed keys with this method.
    
    $bit$ refers to the index of a column (in both $compressedKeys$ and $free$), whereas $hi$ and $lo$ refers to a range of rows (also in both $compressedKeys$ and $free$).
    $free$ is updated by following the steps:
    \begin{enumerate}
        \item
        Starting from the most significant column (given by the parameter $bit$), e.g., the most significant bit of the compressed key and a range of keys that includes all rows:
        \begin{itemize}
            \item
            If all bits in that column are the same, then that position is a "don't care" for all keys. This is because, in this range, regardless of the value of the bit, the order of the keys is always the same.
            
            \item
            If at least one bit differs in that column, then we care for that position in all keys. Again, the particular value for these rows and column contributes to the order of the compressed keys.
        \end{itemize}
        
        \item
        The method is called recursively:
        \begin{itemize}
            \item
            If the bits were all the same for that range and in that column, then the method is called with the same range of rows, but now on the next lesser significant column.
            
            \item
            Otherwise, we do two recursive calls: one for the range of rows whose bit was set to 0 and another for the keys that had the bit set to 1 in that column.
        \end{itemize}
        
        \item
        The recursive call chain reaches its end when the column index, $bit$, is $-1$.
    \end{enumerate}
    Since the method iterates through all $k$ columns and $n$ rows (which correspond to compressed versions of keys in the set) of $free$, this algorithm takes $O(k \cdot n)$ time.
    
    \item
    After having $compressedKeys$ and $free$ computed, the {\ttfamily final long compressedKeys} method updates $branch$ with the expression:
    \begin{align*}
        branch \coloneqq compressedKeys \wedge \neg free
    \end{align*}
    This takes $O(1)$ time.
    
    \item
    The helper method {\ttfamily match(x)} has the signature:
    \begin{lstlisting}
private int match(final long x)
    \end{lstlisting}
    As mentioned in \ref{sec:rankWithDontCares}, it implements the operation described in the \textit{Matching with don't cares} section of \cite{patrascu2014dynamic}.
    Since it uses {\ttfamily compress(final long x)} as a subroutine, its running time is bounded by the running time of that operation.
    
    \item
    The {\ttfamily dontCaresRank(final long x)} returns the rank of $x$ in the set, using {\ttfamily match(final long x)}, {\ttfamily select(final long rank)}, {\ttfamily msb(final int x)} as subroutines.
    The implementation follows the algorithm presented by Pătrașcu and Thorup in the \textit{Matching with don't cares} section of \cite{patrascu2014dynamic}.
    Its running time is bounded by the running time of its slowest subroutine, {\ttfamily match(final long x)}, which in turn calls {\ttfamily compress(final long x)}, which takes $O(k)$ time.

\end{itemize}

\subsection{Implementation of the Interface Methods} \label{sec:dontCaresRankInterfaceImplementation}

The following interface methods suffer no changes and serve the same purpose as the implementation from Section~\ref{sec:DynamicFusionNodeBinaryRank}:
\begin{itemize}
    \item
    {\ttfamily select(final long rank)}
    
    \item
    {\ttfamily size()}
\end{itemize}

The following interface methods suffer changes in relation to Section~\ref{sec:binaryRankInterfaceImplementation}:
\begin{itemize}
    \item
    {\ttfamily insert(final long x)} keeps all the steps described in Section~\ref{sec:binaryRankInsert} and adds the following right after those steps:
    \begin{enumerate}
        \item
        The $compressingKey$ is updated with a call to {\ttfamily updateCompressingKey()}.
        
        \item
        All the keys are compressed and the result is stored in a local variable with the statement:
        \begin{lstlisting}
final long compressedKeys = compressedKeys();
        \end{lstlisting}
        
        \item
        $free$ is updated with the call:
        \begin{lstlisting}
updateFree(compressedKeys);
        \end{lstlisting}
        
        \item
        And the last step is to update $branch$, which is done with:
        \begin{lstlisting}
updateBranch(compressedKeys);
        \end{lstlisting}
    \end{enumerate}
    
    \item
    Similarly to {\ttfamily insert}, {\ttfamily delete(final long x)} keeps all the steps from Section~\ref{sec:binaryRankHelperMethods} and adds the following right after those steps:
    \begin{enumerate}
        \item
        The $compressingKey$ is updated with a call to {\ttfamily updateCompressingKey()}.
        
        \item
        All the keys are compressed and the result is stored in a local variable with the statement:
        \begin{lstlisting}
final long compressedKeys = compressedKeys();
        \end{lstlisting}
        
        \item
        $free$ is updated with the call:
        \begin{lstlisting}
updateFree(compressedKeys);
        \end{lstlisting}
        
        \item
        And the last step is to update $branch$, which is done with:
        \begin{lstlisting}
updateBranch(compressedKeys);
        \end{lstlisting}
    \end{enumerate}
    
    \item
    {\ttfamily rank(final long x)} returns the rank of $x$ in the set by calling the {\ttfamily dontCaresRank(final long x)} helper method.
    
    \item
    {\ttfamily reset()}.
    Resetting the data structure now also entails resetting some of the instance variables. The additional operations are:
    \begin{itemize}
        \item
        Setting $compressingKey$ to $0$ because, in an empty set, there are no branching bits.
        
        \item
        Setting $branch$ to $0$ because, in an empty set, there are no compressed keys.
        
        \item
        Setting $free$ to $-1$, because in an empty set, there are no keys and bits set in $free$ mean that we do not care for those positions of the compressed keys.
    \end{itemize}
\end{itemize}

\subsection{Example} \label{sec:dontCaresRankExample}

This section is aimed at showcasing how the compressed keys with "don't cares" are stored in the data structure and what are the steps taken by the algorithm to return a $\text{rank}(x)$ query using the algorithm implemented in the {\ttfamily dontCaresRank(final long x)} method.

Our example starts with a set containing the keys from table~\ref{tab:keysInTheSetForRank} and a rank query key $x = 1010\ 1010\ 1111_2$. For brevity, the selected set of keys will only have bits set between the indices 0 and 11. This way, we know that the 52 leading bits will have no influence when running the algorithm.

\begin{table}[H]
\centering
\input{04_Tables/003_keysInTheSet.tex}
\caption[Example of keys present in the set stored in $key$ in binary]{Keys present in the set stored in $key$ in binary. The header row are the bit indices and the rank of the keys is the first column.}
\label{tab:keysInTheSetForRank}
\end{table}

We can already see that $\text{rank}(x) = 4$.

\subsubsection{Key Compression} \label{sec:keyCompression}

The keys from table~\ref{tab:keysInTheSetForRank} will produce the following compressing key (with the $52$ most significant bits omitted for brevity):
\begin{align*}
    compressingKey = 1111\ 1001\ 0010_2
\end{align*}

Having this compressing key implies that, when compressing keys, we keep only the bits at positions 1, 4, 7, 8, 9, 10, and 11. We can see these indices highlighted in table~\ref{tab:significantBitsHighlighted}.

\begin{table}[H]
\centering
\input{04_Tables/004_significantBitsHighlighted.tex}
\caption[Example of bits that are kept when compressing keys]{The highlighted columns correspond to the set bits of the compressing key. When compressing a key, we keep only the bits of the highlighted columns.}
\label{tab:significantBitsHighlighted}
\end{table}

After compressing our keys with our $compressingKey$, we end up with the result of table~\ref{tab:compressedKeys}.

\begin{table}[H]
\centering
\input{04_Tables/005_compressedKeys.tex}
\caption[Example of compressed keys]{Compressed Keys}
\label{tab:compressedKeys}
\end{table}

\subsubsection{Compressed Keys with "Don't Cares"} \label{sec:keyCompressionWithDontCares}

As previously mentioned, the particular value of some of the bits at some positions has no influence on the rank of the keys. These positions have been replaced with "$?$" on table~\ref{tab:compressedKeysWithDontCares}. The operation of transforming compressed keys in compressed keys with "don't cares" corresponds to what the {\ttfamily dontCares} method described in \ref{sec:dontCaresRankHelperMethods} does.

\begin{table}[H]
\centering
\input{04_Tables/006_compressedKeysWithDontCares.tex}
\caption[Example of compressed keys with "don't cares"]{Compressed Keys with "don't cares"}
\label{tab:compressedKeysWithDontCares}
\end{table}

In the data structure, this data is stored in the two class variables, $branch$ and $free$, which follows the logic explained in \ref{sec:rankWithDontCares}. They are each a single $w$-bit word. If we lay each of those words in a $k \times k$ matrix, then each row will correspond to a compressed key. This is precisely what we see in the tables from figure~\ref{fig:branchAndFreeCompressedKeys}.% tables~\ref{tab:branchTable} and \ref{tab:freeTable}.

\begin{figure}[H]
\centering
\input{04_Tables/007_branchTable.tex}
\caption[Example of how the compressed keys with "don't cares" are stored in the instance variables $branch$ and $free$]{Compressed keys with "don't cares" stored in the resulting words $branch$ and $free$ displayed in $k \times k$ matrices}
\label{fig:branchAndFreeCompressedKeys}
\end{figure}

% \begin{table}[H]
% \centering
% \input{04_Tables/008_freeTable.tex}
% \caption{The resulting word $free$ laid in a $k \times k$ matrix}
% \label{tab:freeTable}
% \end{table}

\subsubsection{Querying} \label{sec:rankDontCaresQuery}

Sections \ref{sec:keyCompression} and \ref{sec:keyCompressionWithDontCares} have handled the contents of the set and the relevant class variables for this operation. We shall now see what unfolds as soon as we query $\text{rank}(1010\ 1010\ 1111_2)$.

\begin{enumerate}
    \item
    The method starts by checking if the set is empty, returning $0$ in this situation. It is not the case in the example, so we proceed.
    
    \item
    A call to {\ttfamily match} with the query $x$ is done: $\text{match}(1010\ 1010\ 1111_2)$. The operation entails compressing the query, computing the word $branch \vee (\hat x^k \wedge free)$ and computing the rank of $\hat x$ in that word via Rank Lemma 1.
    \begin{enumerate}
        \item
        We compress the query with $\text{compress}(1010\ 1010\ 1111_2)$. Thus we have:
        \begin{align*}
            compressingKey = 1111\ 1001\ 0010_2\\
            x = \underline{1010}\ \underline{1}01\underline{0}\ 11\underline{1}1_2\\
            \cline{1-2}
            \hat x = \underbrace{0\underline{101}\ \underline{0101}_2}_k
        \end{align*}
        \item
        We make $k$ copies $\hat x$:
        \begin{align*}
            M = (0^{k-1}1)^k_2\\
            \hat x = 0101\ 0101_2\\
            \cline{1-2}
            \hat x^k = M \times \hat x = (0101\ 0101_2)^k\\
        \end{align*}
        
        If we lay the resulting word in a matrix we have:
        \begin{table}[H]
        \centering
        \input{04_Tables/009_xCompressedCopiedMatrix.tex}
        \caption[Example of a compressed key copied $k$ times and laid in a $k \times k$ matrix]{$k$ copies of $\hat x$ in a word laid in a $k \times k$ matrix}
        \label{tab:xCompressedCopied}
        \end{table}
        
        \item
        We compute $\hat x^k \wedge free$, which keeps only the "don't cares" bits in $\hat x^k$. By bitwise $\wedge$ tables \ref{tab:xCompressedCopied} and \ref{tab:freeTable} we have:
        \begin{table}[H]
        \centering
        \input{04_Tables/010_xCompressedANDfree.tex}
        \caption[Example of $\hat x^k \wedge free$ in a word laid in a $k \times k$ matrix]{$\hat x^k \wedge free$ in a word laid in a $k \times k$ matrix}
        \label{tab:xCompressedANDfree}
        \end{table}
        
        \item
        We compute $branch \vee (\hat x^k \wedge free)$, which is done by bitwise $\vee$ tables~\ref{tab:branchTable} and \ref{tab:xCompressedANDfree}. This operation will use the actual bits of $\hat x^k$ in the "don't cares" positions of all the compressed keys with "don't cares" in the set. Thus we end up with:
        \begin{table}[H]
        \centering
        \input{04_Tables/011_branchORxCompressedANDfree.tex}
        \caption[Example of $branch \vee (\hat x^k \wedge free)$ in a word laid in a $k \times k$ matrix]{$branch \vee (\hat x^k \wedge free)$ in a word laid in a $k \times k$ matrix}
        \label{tab:branchORxCompressedANDfree}
        \end{table}
        
        \item
        Now, match returns $\text{rank}(\hat x, branch \vee (\hat x^k \wedge free))$ via Rank Lemma 1. In table~\ref{tab:branchORxCompressedANDfree}, we can see that $\hat x = 0101\ 0101_2$ is larger than the keys up to row 4, meaning that its rank is 5 (the highlighted row). Thus we have:
        \begin{align*}
            \text{match}(x) = 5
        \end{align*}
    \end{enumerate}
    This result is stored in a local variable, $i$.
    
    \item
    We perform the query $\text{select}(i)$:
    \begin{align*}
        i = 5\\
        \cline{1-2}
        \text{select}(5) = 1010\ 1100\ 1111_2
    \end{align*}
    This is stored in a local variable, $y$.
    
    \item
    We compare $x$ with $y$ using the library function {\ttfamily compareUnsigned}, storing the result in a local variable, $comp$.
    \begin{align*}
        x = 1010\ 1010\ 1111_2\\
        y = 1010\ 1100\ 1111_2\\
        \cline{1-2}
        x < y \implies comp = -1
    \end{align*}
    If $comp = 0$ then $x = y$, which means that $x$ is already present in the set, thus its rank will be $i$. In this case, the method would return $i$. In this example, this is not the case; thus, we proceed.
    
    \item
    We find the branching bit between $x$ and $y$ and store it in a local variable, $j$. This is done with $\text{msb}(x \oplus y)$:
    \begin{align*}
        x &= 1010\ 1010\ 1111_2\\
        y &= 1010\ 1100\ 1111_2\\
        \cline{1-2}
        x \oplus y &= 0000\ 0\underline{1}10\ 0000_2\\
        \cline{1-2}
        j &= \text{msb}(x \oplus y) = 6
    \end{align*}
    
    \item
    The idea behind the current step is described in the \textit{Desketchifying} chapter of \cite{erikdemainelec12}. Below, we also mention the abstraction of viewing the keys at the node as if they were in a Bitwise Binary Tree. This abstraction has been explained in Section~\ref{par:bitwiseTrieAbstraction}.
    
    To find the actual rank of $x$, we need to use the $\text{match}$ function once again. We know now that there is a key, $y$, that matched $x$ but branched away from $x$ in the $6^{\text{th}}$ bit.
    We have now two cases:
    \begin{itemize}
        \item
        If $comp < 0$ then $x < y$, so we apply a mask to $x$ that keeps only its $w-j$ most significant bits and sets the $j$ least significant bits to $0$. Let the value of $x$ after this mask be $x_m$; when applying \textit{match} to $x_m$, we go down the tree to the left as much as possible after the branching bit $j$ because all the bits of $x_m$ after $j$ will be $0$. The rank of $x$ will be the $\text{match}(x_m)$, which Pătrașcu and Thorup denote by $i_0$ in \cite{patrascu2014dynamic}.
        
        \item
        Otherwise, $x > y$. We apply a mask to $x$ that sets its $j$ least significant bits to $1$. When calling $\text{match}$ with $x$ after this mask, we will go down the tree to the right as much as possible after the branching bit $j$ because all the bits of $x_m$ after $j$ will be $1$. The rank of $x$ will be the $\text{match}(x_m) + 1$, which Pătrașcu and Thorup denote as $\text{match}(x_m) = i_1$ in \cite{patrascu2014dynamic}.
    \end{itemize}
    The above-mentioned masks have been defined in Section~\ref{sec:masks}.
    
    In our example, we have $x < y$, so we are in the first case. We apply a mask to $x$ that keeps only the $w-j$ most significant bits of $x$. 
    \begin{align*}
        j = 6\\
        mask = \neg((1 \ll j) - 1)\\
        \cline{1-2}
        mask = \underbrace{1111\ 11}_{w-j}\underbrace{00\ 0000}_j{}_2\\
        x = \underline{1010}\ \underline{10}10\ 1111_2\\
        \cline{1-2}
        x_m = x \wedge mask = \underline{1010}\ \underline{10}00\ 0000_2
    \end{align*}

    Finally we call $\text{match}$ with $x_m$:
    \begin{enumerate}
        \item
        We compress the query with $\text{compress}(1010\ 1000\ 0000_2)$. Thus we have:
        \begin{align*}
            compressingKey = 1111\ 1001\ 0010_2\\
            x_m = \underline{1010}\ \underline{1}00\underline{0}\ 00\underline{0}0_2\\
            \cline{1-2}
            \hat x_m = 0\underline{101}\ \underline{0100}_2
        \end{align*}
        \item
        We make $k$ copies $\hat x$:
        \begin{align*}
            M = (0^{k-1}1)^k_2\\
            \hat x_m = 0101\ 0100_2\\
            \cline{1-2}
            \hat x^k_m = M \times \hat x_m = (0101\ 0100_2)^k\\
        \end{align*}
        
        If we lay the resulting word in a matrix we have:
        \begin{table}[H]
        \centering
        \input{04_Tables/012_xMaskedCompressedCopied.tex}
        \caption[Example of $k$ copies of $\hat x_m$ in a word laid in a $k \times k$ matrix]{$k$ copies of $\hat x_m$ in a word laid in a $k \times k$ matrix}
        \label{tab:xMaskedCompressedCopied}
        \end{table}
        
        \item
        
        We compute $\hat x^k_m \wedge free$, which keeps only the "don't cares" bits in $\hat x^k$. By bitwise $\wedge$ the tables \ref{tab:xMaskedCompressedCopied} and \ref{tab:freeTable} we have:
        \begin{table}[H]
        \centering
        \input{04_Tables/013_freeANDxMaskedCompressedCopied.tex}
        \caption[Example of $\hat x^k_m \wedge free$ in a word laid in a $k \times k$ matrix]{$\hat x^k_m \wedge free$ in a word laid in a $k \times k$ matrix}
        \label{tab:freeANDxMaskedCompressedCopied}
        \end{table}
        
        \item
        We compute $branch \vee (\hat x^k_m \wedge free)$, which is done which bitwise $\vee$ tables~\ref{tab:branchTable} and \ref{tab:freeANDxMaskedCompressedCopied}.
        This operation will use the actual bits of $\hat x^k$ in the "don't cares" positions of all the compressed keys with "don't cares" in the set.
        Thus we end up with:
        \begin{table}[H]
        \centering
        \input{04_Tables/014_branchORfreeANDxMCopied.tex}
        \caption[Example of $branch \vee (\hat x^k_m \wedge free)$ in a word laid in a $k \times k$ matrix]{$branch \vee (\hat x^k_m \wedge free)$ in a word laid in a $k \times k$ matrix}
        \label{tab:branchORfreeANDxMCopied}
        \end{table}
        
        \item
        Now, match returns $\text{rank}(\hat x_m, branch \vee (\hat x^k_m \wedge free))$ via Rank Lemma 1. In table~\ref{tab:branchORfreeANDxMCopied}, we can see that $\hat x_m = 0101\ 0100_2$ is larger than the keys up to row 3, meaning that its rank is 4 (the highlighted row). Thus we have:
        \begin{align*}
            \text{match}(x_m) = 4
        \end{align*}
    \end{enumerate}
    
    \item
    We finish by returning the rank of $x$, which in this case:
    \begin{align*}
        i_0 = \text{match}(x_m) = 4& \\
        \implies \text{rank}(x) = i_0 = 4&
    \end{align*}
\end{enumerate}

\newpage
\section{Inserting while Maintaining the Compressed Keys with "Don't Cares"} \label{sec:InsertDontCares}

\paragraph*{Goal}
Having the implementation from Section~\ref{sec:rankWithDontCares} as a starting point, the goal is to improve the insert method such that $branch$ and $free$ are maintained using the algorithm described in \cite{patrascu2014dynamic} for this effect. Rank queries keep their $O(k)$, and select queries keep their $O(1)$ time. Inserting is bound by the running time of one of its subroutines, which takes $O(k)$ time (the running time of this operation is addressed at a later section of \cite{patrascu2014dynamic}). Apart from that, all the insert algorithm steps take $O(1)$ time. Delete is kept unaltered.

In this section, we will address how to maintain the compressed keys with "don't cares" when inserting a new key, as described in section \textit{Inserting a key} of the \cite{patrascu2014dynamic} paper.
We take another incremental on the implementations from Sections~\ref{sec:DynamicFusionNodeBinaryRank} and \ref{sec:rankWithDontCares}, keeping most of their details with the exception of the {\ttfamily insert} method.
To this extent, we also add some new helper methods.
The resulting implementation can be found in the file specified in figure~\ref{fig:DynamicFusionNodeDontCaresInsertTree}.
\begin{figure}[H]
\dirtree{% 
.1 /. 
.2 src. 
.3 main. 
.4 java. 
.5 integersets. 
.6 \textbf{DynamicFusionNodeDontCaresInsert.java}. 
}
\caption{Location of the {\ttfamily DynamicFusionNodeDontCaresInsert.java} file in the folder structure}
\label{fig:DynamicFusionNodeDontCaresInsertTree}
\end{figure}

The algorithm for inserting a key $x$ in the set while maintaining $branch$ and $free$ entails:
\begin{itemize}
    \item
    Rank via "don't cares", including its subroutines, as introduced and described in Section~\ref{sec:rankWithDontCares}.
    
    \item
    Assessing if introducing a new key adds a new branching bit, e.g., a new column in $branch$ and $free$.
    
    \item
    Computing the rank of new significant positions. In other words, if adding a new key implies adding a new column $j$ in $branch$ and $free$ because it is a new significant position, then we need to know how many set bits are there in the $compressingKey$ up to index $j$.
    
    \item
    Matrix operations in $branch$ and $free$ such as:
    \begin{itemize}
        \item
        Adding rows and columns.
        
        \item
        Updating rows and columns.
        
        \item
        Setting and deleting ranges of bits or particular bits in rows or columns.
    \end{itemize}
    
    \item
    All of the operations described in the {\ttfamily insert (final long x)} method of Section~\ref{sec:binaryRankInterfaceImplementation}.
\end{itemize}

\subsection{Fields} \label{sec:dontCaresInsertFields}

All the class and instance variables remain unchanged in comparison with Section~\ref{sec:dontCaresRankFields}. They are:
\begin{lstlisting}
private static final int k = 8;
private static final int ceilLgK = (int) Math.ceil(Math.log10(k) / Math.log10(2));
private static final long M = Util.M(k, k * k);
private final long[] key = new long[k];
private long index;
private int bKey;
private int n;
private long compressingKey;
private long branch;
private long free;
\end{lstlisting}

\subsection{Helper Methods} \label{sec:dontCaresInsertHelperMethods}

The following helper methods, which have already been implemented in \ref{sec:binaryRankHelperMethods} and \ref{sec:dontCaresRankHelperMethods} are kept:
\begin{itemize}
    \item
    {\ttfamily firstEmptySlot()}
    
    \item
    {\ttfamily fillSlot(final int j)}
    
    \item
    {\ttfamily vacantSlot(int j)}
    
    \item
    {\ttfamily getIndex(final long i)}
    
    \item
    The overloaded methods {\ttfamily updateIndex}
    
    \item
    {\ttfamily updateCompressingKey()}
    
    \item
    {\ttfamily compress(final long x)}
    
    \item
    {\ttfamily long compressedKeys()}
    
    \item
    {\ttfamily updateFree(final long compressedKeys)}
    
    \item
    {\ttfamily dontCares}
    
    \item
    {\ttfamily match(x)}
    
    \item
    {\ttfamily dontCaresRank(final long x)}
    
\end{itemize}

The following are helper methods introduced in this implementation:
\begin{itemize}
    \item
    {\ttfamily matrixM(final int h)} returns a word which when interpreted as a $k \times k$ matrix has only column $h$ set. Let $h = 5$, then {\ttfamily matrixM(5)} returns:
    \begin{table}[H]
    \centering
    \input{04_Tables/015_MatrixH.tex}
    \caption{{\ttfamily matrixM(5)}}
    \label{tab:matrixM}
    \end{table}
    
    \item
    {\ttfamily matrixMColumnRange(final int lo, final int hi)} returns a word which when interpreted as a $k \times k$ matrix will have the bits in the range of columns between $lo$ (inclusive) and $hi$ (inclusive) set. Let $lo = 3$ and $hi = 6$, then {\ttfamily matrixMColumnRange(3, 6)} returns:
    \begin{table}[H]
    \centering
    \input{04_Tables/016_MatrixColumnRange.tex}
    \caption{{\ttfamily matrixMColumnRange(3, 6)}}
    \label{tab:MatrixColumnRange}
    \end{table}
    
    \item
    {\ttfamily matrixMRowRange(final int lo, final int hi)} returns a word which when interpreted as a $k \times k$ matrix will have the bits in the range of rows between $lo$ (inclusive) and $hi$ (inclusive) set. Let $lo = 3$ and $hi = 6$, then {\ttfamily matrixMRowRange(3, 6)} returns:
    \begin{table}[H]
    \centering
    \input{04_Tables/019_MatrixRowRange.tex}
    \caption{{\ttfamily matrixMRowRange(3, 6)}}
    \label{tab:MatrixRowRange}
    \end{table}
    
    \item
    {\ttfamily insertAndInitializeColumn(final int h)} introduces a new column in $branch$ and $free$, initializing it to its default bit value ($0$ in $branch$ and $1$ in $free$).
    Let $branch$ and $free$ be the following:
    \begin{figure}[H]
    \centering
    \input{04_Tables/017_branchAndFreeExample.tex}
    \caption{Examples of $branch$ and $free$}
    \label{fig:branchAndFreeExample}
    \end{figure}
    A call to {\ttfamily insertAndInitializeColumn(2)} will move all columns larger than $2$ one position to the left and set values in the new column them to their respective default. In the tables from figure~\ref{fig:branchAndFreeAfterColumnInsertion} we can see the new column highlighted.
    \begin{figure}[H]
    \centering
    \input{04_Tables/018_branchAndFreeAfterInsertion.tex}
    \caption[Example of $branch$ and $free$ after insertion of column at position $2$]{$branch$ and $free$ after insertion of column at position $2$}
    \label{fig:branchAndFreeAfterColumnInsertion}
    \end{figure}
    
    \item
    {\ttfamily insertRow(final int rank)} introduces a new row in $branch$ and $free$ at position $rank$. All rows with rank larger than $rank$ will occupy their respective next row. Calling {\ttfamily insertRow(2)} while having $branch$ and $free$ as the tables from figure~\ref{fig:branchAndFreeExample} as instance variables will result on the following:
    \begin{figure}[H]
    \centering
    \input{04_Tables/020_InsertingRow.tex}
    \caption[Example of $branch$ and $free$ after insertion of row at position $2$]{$branch$ and $free$ after insertion of row at position $2$}
    \label{fig:branchAndFreeAfterRowInsertion}
    \end{figure}
\end{itemize}

\subsection{Implementation of the Interface Methods}  \label{sec:dontCaresInsertInterfaceImplementation}

The following interface methods suffered no changes and serve the same purpose as the implementation from Section~\ref{sec:dontCaresRankInterfaceImplementation}:
\begin{itemize}
    \item
    {\ttfamily select(final long rank)}
    
    \item
    {\ttfamily size()}
    
    \item
    {\ttfamily delete(final long x)}\footnote{At this stage, we still maintain the compressed keys with "don't cares" naively after removing a key from the set.}
    
    \item
    {\ttfamily rank(final long x)}
    
    \item
    {\ttfamily reset()}
\end{itemize}

Based on the description of \textit{Inserting a key} of \cite{patrascu2014dynamic}, we implement {\ttfamily insert(final long x)} method the following way:
\begin{enumerate}
    \item
    A local variable $rank$ is initialized to $0$.
    
    \item
    If the set is not empty:
    \begin{enumerate}
        \item \label{blt:matchX}
        We compute $\text{match}(x)$ and store it in a local variable $i$.
        
        \item
        We query $\text{select}(i)$ and and store it in a local variable $y$.
        
        \item
        We use the unsigned comparator from the standard library, {\ttfamily compareUnsigned}, to assess if the keys, $x$ and $y$, are equal, or if one is larger than the other. This is stored in a local variable $comp$.
        
        \item
        If $comp = 0$, then $x = y$, which means that $x$ is already present in the set. In this case, the method returns, introducing no changes to the contents of the data structure.
        
        \item
        At this stage, we know that $x$ is a new key, so before inserting it, we perform another check to see if the data structure has reached its capacity limit, $k$, throwing an exception in this case.
        
        \item
        We find the branching bit between $x$ and $y$, $\text{msb}(x \oplus y)$, and store it in a local variable, $j$.
        
        \item \label{blt:naiveRankJ}
        We compute the rank of $j$ in $compressingKey$ by masking all the bits at indices larger than $j$ and calling the standard library function, {\ttfamily bitCount}, on the masked $compressingKey$. This is stored in a local variable, $h$. At this stage, this operation is done naively, as Pătrașcu and Thorup address this operation in a later section.
        
        \item  \label{blt:matchI_0I_1}
        We compute $i_0$ and $i_1$, given by the calls $\text{match}(x \wedge \neg((1 \ll j) - 1))$ and $\text{match}(x \vee ((1 \ll j) - 1))$. These masks and queries have been explained in \ref{sec:rankDontCaresQuery} and they will correspond to rows in $branch$ and $free$, e.g. the rank of actual keys in the set.
        
        \item
        Just like in \ref{sec:rankDontCaresQuery}, we compute the rank of $x$ based on how its value compares with $y$, updating the local variable $rank$ accordingly.
        
        \item
        We compute and store locally {\ttfamily matrixM(h)}.
        
        \item
        If $j$ was not already a significant bit:
        \begin{itemize}
            \item
            We mark it as a significant bit in $compressingKey$.
            
            \item
            We update $branch$ and $free$ with a call to {\ttfamily insertAndInitializeColumn(h)}.
        \end{itemize}
        
        \item \label{blt:matrixRowColumnMask}
        We call {\ttfamily matrixMRowRange(i\_0, i\_1)} and intersect it with  {\ttfamily matrixM(h)}. This will produce a mask that has column $h$ in the range of rows between $i_0$ and $i_1$ set to $1$, and every other rows and columns set to $0$.
        
        \item
        We use the mask from step~\ref{blt:matrixRowColumnMask} to mark column $h$ in the range of rows between $i_0$ and $i_1$ as a "care" position. This entails setting those positions to $0$ in $free$ and storing the bit value of position $j$ in $y$ in $branch$.
        
        \item
        We insert a new row in $branch$ and $free$ with a call to {\ttfamily insertRow(rank)}.
        
        \item
        The local variable $i$, which stores the rank of $y$, is updated. This means that if $x < y$, then after inserting $x$, the rank of $y$ will have incremented. In such a case, we increment $i$ to reflect that.
        
        \item
        The last steps consist of updating row $rank$, which stores the $\hat x^?$, with the appropriate values. These are:
        \begin{itemize}
            \item
            In $branch$:
            \begin{itemize}
                \item
                The values of the bits in positions between $0$ and $h - 1$ are set to $0$:
                \begin{align*}
                    branch\langle rank, 0 \dots h - 1 \rangle_{k \times 1} \coloneqq 0^h
                \end{align*}
                
                \item
                We read $x\langle j\rangle_1$ and store it at position $h$:
                \begin{align*}
                    branch\langle rank, h\rangle_{k \times 1} \coloneqq x\langle j \rangle_1
                \end{align*}
                
                \item
                We copy the bit values in positions between $h+1$ and $k-1$ from the $\hat y^?$ to the same positions:
                \begin{align*}
                    branch\langle rank, h + 1 \dots k - 1\rangle_{k \times 1} \coloneqq branch\langle i, h + 1 \dots k - 1\rangle_{k \times 1}
                \end{align*}
                
            \end{itemize}
            
            \item
            In $free$:
            \begin{itemize}
                \item
                The values of the bits in positions between $0$ and $h-1$ are set to $1$:
                \begin{align*}
                    free\langle rank, 0 \dots h - 1 \rangle_{k \times 1} \coloneqq 1^h
                \end{align*}
                
                \item
                We set position $h$ to $0$:
                \begin{align*}
                    free\langle rank, h\rangle_{k \times 1} \coloneqq 0
                \end{align*}
                
                \item
                We copy the bit values in positions between $h+1$ and $k-1$ from the $\hat y^?$ to the same positions:
                \begin{align*}
                    free\langle rank, h + 1 \dots k - 1\rangle_{k \times 1} \coloneqq free\langle i, h + 1 \dots k - 1\rangle_{k \times 1}
                \end{align*}
            \end{itemize}
        \end{itemize}
    \end{enumerate}
    
    \item
    We finish by computing the steps described in \ref{sec:binaryRankInsert}, effectively insert $x$ in the set.
\end{enumerate}

The overall running time of this algorithm is bound by the match subroutines (steps~\ref{blt:matchX} and \ref{blt:matchI_0I_1}) and finding the rank of the new branching bit (step~\ref{blt:naiveRankJ}): these take $O(3\cdot k) = O(k)$. Otherwise, all the remaining steps taken by this algorithm run in $O(1)$ time.

\subsection{Example} \label{sec:dontCaresInsertExample}

We will now insert the key $x = 1001\ 0101\ 0001_2$ in a set containing the keys from table~\ref{tab:keysInTheSetBeforeInsertion}, showcasing all the steps. For brevity, the chosen keys only have set bits up to position 11 such that the 52 most significant bits do not influence any of the steps in the algorithm and can safely be omitted.

\begin{table}[H]
\centering
\input{04_Tables/021_keysInTheSetBeforeInsertion.tex}
\caption[Example set of keys in binary]{Binary representation of the keys present in the data structure. The table also shows their rank (on the first column) and the bit values at every index (on the first row) up to position 11}
\label{tab:keysInTheSetBeforeInsertion}
\end{table}

This set of keys will produce the following compressing key:
\begin{align*}
    compressingKey = 1100\ 0001\ 0000_2
\end{align*}

The compressed keys with "don't cares" stored in $branch$ and $free$ are shown in the tables of figure~\ref{fig:branchAndFreeBeforeInsertion}.

\begin{figure}[H]
\centering
\input{04_Tables/022_branchAndFreeBeforeInsertion.tex}
\caption{Resulting $branch$ and $free$ after the compression of keys with "don't cares" from table~\ref{tab:keysInTheSetBeforeInsertion}}
\label{fig:branchAndFreeBeforeInsertion}
\end{figure}

Inserting $x$ in the given set is comprised of the following:

\begin{itemize}
    \item
    We start by initializing a local variable $rank$, which will be used to store the rank of our query, $x$. Its initial value will be $0$.
    
    \item
    If the set is not empty (which for the moment it is not), then we have to run the steps from Sections~\ref{sec:updateI0_I1} to \ref{sec:updateRankRow}; otherwise we skip to \ref{sec:dontCaresInsert}. This is because when the set is empty, there is no need for updating the compressed keys with "don't cares".
\end{itemize}

\subsubsection{Updating the Range of Keys whose Compressed Key match the Insertion Key} \label{sec:updateI0_I1}

\begin{enumerate}
    \item
    We start by computing some variables that are used for computing the rank of $x$ along with $i_0$ and $i_1$, which specify a range of compressed keys with "don't cares" (rows in $branch$ and $free$) which have to be updated upon the present insertion:
    \begin{enumerate}
        \item
        We run $\text{match}(x)$ and store it in a local variable $i$:
        \begin{align*}
            x = 1001\ 0101\ 0001_2\\
            \cline{1-2}
            i \coloneqq \text{match}(x) = 3
        \end{align*}
        
        \item
        We query $\text{select}(i)$ and store it in a local variable $y$:
        \begin{align*}
            i = 3\\
            \cline{1-2}
            y \coloneqq \text{select}(i) = 1010\ 1101\ 0110_2
        \end{align*}

        \item
        We compare $x$ and $y$ with the {\ttfamily compareUnsigned} function from the standard library, storing the result in a local variable $comp$.
        \begin{align*}
            x = 1001\ 0101\ 0001_2\\
            y = 1010\ 1101\ 0110_2\\
            \cline{1-2}
            x < y \implies comp = -1
        \end{align*}
        Since $comp \not= 0$, then $x$ is not in the set, so we proceed.
        
        \item
        We check also if the set has room for $x$ with {\ttfamily size() < k}. In this case, it is not, so we proceed.

        \item
        To find the branching bit between $x$ and $y$, we compute $\text{msb}(x \oplus y)$ and store it in a local variable, $j$.
        \begin{align*}
            x = 10\underline{0}1\ 0101\ 0001_2\\
            y = 10\underline{1}0\ 1101\ 0110_2\\
            \cline{1-2}
            x \oplus y = 00\underline{1}1\ 1000\ 0111_2\\
            \cline{1-2}
            j \coloneqq \text{msb}(x \oplus y) = 9
        \end{align*}
        
        \item
        We need to find the rank of $j$ in the $compressingKey$ and store it in a local variable, $h$. This variable will specify the column where we will write the branching bit to. We mask the bits that are at higher positions than $j$ and call the standard library function, {\ttfamily bitCount}, on that result:
        \begin{align*}
            j = 9 \\
            compressingKey = 110\underline{0}\ \underline{0001}\ \underline{0000}_2 \\
            mask = (1 \ll j) - 1 = 0001\ 1111\ 1111_2\\
            \cline{1-2}
            h \coloneqq \text{{\ttfamily bitCount}}(compressingKey \wedge mask) = 1
        \end{align*}
        
        \item
        We compute $i_0$ and $i_1$, which are computed by calling $\text{match}(x \wedge \neg((1 \ll j) - 1))$ and $\text{match}(x \vee ((1 \ll j) - 1))$:
        
        \begin{align*}
            j = 9 \\
            x = 100\underline{1}\ \underline{0101}\ \underline{0001}_2 \\
            \cline{1-2}
            \neg((1 \ll j) - 1) = 1110\ 0000\ 0000_2 \\
            x \wedge \neg((1 \ll j) - 1) = 100\underline{0}\ \underline{0000}\ \underline{0000}_2\\
            i_0 \coloneqq\text{match}(x \wedge \neg((1 \ll j) - 1)) = 2\\
            \cline{1-2}
            (1 \ll j) - 1 = 0001\ 1111\ 1111_2 \\
            x \vee ((1 \ll j) - 1) = 100\underline{1}\ \underline{1111}\ \underline{1111}_2\\
            i_1 \coloneqq \text{match}(x \vee ((1 \ll j) - 1)) = 3\\
        \end{align*}
        
        \item
        We compute $\text{rank}(x)$. If $x < y$, then $\text{rank}(x) = i_0$; otherwise, it is $i_1 + 1$:
        \begin{align*}
            i_0 = 2 \\
            i_1 = 3 \\
            \cline{1-2}
            comp = -1 \implies \text{rank}(x) = i_0 \\
            rank \coloneqq 2
        \end{align*}
    \end{enumerate}
    
    \item
    We compute the matrix mask needed for, among other things, adding a new column $h$ in $branch$ and $free$, storing the result in a local variable $matrixM_h$. This results in table~\ref{tab:matrixMh}, where we can also see column $h$ highlighted.
    \begin{table}[H]
    \centering
    \input{04_Tables/023_matrixMh.tex}
    \caption[{\ttfamily matrixM(1)}]{$matrixM_h$}
    \label{tab:matrixMh}
    \end{table}
    
    \item
    We check if $j$ was already a significant position:
    \begin{align*}
        j = 9 \\
        compressingKey = 11\underline{0}0\ 0001\ 0000_2 \\
        \cline{1-2}
        \text{bit}(j, compressingKey) = 0
    \end{align*}
    Since it was not:
    \begin{itemize}
        \item
        We mark it as a significant position by setting bit $j$ in $compressingKey$:
        \begin{align*}
            j = 9 \\
            compressingKey = 11\underline{0}0\ 0001\ 0000_2\\
            \cline{1-2}
             compressingKey \coloneqq \text{setBit}(j, compressingKey) = 11\underline{1}0\ 0001\ 0000_2
        \end{align*}
        
        \item
        We update $branch$ and $free$ to include the new column $h$. The {\ttfamily insertAndInitializeColumn(h)} method is called thus altering $branch$ and $free$ as we see in the tables from figure~\ref{fig:branchAndFreeInsertHcolumn}.
        \begin{figure}[H]
        \centering
        \input{04_Tables/024_branchAndFreeInsertHcolumn.tex}
        \caption[Example of $branch$ and $free$ after insertion of column at position $1$]{Insertion of column $h$ in $branch$ and $free$}
        \label{fig:branchAndFreeInsertHcolumn}
        \end{figure}
    \end{itemize}

    \item
    We call the function {\ttfamily matrixMRowRange($i_0$, $i_1$)} which returns a mask comprised of the range of rows $\{ i_0, \dots, i_1 \}$. Bitwise $\wedge$ that mask with $matrixM_h$ computes a mask where only the bits of rows $\{ i_0, \dots, i_1 \}$ and column $h$ are set. These are the bits that of the compressed keys that need to be updated due the insertion of the new key $x$. Thus the mask needed for this effect is the one from table~\ref{tab:matrixMi_0Mi_1h}.
    \begin{table}[H]
    \centering
    \input{04_Tables/025_matrixMi_0Mi_1h.tex}
    \caption[Example of the intersection of column matrix mask, $matrixM_1$, with the row matrix mask $matrixM^{2:3}$, resulting in the mask $matrixM^{2:3}_1$]{$matrixM^{i_0:i_1}_h$, which resulted from the intersection of the column matrix mask, $matrixM_h$, and the row matrix mask, $matrixM^{i_0:i_1}$}
    \label{tab:matrixMi_0Mi_1h}
    \end{table}
    
    \item
    Now we need to update $branch$ and $free$ accordingly. We know that we care for the highlighted positions in table~\ref{tab:matrixMi_0Mi_1h} because $i_0$ and $i_1$ have matched $x$, so we set these positions to $0$ in $free$. The value to store at those positions in $branch$ has to be read from $y$:
    \begin{align*}
        y = 10\underline{1}0\ 1101\ 0110_2 \\
        j = 9 \\
        \cline{1-2}
        \text{bit}(j, y) = 1
    \end{align*}
    We see that the bit value is $1$, thus this will be the value we will update $branch$ with. The result after this update can be seen in the tables from figure~\ref{fig:branchAndFreeAfterMatrixMi_0Mi_1h}.
    \begin{figure}[H]
    \centering
    \input{04_Tables/026_branchAndFreeAfterMatrixMi_0Mi_1h.tex}
    \caption[Example of $branch$ and $free$ after updating column $1$ in rows $2$ and $3$]{$branch$ and $free$ after updating column $h$ of the $i_0:i_1$ compressed keys}
    \label{fig:branchAndFreeAfterMatrixMi_0Mi_1h}
    \end{figure}
\end{enumerate}

\subsubsection{Updating the Instance Variables with the new Compressed Key} \label{sec:updateRankRow}

We now have to insert a row for the new key in $branch$ and $free$ and write its corresponding values. This entails the following:

\begin{enumerate}
    \item
    We call {\ttfamily insertRow(rank)}, making row for $\hat x^?$ in row $rank$ of $branch$ and $free$. The tables from figure~\ref{fig:insertRowRank} show the result of this operation.
    \begin{figure}[H]
    \centering
    \input{04_Tables/027_insertRowRank.tex}
    \caption[Example of $branch$ and $free$ after the insertion of a row]{Insertion of row $rank$ in $branch$ and $free$}
    \label{fig:insertRowRank}
    \end{figure}
    
    \item
    Some of the values of $\hat x^?$ will be copied from $\hat y^?$. For this reason we have to update $i$, the rank of $y$, such that the needed values are copied from the right key.
    \begin{align*}
        i = 3 \\
        x = 1001\ 0101\ 0001_2 \\
        y = 1010\ 1101\ 0110_2 \\
        \cline{1-2}
        x < y \implies i\coloneqq 4
    \end{align*}
    
    \item
    Lastly, we write $\hat x^?$ to $branch$ and $free$.
    \begin{itemize}
        \item
        Row $rank$ of $branch$ will be:
        \begin{align*}
            \textbf{(a)}\quad branch\langle rank, 0 \dots h - 1 \rangle_{k \times 1} &\coloneqq 0^h\\
            \textbf{(b)}\quad branch\langle rank, h\rangle_{k \times 1} &\coloneqq x\langle j \rangle_1\\
            \textbf{(c)}\quad branch\langle rank, h + 1 \dots k - 1\rangle_{k \times 1} &\coloneqq branch\langle i, h + 1 \dots k - 1\rangle_{k \times 1}\\
            \cline{1-2}
            branch\langle rank \rangle_k &\coloneqq\underbrace{000010}_{\textbf{(c)}} \underbrace{0}_{\textbf{(b)}} \underbrace{0}_{\textbf{(a)}}
        \end{align*}
        
        \item
        Row $rank$ of $free$ will be:
        \begin{align*}
            \textbf{(a)}\quad free\langle rank, 0 \dots h - 1 \rangle_{k \times 1} &\coloneqq 1^h \\
            \textbf{(b)}\quad free\langle rank, h\rangle_{k \times 1} &\coloneqq 0 \\
            \textbf{(c)}\quad free\langle rank, h + 1 \dots k - 1\rangle_{k \times 1} &\coloneqq free\langle i, h + 1 \dots k - 1\rangle_{k \times 1} \\
            \cline{1-2}
            free\langle rank \rangle_k &\coloneqq\underbrace{111101}_{\textbf{(c)}} \underbrace{0}_{\textbf{(b)}} \underbrace{1}_{\textbf{(a)}}
        \end{align*}
    \end{itemize}

    We can see the updates described above in the tables from figure~\ref{fig:branchAndFreeAfterUpdatingValuesForRank}.
    \begin{figure}[H]
    \centering
    \input{04_Tables/028_branchAndFreeAfterUpdatingValuesForRank.tex}
    \caption[Example of $branch$ and $free$ after the insertion of a $\hat x^?$ ]{$branch$ and $free$ after the insertion of $\hat x^?$}
    \label{fig:branchAndFreeAfterUpdatingValuesForRank}
    \end{figure}
    
\end{enumerate}

\subsubsection{Storing the Key} \label{sec:dontCaresInsert}

With $branch$ and $free$ now updated, we proceed with remaining insertion operations, which have been described in Section~\ref{sec:binaryRankInsert}.

\chapter{Validation} \label{sec:validationChapter}

This chapter describes the tests that have been implemented and conducted in order to assert the soundness of the implementations discussed in Chapter~\ref{sec:implementationsChapter}.
The implemented test classes can be found in the folder shown in figure~\ref{fig:testFolderTree}.
\begin{figure}[H]
    \dirtree{%
    .1 /. 
    .2 src. 
    .3 test. 
    .4 \textbf{java}. 
    }
    \caption{Location of the testing classes folder}
    \label{fig:testFolderTree}
\end{figure}

Validation summary tables, which include the test results, together with the range or size of the test instances, have been included.
The symbol \checkmark \ in those tables signifies a passed test with the specified parameters.

\section{{\ttfamily Util} Class Tests}

All the tests concerning the {\ttfamily Util} class can be found in the {\ttfamily UtilTest.java} file, whose path is shown in figure~\ref{fig:utilTestTree}.

\begin{figure}[H]
    \dirtree{%
    .1 /. 
    .2 src. 
    .3 test. 
    .4 java. 
    .5 \textbf{UtilTest.java}. 
    }
    \caption{Location of the file containing the testing class of the {\ttfamily Util} class}
    \label{fig:utilTestTree}
\end{figure}

\subsection{msb Series Tests}

The {\ttfamily Util} class contains many different implementations of the msb$(x)$ operation. Since Java's standard library features the {\ttfamily numberOfLeadingZeros} function, we can easily test the different msb$(x)$ implementations. Converting the result from the standard library function is done by subtracting its return value to $w - 1$.

Taking as an example the test on the {\ttfamily msbConstant()} implementation, for such a test to pass all instances in a given range have to assert that {\ttfamily Long.SIZE - 1 - Long.numberOfLeadingZeros(i)} and {\ttfamily Util.msbConstant(i)} are the same. Tests on the other implementations differ only either on $w$ (which can be either 32-bit {\ttfamily Integer} or 64-bit {\ttfamily Long}) and the function that is called, and each of them is named after the function they are testing, e.g. {\ttfamily msb32Obvious()} tests the 32-bit version the naive msb$(x)$ algorithm.

\subsubsection{Validation Results}

\begin{table}[H]
\centering
\input{src/tex/04_Tables/035_msb32Validation}
\caption{Validation summary of the {\ttfamily msb32} functions}
\label{tab:msb32Validation}
\end{table}

\begin{table}[H]
\centering
\input{src/tex/04_Tables/036_msb64Validation}
\caption{Validation summary of the {\ttfamily msb64} functions}
\label{tab:msb64Validation}
\end{table}



\subsection{{\ttfamily splitLong} and {\ttfamily mergeInts}}

The {\ttfamily splitMerge()} method tests the {\ttfamily splitLong} and {\ttfamily mergeInts} methods by evaluating if the following property holds for a determined range of 64-bit keys: {\ttfamily key == mergeInts(splitLong(key))}.

\subsubsection{Validation Results}

\begin{table}[H]
\centering
\input{src/tex/04_Tables/037_splitMergeValidation}
\caption{Validation summary of the {\ttfamily splitLong} and {\ttfamily mergeInts} functions}
\label{tab:splitMergeValidation}
\end{table}

\subsection{Fields of Words Tests}
The {\ttfamily getField} and {\ttfamily setField} methods are tested in the {\ttfamily setAndGetField32()} and {\ttfamily setAndGetField64()} methods (the latter differ solely on the size of the word where the fields are to be written to). A pass of the test consists of:
\begin{enumerate}
    \item
    Varying $b$ (being $b$ the size of each field) between $1$ and $w - 1$.
    
    \item
    For each value $b$ takes, the number of fields to be stored in $A$, $m$, is computed as a function of $b$. The goal is to fit as many fields as possible in $A$, having $b$ and $w$ as constraints. The number of fields to store in A is computed with $m = w / b$.
    
    \item
    Then, $m$ keys of $b$ size are pseudo-randomly generated. Each time a key is generated, $A$ is shifted to the left by $b$ bits, and the key is stored both in an auxiliary array and in $A$ with the {\ttfamily setField} function. 
    
    \item
    When all $m$ keys have been generated and inserted, the auxiliary array is iterated, and at each iteration $i$, it asserts that the key at index $i$ in the auxiliary array is the same as the one returned by the {\ttfamily getField} function.
\end{enumerate}

\subsubsection{Validation Results}

\begin{table}[H]
\centering
\input{src/tex/04_Tables/038_setGetFieldValidation}
\caption{Validation summary of the setter and getter field functions}
\label{tab:setGetFieldValidation}
\end{table}

\subsection{Test for Rank Lemma 1}
The {\ttfamily rankLemma1} function is tested in a method with the same name.
A pass in this test consists of:
\begin{enumerate}
    \item
    Varying $b$ (size in bits of each key). This range is specified in the fields of the {\ttfamily UtilTest} class by the variables {\ttfamily int loB} and {\ttfamily int hiB}.
    
    \item
    For each value $b$ takes, the number of keys to be stored in $A$, $m$, is computed by taking the minimum between $2^b$ and $w/b$. This is because the method requires that all keys stored in $A$ to be distinct (and all combinations of keys of size $b$ are given by $2^b$), but also $A$ can only store up to $w/b$ keys.
    
    \item
    We produce $m$ distinct keys by using a pseudo-random generator and inserting them in a set. We stop once the size of the set is $m$.
    
    \item
    An additional key $x$ is generated. The rank of $x$ will be computed and used later as one of the last checks of this test.
    
    \item
    The keys are then copied to a list, where they are sorted in descending order.
    
    \item
    The list is then iterated from the largest key to the smallest. Each iteration consists of inserting the current key in $A$. That key is also compared with $x$ in order to compute the rank of $x$, which is determined by the index of the current key in the list.
    
    \item
    The list is iterated once more in order to assess if the rank of each key in the list agrees with the rank computed with {\ttfamily rankLemma1} function.
    
    \item
    Lastly, the rank of $x$, which has been computed before, is compared with its rank computed via the {\ttfamily rankLemma1} function.
\end{enumerate}

\subsubsection{Validation Results}

\begin{table}[H]
\centering
\input{src/tex/04_Tables/039_Lemma1Validation}
\caption{Validation summary of the Rank Lemma 1 function}
\label{tab:rankLemma1Validation}
\end{table}

\newpage
\section{Integer Data Structure tests} \label{sec:IntegerDataStructureTests}

Each implementing class of the {\ttfamily RankSelectPredecessorUpdate} interface has a corresponding test class. The file names of those classes are the highlighted in figure~\ref{fig:implementingClassesTestFilesTree}.

\begin{figure}[H]
    \dirtree{%
    .1 /. 
    .2 src. 
    .3 test. 
    .4 java. 
    .5 \textbf{DynamicFusionNodeBinaryRankTest.java}. 
    .5 \textbf{DynamicFusionNodeDontCaresInsertTest.java}. 
    .5 \textbf{DynamicFusionNodeDontCaresRankTest.java}. 
    .5 \textbf{NaiveDynamicFusionNodeTest.java}. 
    }
    \caption{Location of the testing class files of the {\ttfamily RankSelectPredecessorUpdate} implementing classes}
    \label{fig:implementingClassesTestFilesTree}
\end{figure}

\subsection{Testing Helper Class}

In order to avoid duplicate code, a helper class, denoted {\ttfamily RankSelectPredecessorUpdateTest}, was implemented. It can be found in the same folder as the remaining test classes, as shown in figure~\ref{fig:implementingClassesTestFilesTree}.

Each of the implementation's testing classes creates an instance of the helper class and uses its methods to test its respective implementation.

The {\ttfamily RankSelectPredecessorUpdateTest} constructor takes the following parameters:
\begin{itemize}
    \item
    {\ttfamily long seed}.
    This seed is used as a parameter for instantiating a pseudo-random generator from the Java standard library --- {\ttfamily java.util.Random}.
    This instance will be later used to produce data for the test cases, such as seeds for passes (explained below), which in turn will produce keys to be used in the tests.
    
    \item {\ttfamily int passes}.
    Some tests can be executed in more than one pass. A pass in a particular test consists of generating data with its corresponding seed and running the test with that data
    When $passes > 1$, distinct $\#passes$ seeds are generated, resulting in different pseudo-random values, and the test is run {\ttfamily passes} number of times.
    
    \item {\ttfamily int numKeys}.
    This parameter defines the size of the data set to be generated.
    It is particularly important for testing instances of {\ttfamily DynamicFusionNode}, which size cannot exceed $k$.
\end{itemize}

\subsection{{\ttfamily insertAndMemberSmallTest()}} \label{sec:insertAndMemberSmallTest}
The methods tested in this test are {\ttfamily insert} and {\ttfamily member}. A small set of predetermined keys is inserted in the set, and then {\ttfamily member} is called on the set with each of those keys. 

\subsection{{\ttfamily smallCorrectnessTest()}}

An instance of a {\ttfamily RankSelectPredecessorUpdate} implementation is instantiated and keys are inserted such that after these insertions $S = \{10, 12, 42, -1337, -42\}$.

It is defined that:
\begin{itemize}
    \item
    Select queries can range between $0$ and $|S|-1$. Should any query fall outside this range, then {\ttfamily null} is returned, meaning, no result.
    \item
    $\text{select}(0) = \text{min}\{y \in S \}$.
    \item
    $\text{select}(|S|-1) = \text{max}\{y \in S\}$.
    \item
    Rank queries can be any $w$-bit integer, and their possible range of results $\in \big[ 0, |S| \big]$
    \item
    Any given predecessor query returns the largest key in the subset of keys that are \textbf{strictly} smaller than the query, otherwise {\ttfamily null}.
    \item
    Whereas a successor query returns the queried key if present, otherwise the smallest key in the subset of keys that are larger than the query if any (and in this case {\ttfamily null} is returned).
\end{itemize}

With the given set and the above-mentioned rules, a small test is performed. Table~\ref{tab:smallCorrectnessTests} shows the expressions to be evaluated, and all of them must evaluate to {\ttfamily true} for the test to pass.

\begin{table}[H]
\centering
\input{04_Tables/002_CorrectnessTestSmall.tex}
\caption{Small correctness tests}
\label{tab:smallCorrectnessTests}
\end{table}


\subsection{{\ttfamily insertThenMemberTest()}}

The methods tested in this test are {\ttfamily insert} and {\ttfamily member}, and it can be executed in passes. It consists of:
\begin{enumerate}
    \item
    Iterating through all the pseudo-randomly-generated keys and inserting them all in the instance to be tested.
    \item
    Iterating in random order through all the keys and asserting $key \in S$.
\end{enumerate}

\subsection{{\ttfamily insertThenDeleteRangeOfKeysTest()}}

The methods tested in this test are {\ttfamily insert} and {\ttfamily member}. It consists of iterating the whole range (which goes from $0$ to {\ttfamily numKeys}), where each iteration {\ttfamily i} consists of:
\begin{enumerate}
    \item
    Asserting that the key, {\ttfamily i} is not in the set by calling {\ttfamily member} on the set with the key.
    \item
    Inserting the key {\ttfamily i} in the set.
    \item
    Asserting that the key {\ttfamily i} is in the set.
\end{enumerate}
Should the number of keys exceed 9, then every $1/10$ of {\ttfamily numKeys} the data structure is reset, and all keys are removed.

\subsection{{\ttfamily insertThenDeleteRandomKeysTest()}}

The methods tested in this test are {\ttfamily insert} and {\ttfamily delete}, and it can be executed in passes. After inserting all the pseudo-randomly-generated keys in the set, the keys are iterated in random order. Each iteration consists of:
\begin{enumerate}
    \item
    Asserting that $key \in S$.
    \item
    Removing the key.
    \item
    Asserting that $key \not\in S$.
\end{enumerate}

\subsection{{\ttfamily deleteTest()}}

This test aims to assert that only when deleting an existing key, the set's cardinality is altered. It tests the methods {\ttfamily delete} and {\ttfamily size()}, and it can be executed in passes. At each pass:
\begin{enumerate}
    \item
    Pseudo-random keys are generated, and delete on the set is called with that key.
    \item
    If the key was in the set, then the size must have decreased; otherwise, it must remain the same.
\end{enumerate}

\subsection{{\ttfamily sizeTest()}}

The methods tested in this test are {\ttfamily insert}, {\ttfamily size} and {\ttfamily delete} and it can be executed in passes. Each pass consists of:
\begin{enumerate}
    \item
    Iterating the pseudo-randomly-generated keys in random order. At each iteration, the key is inserted, and it is asserted that {\ttfamily size} has increased by 1.
    \item
    After all the keys have been inserted, the keys are iterated in random order once more, and at each iteration, the key is removed, and it is asserted that {\ttfamily size} has decreased by 1.
\end{enumerate}

\subsection{{\ttfamily growingRankTest()}}

This test aims at ensuring that the following property holds for all the keys in the set: the rank of keys in sorted order is a monotone increasing function. It can be executed in passes, and it works the following way:
\begin{itemize}
    \item
    After inserting all the keys in the set, a copy of those keys is kept on a {\ttfamily TreeSet} (a set that keeps its values in sorted order) such that we can iterate them in their sorted order.
    \item
    A counter {\ttfamily i} is kept and initialized as $0$. It is incremented at each iteration.
    \item
    The test then asserts that the key's rank is the same as the number of the current iteration. Note that we can assume that this condition must hold because the keys are iterated in sorted order. 
\end{itemize}

\subsection{{\ttfamily selectOfRankTest()}}

This test aims at ensuring that the following property holds for all the keys in the set: if a key is present in the set, knowing its rank and them querying for select of that must return the key. It can be executed in passes, and it works by iterating through the pseudo-randomly-generated keys, and at each iteration, it is asserted that {\ttfamily key == select(rank(key))}.

\subsection{{\ttfamily rankOfSelectTest()}} \label{sec:rankOfSelectTest}

This test aims at ensuring that the following property holds for all the keys in the set: the rank of select a query is the query. It can be executed in passes, and it works by iterating from {\ttfamily 0} to {\ttfamily numKeys}. At each iteration {\ttfamily i}, it is asserted that {\ttfamily i == rank(select(i))}.


\subsection{Validation Results}

This section summarizes the results from the tests described in Sections from \ref{sec:insertAndMemberSmallTest} to \ref{sec:rankOfSelectTest} against the implementations described in Sections from \ref{sec:naiveImplementation} to \ref{sec:InsertDontCares}.
The results can be seen in table~\ref{tab:validationImplementations}, where the correspondence between implementation and abbreviation is done in table~\ref{tab:abbreviationsTable}.
In table~\ref{tab:validationImplementations}, the \checkmark symbol signifies a passed test.
We can see that the highlighted implementations pass all tests, using as many keys as each implementation allows.
Each test was repeated with a different set of keys \#$passes$ times.

\begin{table}[H]
\centering
\input{src/tex/04_Tables/034_abbreviationsTable.tex}
\caption{Correspondence table}
\label{tab:abbreviationsTable}
\end{table}

\begin{table}[H]
\centering
\input{src/tex/04_Tables/033_DynamicFusionNodeValidation.tex}
\caption{Validation summary of the \textit{Dynamic Fusion Node} implementations}
\label{tab:validationImplementations}
\end{table}